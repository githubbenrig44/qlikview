///$tab About
/*

This script, BASED ON ROB'S V1.3 CODEBASE, was customized by Steven White (SOIO) to solve
the various issues where Rob's code was confused by TRACE commands and other commands containing the keyword "LOAD"
would incorrectly detect the start and end of "operations" e.g. LOAD, JOIN, CONCATENATE etc

*/

/************************************************
* This QVW is Copyright 2014 by Rob Wunderlich. *
*                                               *
* This QVW may not be redistributed without     *
* permission of the Author.                     *
************************************************/

IF len('$(v.Cookbook.Example.Date)')=0 THEN 
	LET v.Cookbook.Example.Date=date(today(1),'YYYY-MMM-DD');
ENDIF	
IF len('$(v.Cookbook.DocumentName)')=0 THEN 
	LET v.Cookbook.DocumentName = Capitalize(subfield(DocumentName(),'.',1));
ENDIF	
SET v.Cookbook.DocumentName = 'Script Log Analyzer';	
//==== Configure the variables below ===
SET v.Cookbook.Example.Revision=1.3;		// Version 
SET v.Cookbook.Author=Rob Wunderlich;	// Author Name


/************************************************************************
* This script uses Qlikview Components (QVC) as part of it's scripting.	*		 
*																		*
* Learn more about QVC at http://qlikviewcomponents.org					*
*																		*
************************************************************************/
///$tab COMMON FUNCTIONS (NOT CUSTOMIZED)
/*

CSI common functions code (as of 1st Dec 2015) with environment awareness code removed


*/


LET V_DELIMITER_COMMA = ',' ;
LET V_DELIMITER_SEMICOLON = ';' ;
LET common.longest_table_name_formatted = 30 ;

//set local_MAX_FORMAT_LENGTH=30 ; // maximum number of characters allowed for formatting variable name. longer var names will be truncated.
	
// 

// ========================================================================================================================
//
// Save this TAB's text to a file named "FIRE_CSI_QVW_ECS_Common_Functions.TXT" located in relevant INCLUDES folder
//
//
// ========================================================================================================================

// single line functions i.e. $(function_name(parameter1, parameter2, etc)) e.g. IF $(f_does_file_exist(filename)) = 'Y' THEN ; trace Yes it does! ; ELSE ; Trace No it doesnt! ; END IF ;
// f_does_file_exist (filename)
// f_does_table_exist (tablename)
// f_does_field_exist_in_table (fieldname, tablename)
// f_does_field_exist_in_data_model (fieldname)
// f_get_user_my_documents_folder
// f_is_qvw_running_in_publisher
// f_get_just_the_filename
// f_get_just_the_folder
// f_get_clean_connect_string
// f_is_qvw_running_in_publisher
// f_NoOfRows


// LOG file management:
// SUB sub_trace_event (event_description)
// sub generate_error (param_error_text)
// sub generate_warning (param_warning_text)
// sub debug_code_warning (optional_message);
// sub log_new_code_section (optional_message) ;
// common.generate_fatal_error

// file management:
// Sub describe_qvd_file (param_qvd_file, param_optional_get_fields_yn))
// SUB does_file_exist (param_filename)
// SUB get_just_the_directory (param_path_and_filename)
// SUB get_just_the_filename (param_path_and_filename)

// table management:
// sub drop_table ( param_table_name ) 
// sub rename_table (param_table_name_before, param_table_name_after)
// sub describe_all_tables 
// sub is_field_value_unique_within_table (param_table_name, param_field_name)
// sub does_table_exist (param_table_name)
// sub drop_all_tables_except (param_table_name)
// REPLACED WITH SINGLE LING FUNCTION sub does_field_exist_in_table (param_table_name, param_field_name )
// sub is_field_name_unique_to_table (param_table_name, param_field_name )
// sub describe_table (param_table_name, param_fields_output_yn)
// sub common.compare_two_tables (param_table_one, param_table_two)
// sub add_metadata_comment_to_table (param_table_name, param_custom_metadata)
// sub compare_two_qvds (param_qvd_file_1, param_qvd_file_2)
// sub get_table_field_names (param_table_name, param_optional_sort_yn)
// sub get_qvd_field_names (param_qvd_filename, param_optional_sort_yn)
// sub store_table_in_qvd (param_table_name, param_qvd_file, param_write_metadata_yn, param_describe_yn) 
// SUB replace_table (param_original_table_name, param_temporary_table_name) 
// SUB drop_table_if_exists (param_table_name) ;

// support routines
// sub compare_two_delimited_lists (param_list_1, param_list_2, param_delimiter)
// sub sort_delimited_list (param_delimited_list, param_delimiter)
// SUB ENVIRONMENT_INDICATOR.GET_VALUE (optional_param_relative_path_to_includes)

// DEBUG ROUTINES (THEY WILL ONLY DO SOMETHING IF DEBUG FILE "TODO" EXISTS IN HOST QVW'S DIRECTORY
// sub DEBUG.output_tables_to_files (param_comma_list_of_table_names, param_output_folder, param_output_format) ;
// SUB DEBUG.LET_VARIABLE_EQUAL_VALUE

LET QVW_ECS_Common_Functions.v_error_count 				= 0 ;
LET QVW_ECS_Common_Functions.v_warning_count 			= 0 ;
LET QVW_ECS_Common_Functions.v_debug_code_warning 		= 0 ;


// ========================================================================================================================

// Single expression custom functions using SET keyword and $1, $2 etc parameters
// See QVW manual section "Dollar-Sign Expansion with Parameters" for more information on this syntax

// this is used by non-pending SUM GROUPBY logic to provide a generic LOAD SUM GROUPBY statement that can be used by all periods and is executed via parameters
SET f_does_field_exist_in_data_model =IF( IsNull (fieldvaluecount( $1 )), 'N', 'Y') ;

// $1 path and file filename
// will return just the filename.EXT part of a path\filename (used for logging)
// e.g. let x= $(f_get_just_the_filename('C:\temp\filename.QVD')) will returned 'filename.QVD' in variable 'x'
//Set f_get_just_the_filename = IF (index( $1, '\', -1 ) =0, '$1', MID ($1, index( $1, '\', -1 )+1 ) ) ;
Set f_get_just_the_filename =SubField ( $1, '\' , -1)  ; // -1 means 1st field working from end of string backwards (1 would mean working from the start of string). also if no delimiter, whole is returned

Set f_get_just_the_folder =IF (index( $1, '\', -1 ) =0, '', MID ($1, 1, index( $1, '\', -1 )-1 ) ) ;

// $1 filename
SET f_does_file_exist =IF( IsNull (FileTime( $1 )), 'N', 'Y') ;
	
// $1 table name
set f_does_table_exist =IF ( IsNull ($1), 'N', IF ( IsNull (TableNumber($1)), 'N', 'Y' ) ) ;

// $1=fieldname $2=tablename
SET f_does_field_exist_in_table =IF (FieldNumber($1,$2) = 0, 'N', 'Y' ) ;

// no parameters - will return Windows My Documents folde for current user e.g. C:\Users\soio\Documents
SET f_get_user_my_documents_folder =GetRegistryString('HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders','Personal')  ; // "Desktop" is another good key

// Remove password from ConnectString. May hide useful info from more complex ConnectString return values e.g. usage [ let x=$(f_get_clean_connect_string) ]
SET f_get_clean_connect_string = LEFT (ConnectString(), INDEX (ConnectString(), 'PWD')-1 );


/*
Function [f_is_qvw_running_in_publisher] detects if the QVW is running in PUBLISHER when OSUSER is any of the QVW team's aliases

Other ways of detecting running in Publisher is if QVW LOG has the following values *highlight* 
Reload Executed By *OPR\SVC_QLIKVIEW* <<<<<<<<<<< THIS RELATES TO QVW FUNCTION "OSuser"
Process Executing: *QVB*

This procedure is used to avoid raising custom dialog boxes while code is running in Publisher
THIS METHOD OF SPECIFICALLY CHECKING FOR ALIASES WAS DEEMED THE SAFEST SINCE WE CAN NEVER RISK RAISING A DIALOG IN PUBLISHER AND NO NORMAL USER ALIAS IS LOGGED IN AND RUNNING THE JOBS VIA PUBLISHER. ONLY SYSTEM USERS ARE.
another way of detecting runnung in Publisher is if the QVW LOG contains the line (early on) of "Process Executing: QVB" (as compared to non-Publisher of "Process Executing: QlikView Desktop") but since QVW LOG filenames can be timestamped and its not easy to work out which QVW LOG file relates the currently executing QVW it is not 100% reliable
*/

SET f_get_just_user_from_OSUser = IF (INDEX (UPPER (OSuser()),'\',-1) > 0, MID (UPPER (OSuser()),INDEX (UPPER (OSuser()),'\',-1)+1, 1000), UPPER (OSuser()) ) ; // helper function to make [f_get_just_user_from_OSUser] easier to read

Set f_is_qvw_running_in_publisher=IF ( INDEX ('DXIN,MM8A,JNZG,DXUD,GEPQ,D5LU,QOZ7,DW8P,SOIO,', UPPER ( $(f_get_just_user_from_OSUser()) ) ) > 0, FALSE () , True ()  ) ;



SET f_NoOfRows=IF ( IsNull (NoOfRows($1)), -10000000000,  NoOfRows($1)  ) ; // NoOfRows doesn't produce an error when supplied by bad table name. it does return a NULL. so this function makes it return a really bad number which should stand out

SET f_return_fixed_length_number 	= REPEAT (' ', $2 - LEN (num($1) ) ) & num($1); // let x=$(f_return_fixed_length_number(1234, 10)); //where 1234=is the number, and 10 is the total char length of return value

SET f_return_fixed_length_text 		= $1 & REPEAT (' ', $2 - LEN ($1 ) ); // let x=$(f_return_fixed_length_number(1234, 10)); //where 1234=is the number, and 10 is the total char length of return value

SET f_return_fixed_length_text_justified	= REPEAT (' ', $2 - LEN ($1 ) ) &  $1 ; // let x=$(f_return_fixed_length_number(1234, 10)); //where 1234=is the number, and 10 is the total char length of return value

SUB get_NoOfRows (param_table_name, return_NoOfRows) ;// alternative to [f_NoOfRows] returns result in [get_NoOfRows.result]
	
	IF $(f_does_table_exist(param_table_name)) = 'Y' THEN ;
	
		LET get_NoOfRows.result = NoOfRows (param_table_name) ;
		
	ELSE
		call generate_error ('Procedure [get_NoOfRows] was passed an invalid table name [$(param_table_name)]') ;
		LET get_NoOfRows.result = -1000000 ; // a very large bad number to make things stand out in log
		
	END IF ;
	
	call output_variable_values ('get_NoOfRows.result') ;
	
	LET return_NoOfRows = get_NoOfRows.result ; // if procedure passed a valid
	
END SUB ;
// =============================================================================================================================================================================================
//LET custom_logging.custom_logging_to_alternate_location_folder = '.\' ;

LET custom_logging.did_logging_table_exist_YN 					= ; // set here so its global

LET custom_logging.table_name 									= 'custom_logging_to_alternate_location_table' ;

let custom_logging.log_file_path_and_name						= DocumentPath( ) & '\' & DocumentName() & '.CUSTOM_LOG.LOG' ; // default until something else comes along

LET custom_logging.enabled_YN 									= 'N' ;

// Sort a delimited list and optionally provide a sort key with a 1-to-1 mapping between the list and the sort key. 

// ========================================================================================================================

// Uses QVW function "SubField"
// subfield( s, 'delimiter' [ , index ] )
// example: 
// substringcount( text , substring )

// cannot have a ',' (comma) in data. The code will replace all commas with semi-colons, sort the list and then re-instate the commas

// SEE 'END SUB' for example usages
// returns via [sort_delimited_list.sorted_list]

sub sort_delimited_list (param_delimited_list, param_delimiter /* optional */ , optional_distinct_list_YN, optional_sort_key_delimited_list /* local variables */, local_distinct_list_YN, local_field_index, local_numer_of_fields, local_swap_indicator, local_temp_field_value, local_temp_table_name, local_reinstate_commas, local_final_delimiter )

	let param_delimited_list 	= trim (param_delimited_list) ;
	let param_delimiter			= TRIM (param_delimiter) ;
	
	//call sub_trace_event ('Procedure [sort_delimited_list] has been passed parameters param_delimited_list=[$(param_delimited_list)] and param_delimiter=[$(param_delimiter)]') ;

	// validation
	IF param_delimiter='' or IsNull (param_delimiter) OR IsNull (param_delimited_list) OR param_delimited_list = '' THEN ; LET _sort_delimited_list = 'Parameter [param_delimited_list] or [param_delimiter] is either NULL or empty' ; call generate_error (_sort_delimited_list) ; EXIT SUB ; END IF ;
	
	IF param_delimiter = ',' THEN ; 
		//call generate_warning ('Procedure [sort_delimited_list] parameter [param_delimiter] is a comma and will be substititued with a semicolon. All commas in the [param_delimited_list] will be replaced but re-instated upon completion ') ; 
		LET local_reinstate_commas = 'Y';
		let param_delimited_list = REPLACE (param_delimited_list, ',' , ';') ;
		LET param_delimiter = ';' ;
	ELSE
		LET local_reinstate_commas = 'N';
	END IF ;
	
	IF ISNULL (optional_distinct_list_YN) OR optional_distinct_list_YN <> 'Y' THEN ;
		
		LET local_distinct_list_YN = ' ' ;
	
	ELSE
		LET local_distinct_list_YN = ' DISTINCT ' ;
	
	END IF ;
	
	// defaults
	IF Right (param_delimited_list,1 ) = param_delimiter THEN ; let param_delimited_list=left (param_delimited_list,len (param_delimited_list)-1); let local_final_delimiter ='Y'; ELSE ; let local_final_delimiter = 'N' ; END IF ; // remove delimiter (it will be added back)
	
	let local_numer_of_fields = SubStringCount( param_delimited_list , param_delimiter ) ; // detect how many fields there are
	
	//call sub_trace_event ('Procedure [sort_delimited_list_using_bubble_sort] with param_delimited_list [$(param_delimited_list)] param_delimiter [$(param_delimiter)] local_numer_of_fields [$(local_numer_of_fields)]' ) ;
	
	let local_temp_table_name = 'sort_delimited_list_using_inline_table' ; // must not clash with any existing table or else QVW will rename unpredictably

	$(local_temp_table_name)_temp: // make temporary table with one row containing all the delimited values
	NOCONCATENATE LOAD * INLINE [
	field_name_sort_delimited_list_using_inline_table
	$(param_delimited_list)
	]
	;
	
	$(local_temp_table_name): // make separate rows from each delimited value using SUBFIELD function
	NOCONCATENATE LOAD 
		SubField (field_name_sort_delimited_list_using_inline_table, '$(param_delimiter)') as field_name_sort_delimited_list_using_inline_table
	RESIDENT 
		$(local_temp_table_name)_temp
	;
	
	DROP TABLE $(local_temp_table_name)_temp ;
	
	$(local_temp_table_name)_sorted: // now sort it
	NOCONCATENATE LOAD 
	$(local_distinct_list_YN) // WILL BE POPULATED AT RUNTIME WITH EITHER A SPACE OR THE WORD 'DISTINCT'
	*
	RESIDENT 
		$(local_temp_table_name)
	ORDER BY 1 ASC // basically use ORDER BY to sort the list
	;

	
	
//$(local_temp_table_name)_sorted: // now sort it
//	NOCONCATENATE LOAD 
//	$(local_distinct_list_YN) // WILL BE POPULATED AT RUNTIME WITH EITHER A SPACE OR THE WORD 'DISTINCT'
//	*
//	RESIDENT 
//		$(local_temp_table_name)
//	ORDER BY 1 ASC // basically use ORDER BY to sort the list
//	;
//	

	DROP TABLE $(local_temp_table_name) ;
	

$(local_temp_table_name)_collapsed: // then get all those separate rows back into a single row
	NOCONCATENATE Load 
		concat(field_name_sort_delimited_list_using_inline_table, '$(param_delimiter)' ) as $(local_temp_table_name)_collapsed
	RESIDENT 
	$(local_temp_table_name)_sorted
;
	

	//  and now PEEK that single row
	let param_delimited_list = PEEK ('$(local_temp_table_name)_collapsed', 0, '$(local_temp_table_name)_collapsed' ) & param_delimiter ;

	DROP TABLE $(local_temp_table_name)_collapsed ;
	DROP TABLE $(local_temp_table_name)_sorted ;


	if local_reinstate_commas = 'Y' THEN ; let param_delimited_list = REPLACE (param_delimited_list, ';', ',') ; END IF ;
	if local_final_delimiter = 'N' THEN ; let param_delimited_list = LEFT (param_delimited_list, LEN(param_delimited_list)-1) ; ELSE /* dont add add it */ ; END IF;

	LET sort_delimited_list.sorted_list = param_delimited_list;
	
end sub


SUB custom_logging.start_logging (param.custom_logging.filename) ;

	// todo - check if empty or a bad folder\filename
	call QVW_Common_routines.logging_header ;
	LET custom_logging.log_file_path_and_name	= param.custom_logging.filename ;
	LET custom_logging.enabled_YN  				= 'Y' ;
	
	call sub_trace_event ('Procedure [custom_logging.start_logging] called and custom logging has started from [' & DocumentName() & '] Log file :' & custom_logging.log_file_path_and_name  ) ;

	call output_variable_values ('custom_logging.did_logging_table_exist_YN,custom_logging.table_name,custom_logging.enabled_YN') ;
	
	
END SUB ;

// =============================================================================================================================================================================================
SUB custom_logging.write_log (param_log_text, /* local variables */ local_unique_log_field_name, local_log_file, local_timestamp_formatted)


	IF custom_logging.enabled_YN  = 'Y' THEN ;

		//LET local_document_name 		= DocumentName() ;
	
		LET local_log_file 				= custom_logging.log_file_path_and_name ;
		
		LET local_timestamp_formatted 	= timestamp( NOW(1), 'YYYY-MM-DD HH:mm:ss') ;
	//	LET local_timestamp_formatted 	= NOW(1);
		
		
		let local_unique_log_field_name = 'Custom_logging_to_an_alternate_location_for_QVW' ;
			
		UNQUALIFY "$(local_unique_log_field_name)"; // Just in case host script has QUALIFY commands active. One reason why this method of holding LOG in an in-memory table isnt always a good idea
		
		//call describe_table (custom_logging.table_name, 'Y') ;
		
		IF custom_logging.did_logging_table_exist_YN = 'Y' AND $(f_does_table_exist(custom_logging.table_name)) = 'N' AND $(f_does_file_exist(local_log_file)) = 'Y'  THEN ; // If the table had been in memory but isnt now we want to load the LOG file into memory to replace it. But if the LOG file itself doesnt exist then we cant load anything. this covers where a LOAD script accidentally does a DROP TABLE on the logging table (usually during a generic clean  up routine)
		
		//call sub_trace_event ('Starting Reload and recreation of table') ;
	
			$(custom_logging.table_name):
			NoConcatenate
			LOAD 
				*
			FROM
				[$(local_log_file)] (txt, utf8, embedded labels, delimiter is '\n', msq) // all that formatting fluff is needed or else field names are badly formed
		;
			
		
		END IF ;
	
		//call sub_trace_event ('After optional reload') ;		
		//call describe_table (custom_logging.table_name, 'Y') ;
				
	
		//call sub_trace_event ('Starting normal CONCAT and STORE') ;
		
		LET local_param_log_text = param_log_text ;
		LET local_param_log_text = REPLACE (local_param_log_text, chr(9), ' ') ; // chr(9) IS A TAB and will cause issues in output TXT file
		LET local_param_log_text = REPLACE (local_param_log_text, ',', ' ') ; // chr(9) IS A TAB and will cause issues in output TXT fil
		
		//call sub_trace_e
				
		$(custom_logging.table_name):
		// No "concatenate" variation can be used here. Correct concatenation will be assumed since there will only be one table with this unusual field name
		LOAD
			'$(local_timestamp_formatted)' & ': ' & '$(local_param_log_text)' as "$(local_unique_log_field_name)" // gotta keep it unique
		AUTOGENERATE 1
		;
			STORE '$(custom_logging.table_name)' into '$(local_log_file)' (txt);
	//	STORE '$(custom_logging.table_name)' into '$(local_log_file)' (txt, delimiter is '\t');
	//		STORE '$(custom_logging.table_name)' into '$(local_log_file)' (txt, delimiter is '|');
			
			
			LET custom_logging.did_logging_table_exist_YN = 'Y' ;			
	
		//call describe_table (custom_logging.table_name, 'Y') ;
	
		QUALIFY "$(local_unique_log_field_name)"; // Just in case host script has UN/QUALIFY commands active. One reason why this method of holding LOG in an in-memory table isnt always a good idea
			
		//call sub_trace_event ('Finished normal CONCAT and STORE') ;
				
	
	
	end if ;
	
			
END SUB ;

// ============================= ===========================================================================================================================================================================================================
// call this procedure at end of script. it will drop logging table and any variables it needs
SUB custom_logging.stop_logging (optional_message, optional_keep_log_table_in_memory); 

	CALL sub_trace_event ('Procedure [stop_custom_logging] called. Resetting variable [custom_logging.log_file_path_and_name] to NULL') ;
	
	IF NOT ISNULL (optional_message) THEN ; CALL sub_trace_event (optional_message) ; END IF ;
	
	IF UPPER(TRIM(optional_keep_log_table_in_memory)) <> 'Y' then ;
		CALL drop_table_if_exists(custom_logging.table_name) ;
	END IF ;
	
	LET custom_logging.log_file_path_and_name 		=; // NULL it to signify logging complete
	LET custom_logging.enabled_YN					= 'N' ;
	
END SUB ;




// ========================================================================================================================
//SUB sub_trace_event (event_description,  optional_param_custom_tag, /* local variables */ local_custom_tag)

//	// NOTE: We cannot allow ';' semi colons to be output by TRACE command since it is a statement terminator
//	let event_description=REPLACE (event_description, ';', ',' ); // TRACE command does not tolerate semi-colons very well
//	let event_description=REPLACE (event_description, chr(13), ' ' ) ; // replace CR with spaces to avoid bad line management in LOG
//
//	IF Not IsNull (optional_param_custom_tag) THEN // if a supplied tag comes along, then use it
//		let local_custom_tag = optional_param_custom_tag ;
//	ELSE
//		IF Not IsNull (QVW_ECS_COMMON_ROUTINES.LOG_ID)   THEN // or use the default if it has been set
//			let local_custom_tag = QVW_ECS_COMMON_ROUTINES.LOG_ID   ;
//		ELSE
//			let local_custom_tag='LOG' ; // else use a standard tag
		//END IF ;
//	END IF ;
		
//	let local_custom_tag = '<' & local_custom_tag & '> ' ;
	
//	trace $(local_custom_tag)$(event_description) ;

//	IF custom_logging.enabled_YN = 'Y' THEN ;
//		CALL custom_logging.write_log  (event_description) ;
//	END IF  ;

//SUB sub_trace_event (event_description) ; // commented out SOIO 1/6/2015
//	TRACE <LOG> $(event_description) ;// commented out SOIO 1/6/2015
//END SUB ;// commented out SOIO 1/6/2015
//

SUB sub_trace_event (event_description) ; // added by SOIO 1/6/2015
	LET sub_trace_event.cleaned_event_description = REPLACE (event_description, ';', ',' ); // added by SOIO 1/6/2015
	TRACE <LOG> $(sub_trace_event.cleaned_event_description) ; // added by SOIO 1/6/2015
END SUB ;





set QVW_ECS_COMMON_ROUTINES.LOG_ID=; // by default this variable is NULL

sub set_LOG_ID (param_QVW_ECS_COMMON_ROUTINES.LOG_ID)

	let QVW_ECS_COMMON_ROUTINES.LOG_ID = param_QVW_ECS_COMMON_ROUTINES.LOG_ID ;
	
end SUB


// ========================================================================================================================
sub generate_error (param_error_text)
// todo - dedcide if its safe to redirect this to the "fatal" error SUB
	
	call sub_trace_event('ERROR:') ;
//	call sub_trace_event('ERROR:' & param_error_text) ;
	IF NOT IsNull (param_error_text) THEN ; call sub_trace_event ('ERROR: $(param_error_text)') ; END IF ;
	call sub_trace_event('ERROR:') ;
	
	// todo - decide how to genrate a fatal error situation SET ERROMODE=2 doesnt work
	LET QVW_ECS_Common_Functions.v_error_count  = QVW_ECS_Common_Functions.v_error_count  + 1; // keep count
	
end sub

// ========================================================================================================================
sub generate_warning (param_warning_text)
	
	call sub_trace_event('WARNING:') ;
//	call sub_trace_event('WARNING:' & param_warning_text) ;
	IF NOT IsNull (param_warning_text) THEN ; call sub_trace_event ('WARNING: $(param_warning_text)') ; END IF ;
	call sub_trace_event('WARNING:') ;
	
	LET QVW_ECS_Common_Functions.v_warning_count = QVW_ECS_Common_Functions.v_warning_count + 1 ;
	
end sub

// ========================================================================================================================

sub debug_code_warning (optional_message);

	call sub_trace_event ('DEBUG CODE: ') ;
	call sub_trace_event ('DEBUG CODE: This QVW contains code which was labelled as DEBUG CODE. Please review with developer since the QVW logic may not function correctly while this code is active') ;
	IF NOT IsNull (optional_message) THEN ; call sub_trace_event ('DEBUG CODE: $(optional_message)') ; END IF ;
	call sub_trace_event ('DEBUG CODE: ') ;
	LET QVW_ECS_Common_Functions.v_debug_code_warning = QVW_ECS_Common_Functions.v_debug_code_warning + 1 ;
	
end sub ;






// ============================================================================================================

// detects if a table name exists in script at the point of execution and returns the existence in variable named as SUB
// All parameters and comparisons are case sensitive
// TECHNICAL NOTE: since functions are not easy in script language, I fake it via a variable named identically to the SUB name

// ALTERNATIVE: See custom function named "f_does_table_exist" for a simpler version of this code

sub does_table_exist (param_table_name /* local vars */ ,_response, _table_number)

	let _table_number = tablenumber(param_table_name) ;
	
	if IsNull (_table_number) then  
		let _response = 'N' ;
	else
		let _response = 'Y' ;
	end if
	
let _does_table_exist = _response ;  // _does_table_exist must be global.
	
end sub

// ========================================================================================================================
// Test whether a field name exists in a specific table
// All parameters and comparisons are case sensitive

// TECHNICAL NOTE: See custom function named "f_does_field_exist_in_table" for a simpler method of detecting this

sub does_field_exist_in_table (param_table_name, param_field_name /* local vars */ ,_does_table_exist,_response,_field_number )

let _response = 'N' ; // default

	call does_table_exist (param_table_name) ;
	if _does_table_exist = 'Y' then
	
		let _field_number = FieldNumber(param_field_name, param_table_name) ;
		
		if _field_number = 0 then  
			let _response = 'N' ;
		else
			let _response = 'Y' ;
		end if
	else
		call generate_error ('Table name [$(param_table_name)] does not exist in script')  ;
		let _response = 'N' ;
	end if

let _does_field_exist_in_table = _response ; // _does_field_exist_in_table must be global
	
end sub

// ========================================================================================================================

// Tests if field name is unique to a table (and not used on any other table)
// Useful to determine which method of checking how unique a key is on an incremental load
// if the key field name is unique then comparing the result of the following functions will indicate uniqueness FieldValueCount(fieldname) and NoOfRows('TableName ')
// if the key field name is not unique then a slower but more reliable method of determining uniqueness must be used
// see is_field_value_unique_within_table procedure for usage
//

sub is_field_name_unique_to_table (param_table_name, param_field_name /* local vars */,_response, _field_existence_counter, _number_of_tables,_table_index,_field_existence_counter)

	//trace Procedure [is_field_unique_to_table] has parameters table name [$(param_table_name)] field name [$(param_field_name)] ;

	let _response = 'N' ; // default

	call does_field_exist_in_table (param_table_name, param_field_name ) ;
	if _does_field_exist_in_table = 'Y' then
		let _field_existence_counter = 0 ;
		let _number_of_tables = NoOfTables() ;
		
		if _number_of_tables > 1 THEN ; // field could exist on multiple tables
			
			for _table_index = 1 to _number_of_tables
				
				call does_field_exist_in_table (TableName(_table_index-1), param_field_name ) ;
				if _does_field_exist_in_table = 'Y' then
					let _field_existence_counter = _field_existence_counter + 1;
				else
					// do nothing 
				end if
	
			next _table_index
			if _field_existence_counter = 1 then // field exists on only one table and since we checked it was on our target table already, it must be unique
				let _response = 'Y' ;
			else
				let _response = 'N' ;	// cant be unique
			end if
	
		ELSE // if there is only table in the model, and that field exists in the table, that it must be unique to the table (makes sense!)
			let _response = 'Y' ; 
		END IF ;		
	else
		call generate_error ('Field [$(param_field_name)] does not exist in table [$(param_table_name)]. Cannot determine uniqueness' ) ;
		let _response = 'N' ;
	end if


let _is_field_name_unique_to_table= _response ; // _is_field_name_unique_to_table must be global

end sub

// ========================================================================================================================

// Determines if the contents of field name are unique within a specific table
// NOTE: Does not use or depend on 'associative' logic i.e. the field's uniqueness is determined exclusively using the values of the targeted table
// This procedure helps with the following script design issues:
// 1. ensuring incremental history files are kept in  synch (since they are usually keyed on a unique field)
// 2. helping confirm that join field(s) are unique for checking cardinalities
//
// Use this function often to prove that DELTA, INCREMENTAL, DELETES or any other tranaction impacting a table are detected and maintained uniquely 
// 
// TECHNICAL NOTES: 
// This procedures uses other functions to dynamically determine which method to use to detect uniqueness. 
// One method is very fast (using QVW built-in functions) and the other uses LOAD RESIDENT to a temoprary table which can be slower on large tables

sub is_field_value_unique_within_table (param_table_name, param_field_name /* local vars */ ,_response )

	//CALL sub_trace_event('Procedure [is_field_value_unique_within_table] has parameters table name [$(param_table_name)] field name [$(param_field_name)]') ;

	if $(f_does_table_exist(param_table_name)) = 'Y' and $(f_does_field_exist_in_table(param_field_name,param_table_name)) = 'Y' then
	
		let _response = 'N' ;
	
			call is_field_name_unique_to_table (param_table_name, param_field_name )
			
			IF NoOfRows(param_table_name) <= 1 THEN 
				call generate_warning ('Procedure [is_field_value_unique_within_table] Uniqueness cannot be checked if there are less than 2 rows in table [$(param_table_name)]');
				let _response = 'N' ;
			ELSE 	
				if _is_field_name_unique_to_table = 'Y' then // use fastest method of detecting uniqueness
							
		//			call sub_trace_event ('FieldValueCount($(param_field_name))=' & FieldValueCount(param_field_name) & ' and NoOfRows($(param_table_name))=' & NoOfRows(param_table_name) ) ;
					if FieldValueCount(param_field_name) = NoOfRows(param_table_name) then
						let _response = 'Y' ;
					else
						let _response = 'N' ;
						
					end if 
				
				else // use slower method (but still alot faster than GROUP BY method)
			
					call generate_warning ('NON OPTIMIZED method of detecting field uniqueness is being used because field [$(param_field_name)] is not unique to table [$(param_table_name)]. Recommend you choose or create field name which is not unique to the target table');
					
					is_field_value_unique_within_table: 
					LOAD
						$(param_field_name) as UNIQUE1234567890_$(param_field_name)
					RESIDENT
						  $(param_table_name) 
					;
					if FieldValueCount ('UNIQUE1234567890_$(param_field_name)') = NoOfRows('is_field_value_unique_within_table') THEN
						let _response = 'Y' ;
					else
						let _response = 'N' ;
					end if 
					drop table is_field_value_unique_within_table ;
				
				end if // END IF FOR _is_field_name_unique_to_table = 'Y'
				
			END IF // END IF FOR NoOfRows(param_table_name) <= 1
	ELSE
	
		call generate_error ('Procedure [is_field_value_unique_within_table] has been passed an invalid table or field name') ;
		let _response = 'N' ;
	
	END IF // does_table_exist
		

IF _response = 'N' THEN

	call generate_warning ('The values of field [$(param_field_name)] in table [$(param_table_name)] CANNOT be confirmed as unique') ;
ELSE 
	call sub_trace_event ('The values of field [$(param_field_name)] in table [$(param_table_name)] have been confirmed as unique') ;
END IF

let is_field_value_unique_within_table = _response ; //is_field_value_unique_within_table must be global

end sub


// ========================================================================================================================
// ALTERNATIVE : See custom function named "f_does_file_exist" for alternative simpler code to achieve the same thing
// 
SUB does_file_exist (param_filename, /* local variable */ v_local_var_file_existence)
	
	CALL sub_trace_event ('Checking for file existence : $(param_filename)') ;
	
	let v_local_var_file_existence =  filetime( param_filename )  ;
	
	if IsNull (v_local_var_file_existence) THEN
		let _does_file_exist = 'N' ; // default
	else
		let _does_file_exist = 'Y' ;
	end if
		
END SUB // _does_file_exist must be global





// ========================================================================================================================
// check if 'before' table name exists
// check if 'after' tale name exists

sub rename_table (param_table_name_before, param_table_name_after)
	
	call sub_trace_event ('Procedure [rename_table] attempting to rename table from [$(param_table_name_before)] to [$(param_table_name_after)]') ;
	
	if IsNull (param_table_name_before) or IsNull (param_table_name_after) THEN
	
		call generate_error ('Procedure [rename_table] has insufficient or incorrect table names') ;
		exit sub ;
		
	END IF
	
	if $(f_does_table_exist(param_table_name_before)) <> 'Y' THEN
		call generate_error ('Table [$(param_table_name_before)] does not exist in model and cannot be renamed') ;
		exit sub ;
	end if
	
	if $(f_does_table_exist(param_table_name_after)) = 'Y' THEN
		call generate_error ('Table [$(param_table_name_after)] already exists in model and cannot be used in rename') ;
		exit sub ;
	end if

	rename table $(param_table_name_before) to $(param_table_name_after) ;
	
	if $(f_does_table_exist(param_table_name_before)) = 'Y' OR $(f_does_table_exist(param_table_name_after)) <> 'Y' THEN ;
	
		call generate_error ('The renaming of table [$(param_table_name_before)] to [$(param_table_name_after)] did not succeed') ;
		exit sub ;
		
	END IF ;
	

		
END SUB ;


// ========================================================================================================================

// constructs metadata about QVW session and table and replaces the table's comments with it
// typically used just before a table is stored in a QVD file
// NOTE: The COMMENT TABLE command associates the comment with the table name and not the table itself i.e. if the table is renamed the comment is still associated with the original table name
// NOTE: To see the comment use TABLE VIEWER 
// param_table_name= name of valid table
// param_custom_metadata = additional text supplied that is included with metadata

// todo - may want to have user code call this with value of varable [QVW_ECS_COMMON_FUNCTIONS.output_variable_values.complete_output_text] to populate [ param_custom_metadata]


sub add_metadata_comment_to_table (param_table_name, param_custom_metadata, /* local variables */ local_v_qvw_metadata_comment, v_CR, v_field_index, v_field_name_list) 

	let add_metadata_comment_to_table.metadata_text =; // by default return NULL
	
	if $(f_does_table_exist(param_table_name)) <> 'Y' THEN ;
	
		call generate_error ('Procedure [add_metadata_comment_to_table] was givem invalid table name [$(param_table_name)]') ;
		
		EXIT SUB ; // cannot update comment since table doesnt exist
		
	END IF 
	
	let v_CR = CHR(13);
	
	call  get_table_field_names (param_table_name, 'N') ;
	let v_field_name_list = get_table_field_names.field_names;
	
	// build metadata string
	let local_v_qvw_metdata_comment = 
	'** Auto generated metadata **' & v_CR & 
	'** To see this metadata in QVW hover over table in Table Viewer. When loading from a QVD LOAD table must be named as table name below for COMMENTs to be displayed. QVW associates COMMENTs with table names and not the table or the QVD itself **' & v_CR & 
	param_custom_metadata & v_CR & 
	''  & v_CR &
	'Timestamp      [' & Now() & ']  ' & v_CR &
	''  & v_CR &
	'[OS user =' & OSuser() & ']  ' & v_CR  &
	'[QVW user =' & QVuser() & ']  ' & v_CR &
	'[QVW version =' & QlikViewVersion() & ']  ' & v_CR   &
	'[Computer name =' & ComputerName() & ']  ' & v_CR &
	'[QVW document =' & DocumentName() & ']  ' & v_CR &
	'[QVW file time =' & FileTime ( DocumentPath() ) & ' (upon QVW opening)' & ']  ' & v_CR &
	'[QVW file size =' & FileSize ( DocumentPath() ) & ' bytes (upon QVW opening)' & ']  ' & v_CR &
	'[QVW path =' & Replace (DocumentPath(), '\', '/') & ']  ' & v_CR  & // have to replace all '\' since they can upset the LOG file for some reason
	'[QVW title =' & DocumentTitle() & ']  ' & v_CR &
	'[Last DB connect =' & $(f_get_clean_connect_string) & ']  ' & v_CR &
	'[Table name =' & param_table_name & ']  ' & v_CR &
	'[Number of rows =' & NoOfRows(param_table_name) & ']  ' & v_CR &
	'[Number of fields =' & NoOfFields(param_table_name) & ']  ' & v_CR &
	'[Field names =' & v_field_name_list & ']  ' & v_CR &
	'' 
	;
	
	
	call sub_trace_event ( REPLACE ('Adding metadata comment to table [$(param_table_name)] ',v_CR, ' ' ) ) ; 
	
	
	COMMENT TABLE $(param_table_name) WITH '$(local_v_qvw_metdata_comment)' ;
	
let add_metadata_comment_to_table.metadata_text = local_v_qvw_metdata_comment ;

END SUB

// ========================================================================================================================
// this procedure is being deprecated and single line function [f_get_just_the_filename] should be used instead

SUB get_just_the_filename (param_path_and_filename)

	call generate_warning ('Function [f_get_just_the_filename] should be used to extract just the filename and not this procedure [get_just_the_filename]. Please update code. This procedure will continue to work ');

	let get_just_the_filename=;
	
	if $(f_does_file_exist(param_path_and_filename)) <> 'Y' THEN  ;
		call generate_error ('Procedure [get_just_the_filename] was passed an invalid filename [$(param_path_and_filename)]' ) ;
		EXIT SUB ;
	END IF ;
	
	get_just_the_filename_file_information: // weird that most of these functions wont operate outside a LOAD statement
	First 1  
	NoConcatenate
	LOAD 
		FileDir() as field_FileDir,
		FileName() as field_FileName,
		FileBaseName() as field_FileBaseName,
		FileExtension() as field_FileExtension,
		FilePath() as field_FilePath
	from 
		'$(param_path_and_filename)' 
	;
	
	let _get_just_the_filename = peek( 'field_FileName',0,'file_information' );
	
	DROP TABLE get_just_the_filename_file_information ;

END SUB

// ========================================================================================================================
SUB get_just_the_directory (param_path_and_filename)

// todo - there is a better way to do this with string scanning i.e. scan from end of string backwards to 1st '\' (if exists) and then extract from that point to end of string

	call generate_warning ('Function [f_get_just_the_folder] should be used to extract just the filename and not this procedure [get_just_the_directory]. Please update code. This procedure will continue to work ');
	
	let get_just_the_path=;
	
	if $(f_does_file_exist(param_path_and_filename)) <> 'Y' THEN  ;
		call generate_error ('Procedure [get_just_the_directory] was passed an invalid filename [$(param_path_and_filename)]' ) ;
		EXIT SUB ;
	END IF ;
	
	get_just_the_directory_file_information: // weird that most of these functions wont operate outside a LOAD statement
	First 1  
	LOAD 
		FileDir() as field_FileDir,
		FileName() as field_FileName,
		FileBaseName() as field_FileBaseName,
		FileExtension() as field_FileExtension,
		FilePath() as field_FilePath
	from 
	'$(param_path_and_filename)' 
	;
	
	let _get_just_the_directory = peek( 'field_FileDir',0,'file_information' );
	
	DROP TABLE get_just_the_directory_file_information ;

END SUB



// // ========================================================================================================================
//// LOGs the field names that are unique to either table and those that are common to both tables
//// helpsto understand what will happen in a script when a JOIN or CONCATENATE is planned in a script
//// 
//// EXAMPLE USAGE : call compare_two_tables ('table_name_1', 'table_name_2') will log the fields that are common to both and distintive to each table
//// 
//// ========================================================================================================================
//
//sub compare_two_tables     (param_table_one, param_table_two, /* expect this to be name of calling variable */ v_compare_two_tables,    /* local variables */ local_field_index, local_field_count, local_field_name, local_common_fields, local_table_one_specific, local_table_two_specific, local_CRLF, local_indent, local_table_1_list, local_table_2_list ) ;
//
//    call sub_trace_event ('Procedure [compare_two_tables] has been passed table one [$(param_table_one)] and table two [$(param_table_one)]') ;
//    
//    let v_compare_two_tables = 'ERROR in procedure [compare_two_tables]' ; // default
//    let local_CRLF = /*CHR(10) & */CHR (13) ;
//    let local_indent = '    ' ;
//    
//    if $(f_does_table_exist(param_table_one)) <> 'Y' THEN 
//        call generate_error ('Table one [$(param_table_one)] does not exist') ;
//        EXIT SUB ;
//    END IF
//
//    if $(f_does_table_exist(param_table_two)) <> 'Y' THEN 
//        call generate_error ('Table two [$(param_table_two)] does not exist') ;    
//        EXIT SUB ;
//    END IF
//    
//    call get_table_field_names(param_table_one, 'N') ; LET local_table_1_list = get_table_field_names.field_names ;
//    call get_table_field_names(param_table_two, 'N') ; LET local_table_2_list = get_table_field_names.field_names ;
//    
//       
//    call compare_two_delimited_lists (local_table_1_list, local_table_2_list, ';') ;
//   
//    let v_compare_two_tables = local_CRLF ;
//    let v_compare_two_tables = v_compare_two_tables & local_indent & 'Procedure [compare_two_tables] comparing Table1 [$(param_table_one)] and Table2 [$(param_table_two)] :' & local_CRLF ;
//    let v_compare_two_tables = v_compare_two_tables & local_indent & 'Fields common to both tables [' & compare_two_delimited_lists.common_to_both_lists & ']'     & local_CRLF;
//    let v_compare_two_tables = v_compare_two_tables & local_indent & 'Fields specific to table1    [' & compare_two_delimited_lists.list_1_only & ']' & local_CRLF ;
//    let v_compare_two_tables = v_compare_two_tables & local_indent & 'Fields specific to table2    [' & compare_two_delimited_lists.list_2_only & ']' & local_CRLF ;
//    
//    call sub_trace_event ( v_compare_two_tables ) ;
//
////	compare_two_tables
//end sub


 // ========================================================================================================================
// LOGs the field names that are unique to either table and those that are common to both tables
// helpsto understand what will happen in a script when a JOIN or CONCATENATE is planned in a script
// 
// EXAMPLE USAGE : call compare_two_qvds ('qvd_filename1', 'qvd_filename1') will log the fields that are common to both and distintive to each table
// 
// ========================================================================================================================

sub compare_two_qvds (param_qvd_file_1, param_qvd_file_2, /* expect this to be name of calling variable */  /* local variables */ local_CRLF, local_indent, local_filename_1, local_filename_2) ;

    call sub_trace_event ('Procedure [compare_two_qvds]:') ;
    call sub_trace_event ('                         QVD1:' & param_qvd_file_1) ;
    call sub_trace_event ('                         QVD2:' & param_qvd_file_2) ;
    
        
    let	compare_two_qvds.comparison_text = 'ERROR in procedure [compare_two_qvds]' ; // default
    let local_CRLF = /*CHR(10) & */CHR (13) ;
    let local_indent = '    ' ;
    
    if $(f_does_file_exist(param_qvd_file_1)) <> 'Y' THEN 
        call generate_error ('QVD doesnt exist: ' & param_qvd_file_1) ;
        EXIT SUB ;
    END IF

    if $(f_does_file_exist(param_qvd_file_2)) <> 'Y' THEN 
        call generate_error ('QVD doesnt exist: ' & param_qvd_file_2) ;
        EXIT SUB ;
    END IF
    
    call describe_qvd_file (param_qvd_file_1, 'N') ; let local_filename_1 = describe_qvd_file.filename ;
    call describe_qvd_file (param_qvd_file_2, 'N') ; let local_filename_2 = describe_qvd_file.filename ;
    
    call get_qvd_field_names(param_qvd_file_1 , 'N') ; LET local_qvd_list_1 = get_qvd_field_names.field_names ;
    call get_qvd_field_names(param_qvd_file_2, 'N') ; LET local_qvd_list_2 = get_qvd_field_names.field_names ;
    
       
    call compare_two_delimited_lists (local_qvd_list_1 , local_qvd_list_2, ';') ;
   
    call sub_trace_event ('');
    call sub_trace_event (local_indent & 'Procedure [compare_two_QVDs] comparing QVD1 [$(local_filename_1)] and QVD2 [$(local_filename_2)] :');
    call sub_trace_event (local_indent & 'Fields common to both tables [' & compare_two_delimited_lists.common_to_both_lists & ']' );
	call sub_trace_event (local_indent & 'Fields specific to QVD1    [' & compare_two_delimited_lists.list_1_only & ']' ) ;
	call sub_trace_event (local_indent & 'Fields specific to QVD2    [' & compare_two_delimited_lists.list_2_only & ']' ) ;
    
    //call sub_trace_event ( compare_two_qvds.comparison_text ) ;

	

end sub



//// param_delimited_list e.g. 
//call sort_delimited_list ('Z,Y,X', ',') ; trace sort_delimited_list.sorted_list=[$(sort_delimited_list.sorted_list)] ; //returns 'X,Y,Z' in global variable [sort_delimited_list.sorted_list] 
//let v_some_text_variable='X,Y,Z'; call sort_delimited_list (v_some_text_variable, ',');   TRACE v_some_text_variable=[$(v_some_text_variable)]  sort_delimited_list.sorted_list=[$(sort_delimited_list.sorted_list)] ; //returns 'X,Y,Z' in global variable [sort_delimited_list.sorted_list] and also in [v_some_text_variable]
//call sort_delimited_list ('Z;Y;X') ; trace sort_delimited_list.sorted_list=[$(sort_delimited_list.sorted_list)] ; //   semi-colon assumed for delimiter
//call sort_delimited_list ('Z Y X', ';') ; trace sort_delimited_list.sorted_list=[$(sort_delimited_list.sorted_list)] ; //returns 'Z Y X' in global variable [sort_delimited_list.sorted_list]   text didnt contain delimiter so cannot sort
//call sort_delimited_list ('', ';') ; trace sort_delimited_list.sorted_list=[$(sort_delimited_list.sorted_list)] ; //generates an error since non-empty first parameter is required
//
//exit script;


// ====================================================================================================================================================================================
// accepts a QVD filename and returns 2 global variables with the field names delimited by ';'
// get_qvd_field_names.field_names 			RETURNS field names in original sequence
// get_qvd_field_names.field_names_sorted 	RETURNS field names in ascending alphanumeric sequence
sub get_qvd_field_names (param_qvd_filename, param_optional_sort_yn /* local variables */,  local_field_index ) 

let get_qvd_field_names.field_names =;
let get_qvd_field_names.field_names_sorted =;

	IF $(f_does_file_exist(param_qvd_filename)) = 'Y' THEN ;
		
		let get_qvd_field_names.field_names=;
		for local_field_index = 1 to QvdNoOfFields( param_qvd_filename ) step 1
			let get_qvd_field_names.field_names = get_qvd_field_names.field_names & QvdFieldName( param_qvd_filename, local_field_index) & ';' ; 
		next local_field_index ;
		
		IF UPPER (param_optional_sort_yn) = 'Y' THEN ;
			let get_qvd_field_names.field_names_sorted = get_qvd_field_names.field_names ;
			call sort_delimited_list (get_qvd_field_names.field_names_sorted, ';') ;
		ELSE
			let get_qvd_field_names.field_names_sorted=;
		END IF ;	
	ELSE 
	
		let _get_qvd_field_names = 'ERROR Procedure [get_qvd_field_names] cannot get field names. File doesnt exist [$(param_qvd_filename)]' ;
		call generate_error (get_qvd_field_names.field_names) ;
		
	END IF ;


END SUB

// ====================================================================================================================================================================================

// accepts a (in memory) table name and returns 2 global variables with the field names delimited by ';'
// _get_table_field_names 			RETURNS field names in original sequence
// _get_table_field_names_sorted 	RETURNS field names in ascending alphanumeric sequence
sub get_table_field_names (param_table_name, param_optional_sort_yn /* local variables */,  local_field_index ) 

let get_table_field_names.field_names =;
let get_table_field_names.field_names_sorted =;


	IF $(f_does_table_exist(param_table_name)) = 'Y' THEN ;
		
		let get_table_field_names.field_names= '';
		for local_field_index = 1 to NoOfFields(param_table_name ) step 1 
			let get_table_field_names.field_names = get_table_field_names.field_names & FieldName( local_field_index, param_table_name) & ';' ; 
		next local_field_index ;
		
		let get_table_field_names.field_names_sorted = get_table_field_names.field_names ;
		IF UPPER (param_optional_sort_yn) = 'Y' THEN ;
			let get_table_field_names.field_names_sorted = get_table_field_names.field_names ;
			call sort_delimited_list (get_table_field_names.field_names_sorted, ';') ;
			LET get_table_field_names.field_names_sorted = sort_delimited_list.sorted_list ;
		ELSE
			let get_table_field_names.field_names_sorted=;
		END IF ;	

	ELSE 
	
		let get_table_field_names.field_names = 'ERROR Procedure [get_table_field_names] cannot get field names. Table doesnt exist [$(param_table_name)]' ;
		call generate_error (get_table_field_names.field_names) ;
		
	END IF ;


END SUB

// ====================================================================================================================================================================================

sub compare_two_delimited_lists (param_list_1, param_list_2, param_delimiter /* local variables */, local_param_list_1, local_param_list_2, local_subfield, local_list_1_index,  local_list_2_index, local_list_1_fieldcount, local_list_2_fieldcount, local_list_1_only, local_list_2_only, local_common_to_both, local_does_field_match)

let local_param_list_1 = param_list_1;
let local_param_list_2 = param_list_2;

//todo  check params
IF IsNULL (param_list_1) OR IsNULL (param_list_2)  OR trim (param_list_1)  = '' or trim (param_list_2)  = '' or IsNull (param_delimiter) OR trim (param_delimiter) = '' THEN

	LET local_subfield = 'Procedure [compare_two_delimited_lists] is missing parameters. It was passed [$(param_list_1)], [$(param_list_2)] and [$(param_delimiter)]' ;
	LET _compare_two_delimited_lists.common_to_both_lists = local_subfield;
	CALL generate_error (compare_two_delimited_lists.common_to_both_lists ) ;
	EXIT SUB ;	
ENDIF

// add any missing delimiters to beginning and end of parameters
let local_param_list_1 = TRIM (local_param_list_1) ; 
IF LEFT (local_param_list_1, 1) <> param_delimiter THEN ; LET local_param_list_1 =  param_delimiter & local_param_list_1  ; END IF ;
IF RIGHT (local_param_list_1, 1) <> param_delimiter THEN ; LET local_param_list_1 =  local_param_list_1  &  param_delimiter ; END IF ;

let local_param_list_2 = TRIM (local_param_list_2) ; 
IF LEFT (local_param_list_2, 1) <> param_delimiter THEN ; LET local_param_list_2=  param_delimiter & local_param_list_2  ; END IF ;
IF RIGHT (local_param_list_2, 1) <> param_delimiter THEN ; LET local_param_list_2 =  local_param_list_2  &  param_delimiter ; END IF ;

// now with a delimeter surrounding each field the faster INDEX function can be used


let local_list_1_fieldcount = substringcount( local_param_list_1 , param_delimiter ) ;
let local_list_2_fieldcount = substringcount( local_param_list_2 , param_delimiter ) ;
let local_list_1_only = ''; 
let local_list_2_only = '' ;
let local_common_to_both = '' ;

FOR local_list_1_index = 1 to local_list_1_fieldcount
	
	IF INDEX (local_param_list_2, subfield(local_param_list_1, param_delimiter , local_list_1_index) ) = 0 THEN //
		let local_list_1_only = local_list_1_only & subfield(local_param_list_1, param_delimiter , local_list_1_index) & param_delimiter ;
	ELSE 
		let local_common_to_both = local_common_to_both & subfield(local_param_list_1, param_delimiter , local_list_1_index) & param_delimiter ;
	END IF
	
next local_list_1_index ;

FOR local_list_2_index = 1 to local_list_2_fieldcount

	IF INDEX (local_param_list_1, subfield(local_param_list_2, param_delimiter , local_list_2_index) ) = 0 THEN //
		let local_list_2_only = local_list_2_only & subfield(local_param_list_2, param_delimiter , local_list_2_index) & param_delimiter ;
	ELSE 
		//let local_common_to_both = local_common_to_both & subfield(param_list_1, param_delimiter , local_list_1_index) & param_delimiter ;
	END IF
	

next local_list_2_index ;


LET compare_two_delimited_lists.common_to_both_lists = local_common_to_both;
LET compare_two_delimited_lists.list_1_only = local_list_1_only ;
LET compare_two_delimited_lists.list_2_only = local_list_2_only ;

END SUB
//call compare_two_delimited_lists ('A;B;C;' , 'A;B;C', ';' )
//call sub_trace_event('_compare_two_delimited_lists.common_to_both_lists=$(_compare_two_delimited_lists.common_to_both_lists)') ;
//call sub_trace_event('_compare_two_delimited_lists.list_1_only = $(_compare_two_delimited_lists.list_1_only)' ) ;
//call sub_trace_event('_compare_two_delimited_lists.list_2_only= $(_compare_two_delimited_lists.list_2_only)')  ;
// -----------------------------------------------------------------------------------------------------------------------------------------------------------



// ========================================================================================================================

sub store_table_in_qvd (param_table_name, param_qvd_file, param_write_metadata_yn, param_describe_yn  /* local vars */ ) 

	call sub_trace_event ('Procedure [store_table_in_qvd] attempting to store table [$(param_table_name)] in QVD file:$(param_qvd_file)') ;
	
	// check if table exists
	IF $(f_does_table_exist(param_table_name)) <> 'Y' THEN 
		call common.generate_fatal_error ('Procedure [store_table_in_qvd] unable to write table [$(param_table_name)] to QVD since table does not exist') ;
		EXIT SUB ;
	ENDIF
	
	// optionally describe source table and target qvd 
	if UPPER (param_describe_yn) = 'Y' THEN
		call sub_trace_event ('Procedure [store_table_in_qvd] is about to over-write the following QVD:') ;
		call describe_qvd_file (param_qvd_file, 'Y') ;
	END IF
	
	// optionally build metadata (default to doing so)
	IF UPPER (param_write_metadata_yn) = 'Y' THEN
		CALL add_metadata_comment_to_table (param_table_name) ;
	END IF
	
	// STORE QVD
	STORE '$(param_table_name)' INTO '$(param_qvd_file)' (qvd);

	// check if filemodified datetime is different, if not then report error (coould not over-write QVD)	
	// todo

	//call sub_trace_event (add_metadata_comment_to_table.metadata_text) ;

	if UPPER (param_describe_yn) = 'Y' THEN
		call sub_trace_event ('Procedure [store_table_in_qvd] has stored table [$(param_table_name)] in the following QVD:') ;
		call describe_qvd_file (param_qvd_file, 'Y') ;
	END IF

	
END SUB



// ========================================================================================================================


// ========================================================================================================================
// returns global variables and logs most of it to the LOG file
// describe_qvd_file.number_of_rows using QvdNoOfRecords( filename )
// describe_qvd_file.filename using FileName( )
// describe_qvd_file.number_of_fields using QvdNoOfFields( filename )
// describe_qvd_file.file_last_modified using FileTime( [ filename ] )
// describe_qvd_file.file_creation using QvdCreateTime( filename )
// describe_qvd_file.table_name using QvdTableName( filename )
// describe_qvd_file.file_size using FileSize( [ filename ] )
//
// will get fields only if parameter param_get_fields_yn is set to 'Y' (getting fields can take a few seconds and generate alot of LOG output)
// describe_qvd_file.field_names QvdFieldName( filename, field_no)
// describe_qvd_file.field_names_sorted QvdFieldName( filename, field_no)

// todo-get other metadata e.g. distinct value count (see QLIKDEV SAN \SUPPORT\Utilities (official versions)\Get QVD Metadata\Get_QVD_Metadata.qvw for code examples

Sub describe_qvd_file (param_qvd_file, param_optional_get_fields_yn, param_optional_identifier, /* local variables */ local_field_name, local_field_index, local_field_names, local_filename, local_qvd_number_of_records, local_qvd_datetime, local_filesize, local_qvd_table_name, local_qvd_number_of_fields )

// param_optional_identifier  if this is set, its used to add an identifier to the global variables returned to help the calling code separate different variabales for each QVD. optional and not expected to be used often
IF IsNull(param_optional_identifier) 	THEN ; let param_optional_identifier=''; END IF;
IF IsNull(param_optional_get_fields_yn) THEN ; let param_optional_get_fields_yn=''; END IF;


let describe_qvd_file.number_of_rows=;
let describe_qvd_file.filename=;
//let describe_qvd_file.file_last_modified=; // no need
let describe_qvd_file.file_creation =;
let describe_qvd_file.file_size =;
let describe_qvd_file.table_name =;
let describe_qvd_file.number_of_fields=;
let describe_qvd_file.field_names =;
let describe_qvd_file.field_names_sorted=;


IF $(f_does_file_exist(param_qvd_file)) = 'Y' THEN

	let describe_qvd_file.number_of_rows 	= num (QvdNoOfRecords( '$(param_qvd_file)' ), '###,###,###,###');
	let describe_qvd_file.file_creation 	= QvdCreateTime( '$(param_qvd_file)' );
	let describe_qvd_file.file_size 		= num ( FileSize(param_qvd_file), '###,###,###,###') ;
	let describe_qvd_file.table_name 		= QvdTableName( '$(param_qvd_file)' ) ;
	let describe_qvd_file.number_of_fields 	= QvdNoOfFields( '$(param_qvd_file)' ) ;
	
	let describe_qvd_file.filename = $(f_get_just_the_filename(param_qvd_file));
	
	call sub_trace_event ('-------------------------------------------------------------------------------------------------------') ;
	call sub_trace_event ('') ;
	call sub_trace_event ('QVD      : $(describe_qvd_file.filename)') ;
	call sub_trace_event ('') ;
	call sub_trace_event ('QVD contains [table=$(describe_qvd_file.table_name)]  [fields=$(describe_qvd_file.number_of_fields)]  [rows=$(describe_qvd_file.number_of_rows)]  [Creation=$(describe_qvd_file.file_creation)] [size=$(describe_qvd_file.file_size) bytes]  file=$(param_qvd_file)' ) ;
		
	if UPPER (param_optional_get_fields_yn) = 'Y' THEN ; // just output field names all the time
		call get_qvd_field_names(param_qvd_file, 'Y') ; // get fields and sort by default
		let describe_qvd_file.field_names 			= get_qvd_field_names.field_names ;
		let describe_qvd_file.field_names_sorted 	= get_qvd_field_names.field_names_sorted;
		//call sub_trace_event ('                Fields in QVD:' & describe_qvd_file.field_names ) ;
		call sub_trace_event ('Field names:') ;
		FOR local_field_index = 1 to describe_qvd_file.number_of_fields ;
		
			LET local_field_name = SUBFIELD (describe_qvd_file.field_names, ';', local_field_index) ;
			
			//call sub_trace_event ('            ' & local_field_name) ; // DELETED
			call sub_trace_event ($(f_return_fixed_length_number(local_field_index, 10)) & '  ' & local_field_name) ; // added
			
			
		NEXT local_field_index ;
		
		call sub_trace_event ('-------------------------------------------------------------------------------------------------------') ;
		
	END IF;
	

ELSE
	
	call generate_warning ('Procedure [describe_qvd_file] QVD file doesnt exist [$(param_qvd_file)]' ) ;
	
END IF 
	

end sub



// specific (simple) routine to log attempt to DROP etc and provide guaranteed error detection

SUB drop_table ( param_table_name ) 

	if $(f_does_table_exist(param_table_name)) = 'Y' then
		call sub_trace_event ('Dropping table [$(param_table_name)]') ;
		DROP TABLE '$(param_table_name)' ; // <<< Changed in SP10 by SOIO to add quotes
		IF $(f_does_table_exist(param_table_name)) = 'Y' THEN
			call common.generate_fatal_error ('Procedure [drop_table] was unable to drop table [$(param_table_name)]') ;
		END IF ;
	else
		call common.generate_fatal_error ('Procedure [drop_table] was passed invalid table name [$(param_table_name)]') ;
	end if ;	

END SUB ;

//SUB common.drop_table_no_log ( param_table_name ) 
//
//	if $(f_does_table_exist(param_table_name)) = 'Y' then
//		//call sub_trace_event ('Dropping table [$(param_table_name)]') ;
//		DROP TABLE '$(param_table_name)' ; // <<< Changed in SP10 by SOIO to add quotes
//		IF $(f_does_table_exist(param_table_name)) = 'Y' THEN
//			call common.generate_fatal_error ('Procedure [drop_table] was unable to drop table [$(param_table_name)]') ;
//		END IF ;
//	else
//		call common.generate_fatal_error ('Procedure [drop_table] was passed invalid table name [$(param_table_name)]') ;
//	end if ;	
//
//END SUB

// ========================================================================================================================

SUB drop_all_tables ;
	
	Let  drop_all_tables.j = NoOfTables();
	
	Do while drop_all_tables.j > 0
		let drop_all_tables.d = TableName(0);
		//Drop Table $(drop_all_tables.d);
		CALL drop_table (drop_all_tables.d) ;
		let drop_all_tables.j = NoOfTables();
	loop

END SUB ;


// ========================================================================================================================
// Procedure helps with troubleshooting by reducing the places that DROP TABLE(S) statements are added or commented out in a script
// Calling it and passing the table nameSs of interest will leave that table intact so that visualizations and model viewer (CTRL-T) are focused on that table
// All parameters and comparisons are case sensitive
// TECHNICAL NOTE : demonstrates building an array using a delimited string and then using FOR EACH to traverse that array

// todo- allow a list of table names to be passed


// =======================================================================================================================================

// =======================================================================================================================================










// =======================================================================================================================================


SUB get_datetime

	LET log_datetime.now = now (1) ;
	
	let log_datetime.now = timestamp (log_datetime.now , 'YYYY-MM-DD hh:mm:ss') ;
	
END SUB

// =======================================================================================================================================
SUB log_datetime  ;
	
	call get_datetime ;
	
	call sub_trace_event ('LOG datetime: $(log_datetime.now)   (no millionths of a seconds value is available)') ; 

end sub ;
// =======================================================================================================================================

sub generate_warning_dialog (param_message)


//	IF $(f_is_qvw_running_in_publisher()) = TRUE THEN // DELETED - the missing paranthesis was causing "TRUE" to be considered a variable name and not function
	IF $(f_is_qvw_running_in_publisher()) = TRUE() THEN // ADDED - added parenthesis
	
		call generate_warning ('Procedure [generate_warning_dialog] was called but function [f_is_qvw_running_in_publisher] determined that the script is running in Publisher therefore will not show a MSGBOX') ;
	
	ELSE
	
		call generate_warning ('Procedure [generate_warning_dialog] called with message : ' & param_message) ; 
		
		generate_warning_dialog_table:
		Load MsgBox('$(param_message)', 'WARNING', 'OK', 'ICONASTERISK') as generate_warning_dialog.field autogenerate 1; 
		// don't care about the response
		DROP TABLE generate_warning_dialog_table ;
		// TODO -USE - CALL DROP_TABLE ('generate_warning_dialog_table') ;
		
	END IF ;

END SUB ;

// =======================================================================================================================================

// RETURNS generate_YESNO_dialog.response
sub generate_YESNO_dialog (param_message)


	IF $(f_is_qvw_running_in_publisher()) = TRUE THEN
	
		call generate_warning ('Procedure [generate_warning_dialog] was called but function [f_is_qvw_running_in_publisher] determined that the script is running in Publisher therefore will not show a MSGBOX') ;
	ELSE 
		
		generate_YESNO_dialog_table:
		Load MsgBox('$(param_message)', 'ICONQUESTION', 'YESNO', 'ICONASTERISK') as generate_YESNO_dialog.field autogenerate 1; 
		// don't care about the response
		LET generate_YESNO_dialog.field = PEEK ('generate_YESNO_dialog.field',0, 'generate_YESNO_dialog_table') ;
		LET generate_YESNO_dialog.response = IF (generate_YESNO_dialog.field = 6, 'YES', 'NO') ;
		DROP TABLE generate_YESNO_dialog_table ;
		
	END IF ;

END SUB ;


// =======================================================================================================================================


// =======================================================================================================================================
// accepts date in central and returns GMT date, datetime and offset value as per QVW and the Operating System

sub calculate_gmt_datetime (param_date_central, calculate_gmt_datetime.return_param_date_gmt, calculate_gmt_datetime.return_param_datetime_gmt, calculate_gmt_datetime.return_param_offset  /* local vars */ ,local.v_DATE_CENTRAL, local.v_DATETIME_CENTRAL, local.v_DATETIME_CENTRAL_TEMP, local.v_DATETIME_GMT_TEMP, local.v_DATETIME_DIFFERENCE, local.v_DATETIME_GMT, local.v_DATE_GMT, local.v_DATE_CENTRAL  ) 

	// Set the value below for a different datetime in Central time zone
	let local.v_DATE_CENTRAL      =  Date( param_date_central, 'YYYY-MM-DD') ; 
	let local.v_DATETIME_CENTRAL  =  Date( local.v_DATE_CENTRAL, 'YYYY-MM-DD') & '-23.59.59.999999'; 
	
	// then ajust it to a QVW compatible datetime format for timezone work and store in original name variable
	// DB2 accepts more datetime formats than QVW does hence the conversion.
	let local.v_DATETIME_CENTRAL = timestamp#( local.v_DATETIME_CENTRAL, 'YYYY-MM-DD-hh.mm.ss.ffffff' ) ;
	
	// then covert to central (using timezone adjustment info from QVW and OS)     
	let local.v_DATETIME_CENTRAL_TEMP = ConvertToLocalTime(local.v_DATETIME_CENTRAL, 'Central Time (US & Canada)', TRUE() ) ; 
	let local.v_DATETIME_GMT_TEMP     = ConvertToLocalTime(local.v_DATETIME_CENTRAL, 'GMT',                        TRUE() ) ; 
	
	// then get difference in timezone for that particular day, in hours
	let local.v_DATETIME_DIFFERENCE = num# (INTERVAL (local.v_DATETIME_GMT_TEMP - local.v_DATETIME_CENTRAL_TEMP,  'hh')) ; 
	
	//  then calculate GMT time
	LET local.v_DATETIME_GMT  = local.v_DATETIME_GMT_TEMP + MakeTime (local.v_DATETIME_DIFFERENCE) ;
	
	// then we need to covert back to the format that we had been using with DB2
	let local.v_DATETIME_GMT  = TimeStamp( local.v_DATETIME_GMT, 'YYYY-MM-DD-hh.mm.ss.fff') ;
	
	// we need to add back the missing millionths of a second since DB2 has 6 but QVW only allows 3 (they wont change with timezone)
	let local.v_DATETIME_GMT = local.v_DATETIME_GMT & '999' ;
	
	// YES THERE IS PROBABLY A SAFER WAY OF REMOVING TIMEPART BUT THE FORMAT OF THE DATETIME ISNT QVW COMPATIBLE BY THIS POINT (IT IS SUITABLE FOR DB2 THOUGH)
	// WE ONLY USE STRING VALUE OF THIS VARIABLE (AND NOT NUMERIC) SO THE WEIRD TRUNCATION BELOW ISNT AN ISSUE
	LET local.v_DATE_GMT     = left (local.v_DATETIME_GMT, 10) ;
	LET local.v_DATE_CENTRAL = left (local.v_DATETIME_CENTRAL, 10) ;
	

	// these are the vvalue
	let calculate_gmt_datetime.return_param_datetime_gmt        = local.v_DATETIME_GMT ; 
	let calculate_gmt_datetime.return_param_date_gmt            = local.v_DATE_GMT ; 
	let calculate_gmt_datetime.return_param_offset 				= local.v_DATETIME_DIFFERENCE ;

END SUB ;

// =======================================================================================================================================


// =======================================================================================================================================
// replace table named as per 'param_original_table_name' with table named as per 'param_temporary_table_name'
// typical use is purge or sort logic where a temp table has some or all of original table's contents and then the temp table needs to take the place of the original table
// and then the original table is dropped

SUB replace_table (param_original_table_name, param_temporary_table_name) 
	
	call drop_table 	(param_original_table_name) ;
	call rename_table 	(param_temporary_table_name, param_original_table_name) ;
	

END SUB ;
// =======================================================================================================================================
// =======================================================================================================================================


SUB describe_environment

	LET describe_environment.v_CR = '  ' ;

	let describe_environment.description = 
	'** Auto generated metadata **' & describe_environment.v_CR & 
	'Timestamp      [' & Now() & ']  ' & describe_environment.v_CR &
	''  & describe_environment.v_CR &
	'[OS user =' & OSuser() & ']  ' & describe_environment.v_CR  &
	'[QVW user =' & QVuser() & ']  ' & describe_environment.v_CR &
	'[QVW version =' & QlikViewVersion() & ']  ' & describe_environment.v_CR   &
	'[Computer name =' & ComputerName() & ']  ' & describe_environment.v_CR &
	'[QVW document =' & DocumentName() & ']  ' & describe_environment.v_CR &
	'[QVW file time =' & FileTime ( DocumentPath() ) & ' (upon QVW opening)' & ']  ' & describe_environment.v_CR &
	'[QVW file size =' & FileSize ( DocumentPath() ) & ' bytes (upon QVW opening)' & ']  ' & describe_environment.v_CR &
	'[QVW path =' & Replace (DocumentPath(), '\', '/') & ']  ' & describe_environment.v_CR  & // have to replace all '\' since they can upset the LOG file for some reason
	'[QVW title =' & DocumentTitle() & ']  ' & describe_environment.v_CR &
	'[Last DB connect =' & ConnectString() & ']  ' & describe_environment.v_CR &
	'[Reload Datetime=' & ReloadTime( ) & ']  '  & describe_environment.v_CR &
	;

	call sub_trace_event ( REPLACE (describe_environment.description, v_CR, ' ') ) ;
	
	
END SUB 


// =======================================================================================================================================
// Similar to drop_table but doesnt care if table exists or not. It wont error out.
// THIS IS A PROCEDURE THAT SHO-ULD BE USED WITH CAUTION. IF A TABLE EXISTS UNEXPECTEDLY THEN IT USUALLY MEANS THERE IS A BUG OR A BAD DESIGN
SUB drop_table_if_exists (param_table_name) ;

	call sub_trace_event ('Procedure [drop_table_if_exists] passed parameter [param_table_name] with value of [$(param_table_name)])') ;

	if $(f_does_table_exist(param_table_name)) = 'Y' THEN ; DROP TABLE $(param_table_name); END IF ;
	
END SUB ;

// ==========================================================================================================================================
/*
Since QVW wont allow you to see the data model as the script progresses with ending script, this procedure will output all or select in memory tables to specific folder 
naming each file after the table it represents. Then a file viewer utility E.G. QVW can look at the files and essentially see the data model as it progresses

TODO:
Adjust for trailing '\ in folder. 
Detect bad folder name.
Detect potentially bad filenames based on table names
Detect if table names have spaces. Procedure wotn work with those
Adjust trailing comma - done

TODO - THIS IS A DEBUG PROCEDURE WHICH MEANS IT WILL DO NOTHING IF THE DEBUG FILE "" DOES NOT EXIST IN THE SAME FOLDER AS THE HOST QVW
examples
CALL DEBUG.output_tables_to_files ('*ALL*', '..\QVD\SUPPORT', 'QVD')
CALL DEBUG.output_tables_to_files ('TABLENAME1,TABLENAME2', '..\QVD\SUPPORT', 'TXT') 

*/
sub DEBUG.output_tables_to_files (param_comma_list_of_table_names, param_output_folder, param_output_format /* optional */ , param_breakpoint_step_identifier_text /* local vars */, local_comma_list_of_table_names, local_bad_table_name_indicator, local_table_name_index) ;

	IF GLOBAL.DEBUG_MODE_INDICATOR_YN = 'Y' THEN ;
		call sub_trace_event ('Procedure [DEBUG.output_tables_to_files] with tables [$(param_comma_list_of_table_names)] folder [$(param_output_folder)] and format [$(param_output_format)]') ;
		
		LET CONSTANT_SINGLE_QUOTE = CHR(39)  ;
		
		LET param_output_format = TRIM (UPPER (param_output_format) ) ;
		LET local_bad_table_name_indicator = 'N' ;
		
		// todo - check if empty etc
		// remove all saocec
		 
		let local_comma_list_of_table_names = trim (param_comma_list_of_table_names) ;
		IF UPPER (local_comma_list_of_table_names) = '*ALL*' THEN ;
		
			FOR v_index = 0 to NoOfTables()-1 ;
			
				let local_table_name_index = TableName(v_index) ;
				
				STORE '$(local_table_name_index)' into '$(param_output_folder)\$(param_breakpoint_step_identifier_text)$(local_table_name_index).$(param_output_format)' ($(param_output_format)) ;
	
			next v_index ;
		ELSE
			
			let local_comma_list_of_table_names	= TRIM (param_comma_list_of_table_names) ;
			let local_comma_list_of_table_names = ',' & REPLACE (trim (local_comma_list_of_table_names), ' ', '') ;
			if right (local_comma_list_of_table_names,1) <> ',' then ; let local_comma_list_of_table_names = local_comma_list_of_table_names & ','; end if ; 
			let local_comma_list_of_table_names = REPLACE (local_comma_list_of_table_names, ',', CONSTANT_SINGLE_QUOTE& ',' & CONSTANT_SINGLE_QUOTE ) ;
			let local_comma_list_of_table_names = LEFT (local_comma_list_of_table_names, Len (local_comma_list_of_table_names) -2 ) ;
			let local_comma_list_of_table_names = RIGHT (local_comma_list_of_table_names, Len (local_comma_list_of_table_names) -2 ) ;
			
			// by this point the table names will be surrounded by single quotes
			
			FOR Each local_table_name_index in $(local_comma_list_of_table_names) ;
			
				if $(f_does_table_exist(local_table_name_index)) = 'Y' THEN ;
					STORE '$(local_table_name_index)' into '$(param_output_folder)\$(param_breakpoint_step_identifier_text)$(local_table_name_index).$(param_output_format)' ($(param_output_format)) ;
				ELSE
					call generate_warning ('Table name [$(local_table_name_index)] does not exist in model and cannot be stored as file in procedure [DEBUG.output_tables_to_files]') ;
					LET local_bad_table_name_indicator = 'Y' ;
				END IF;	
				
			NEXT
		
		end if ;
		
		// 
	
		if local_bad_table_name_indicator = 'Y' THEN ;
			call generate_warning ('Procedure [DEBUG.output_tables_to_files] was passed at least one non-existent table name. To help with troubleshooting all tables will be described below') ;
			call describe_all_tables ;
		END IF ;
	
		call sub_trace_event ('End of procedure [output_tables_to_files]') ;
		
	END IF ; // not in debug mode so dont output anything
	
end sub; // output_tables


// =======================================================================================================================================

sub log_new_code_section (optional_param_tab_name) ;

	// todo this procedure [] will be deprecated meanwhile it will be directed to [log_start_code_section]
	call log_start_code_section (optional_param_tab_name) ;
//
//LET optional_param_tab_name = IF (ISNULL (optional_param_tab_name), '',  TRIM (UPPER(optional_param_tab_name))) ;
//
//	call sub_trace_event ('') ;
//	call sub_trace_event ('=======================================================================================================================================') ;
//	call sub_trace_event ('') ;
//	call sub_trace_event (REPEAT (' ', 20) & IF (optional_param_tab_name='', '>>>> NEW SCRIPT CODE SECTION <<<<', '>>>> [ $(optional_param_tab_name) ] <<<<')  ) ;
//	call sub_trace_event ('') ;
//	call sub_trace_event ('=======================================================================================================================================') ;
//
END SUB  ;
//

// =======================================================================================================================================
sub log_start_code_section (optional_message /* local vars */ , local_len_message, local_formatted_message, local_width, local_text_line, local_padding_len) ;

	// todo - will also number the sections (in case we want to tie debuggging to section numbers)
	// todo - remember the previous section so a lOG entry for END OF SECTION [something] can be written
	// todo - increase log indentation
	
	LET local_width = 120 ;
	LET local_text_line = REPEAT ( '*', local_width ) ;

	CALL sub_trace_event ('') ;	
	CALL sub_trace_event (local_text_line) ;
	CALL sub_trace_event ('*') ;
	
	IF ISNULL (optional_message) THEN ; LET local_formatted_message = '' ; ELSE ; LET local_formatted_message = optional_message ; END IF ;
	LET local_formatted_message = 'START OF CODE SECTION [' & local_formatted_message & ']' ;
	LET local_len_message 			= LEN (local_formatted_message) ;
	LET local_padding_len 			=  FLOOR ((local_width/2)-(local_len_message/2)) ;
	LET local_formatted_message		= '*' & REPEAT ( ' ', local_padding_len ) & local_formatted_message ;
	LET local_len_message 			= LEN (local_formatted_message) ;
	//TRACE $(local_len_message);
	//& local_formatted_message ;
	CALL sub_trace_event (local_formatted_message) ;

	CALL sub_trace_event ('*') ;
	CALL sub_trace_event (local_text_line) ;
	CALL sub_trace_event ('') ;
		
end sub ; // log_start_code_section 

// =======================================================================================================================================

// ============================= ===========================================================================================================================================================================================================

sub describe_table (param_table_name, param_fields_output_yn, local_field_index, local_number_of_rows, local_number_of_fields, local_number_of_tables, local_table_number, local_field_name, local_field_value_count, local_len_field_name)

//trace Call to SUB [describe_table] with parameter [param_table_name] of value [$(param_table_name)] ;

	if $(f_does_table_exist(param_table_name)) <> 'Y' then
	
		call generate_error ('Procedure [describe_table] has been passed an invalid table name [$(param_table_name)]') ;
		EXIT SUB ;
		 
	ELSE
	
		let local_number_of_rows 		= NoOfRows('$(param_table_name)') ; LET describe_table.number_of_rows = local_number_of_rows ;
		let local_number_of_fields 		= NoOfFields('$(param_table_name)') ; LET describe_table.number_of_fields = local_number_of_fields ;
		let local_table_number 			= 1+TableNumber('$(param_table_name)') ; LET describe_table.table_number_in_memory = local_table_number ;
		let local_number_of_tables 		= NoOfTables() ;LET describe_table.number_of_tables = local_number_of_tables ;
		
		//call sub_trace_event ('Procedure [describe_table]  Table [$(param_table_name)]  Rows ['& num (v_temp_a, '###,###,###,###') & ']  Fields [$(v_temp_b)]  Table Number [$(v_temp_c)] of [$(v_temp_d)] in the script so far') ;
		//call sub_trace_event ('') ;
		call sub_trace_event ('Describe table [$(param_table_name)] contains [rows='& num (local_number_of_rows, '###,###,###,###') & ']  [fields=$(local_number_of_fields)]  [table $(local_table_number) of $(local_number_of_tables)]') ;
		call sub_trace_event ('') ; // force a blank line

		
		if UPPER(param_fields_output_yn) = 'Y' then
			
			call sub_trace_event ('          Num        Count   Field Name') ; // force a blank line					
			call get_table_field_names(param_table_name, 'N') ;
			//call sub_trace_event ('       Fields: ' & get_table_field_names.field_names) ;
			LET describe_table.field_names = get_table_field_names.field_names ;
			FOR local_field_index = 1 to local_number_of_fields STEP 1 ;
				
				LET local_field_name 			= SUBFIELD (describe_table.field_names, V_DELIMITER_SEMICOLON, local_field_index) ; LET local_len_field_name = LEN(local_field_name) ;
				LET local_field_value_count 	= FieldValueCount (local_field_name) ;
				
				//$(f_return_fixed_length_number(1234, 10))
				call sub_trace_event ('        ' & NUM(local_field_index, '000') & ' : ' & $(f_return_fixed_length_number(local_field_value_count,10)) & ' : ' & local_field_name ) ;// & REPEAT (' ', 40- local_len_field_name) & '$(local_field_value_count)') ;
				
			NEXT local_field_index;
		
		
			// TODO - use [is_field_name_unique_to_table] to help avoid this message if not necessary to display it 
			if local_number_of_tables > 1 AND UPPER(param_fields_output_yn) = 'Y' THEN ;
				call sub_trace_event ('  "Count" represents the distinct value count for the field across the complete data model at this point in the QVW and not solely within the table listed') ; // force a blank line
			END IF ;
			
			
		ENDIF ;
		
			
		call sub_trace_event (''); 
		
		call if_tablename_has_potential_duplicate_in_model(param_table_name) ; // check for bad ones
		
	end if ;

end sub 

// an alias to [describe_table] 
sub common.describe_table (param_table_name, param_fields_output_yn) ;

	call describe_table (param_table_name, param_fields_output_yn) ; 
	
END SUB ;
// ============================= ===========================================================================================================================================================================================================

// used to detect if a table name has a *potential* duplicate in the data model as denoted by having a similarly named table but with "-NNN" suffixes e.g. "table_name" vs "table_name-1"
SUB if_tablename_has_potential_duplicate_in_model (param_table_name /* local vars */, local_table_index, local_table_name, local_table_name_length) ;

	IF $(f_does_table_exist(param_table_name)) = 'Y' THEN ;
	
		LET local_table_name_length 	= LEN (param_table_name);
			
			
		FOR local_table_index = 1 to NoOfTables() ;
		
			LET local_table_name 			= TableName (local_table_index) ;
				
			IF LEFT (local_table_name, local_table_name_length) = param_table_name and MID (local_table_name,local_table_name_length+1, 1) = '-' then ;
			
				call generate_warning ('Table named [$(param_table_name)] may have a duplicate or badly named table [$(local_table_name)] in memory caused by a design or coding error. It may also be as expected. Tables named identically to one another but with "-NN" where NN is a series of numeric digits are usually caused by attempting to create a table that has the same name as an existing table. A missed DROP or RENAME command may be the cause') ;
				LET if_tablename_has_potential_duplicate_in_model.response = 'Y' ;
			ELSE
				LET if_tablename_has_potential_duplicate_in_model.response = 'N' ;
			END IF  ;
			
		NEXT local_table_index ;
	ELSE
	
		call generate_error ('Procedure [if_tablename_has_potential_duplicate_in_model] was passed an non-existent table name [$(param_table_name)]. Please check LOG and code') ;
		LET if_tablename_has_potential_duplicate_in_model.response = 'BAD TABLE NAME';
		
	END IF ;
	

END SUB ;

//// ============================= ===========================================================================================================================================================================================================
////TODO - UPDATE THIS WITH NEW CODE
//// will not put NULL values into [param_destination_table_name] if fast method is used. this is caused by FieldValueCount and FieldValue functions not returning or counting nulls
//// TODO -DECide if slow method also slips nulls 
//// You cannot use  [source field name AS another_name] in the fast method LOAD statement. weird things happen. You could rename after LOAD RESIDENT field AS field
//// if param_source_table_name is empty ('') or missing (NULL) then the field across the whole model will be used 
//
//
//// todo- handle not passing a source table name and returning all distinct values across the data model
//
//
///*
//param_source_field_name - field name containing values you would like a distinct list from
//param_source_table_name - table hosting that field name. the field name must be unique to that table and cannot exist on another table
//param_destination_table_name - table you'd like to create to hold those distinct values. this table cannot exist in data model when this procedure is called.
//
//
//*/
//SUB get_fast_distinct_list_of_field_values (param_source_field_name, param_source_table_name, param_destination_table_name /* local vars */, local_is_param_source_table_name_empty, local_is_field_name_unique_to_source_table) 
//
//
//LET get_fast_distinct_list_of_field_values.response='OK' ;
//
//	call sub_trace_event ('SUB/FUNCTION [get_fast_distinct_list_of_field_values]') ;
//	
//	call output_variable_values ('param_source_field_name,param_source_table_name,param_destination_table_name') ;
//	
//	
//	IF $(f_does_table_exist(param_destination_table_name)) <> 'Y' THEN  ; // only if destination table does NOT exist can we continue
//
//		
//		IF TRIM (param_source_table_name) = '' OR ISNULL (param_source_table_name) THEN ; // is empty, then error
//			
//			call generate_error ('Procedure [get_fast_distinct_list_of_field_values] was passed an empty value in parameter [param_source_table_name]') ;
//			LET get_fast_distinct_list_of_field_values.response = 'ERROR' ;
//			
//		ELSE 
//
//			CALL is_field_name_unique_to_table (param_source_table_name, param_source_field_name ) ;
//	
//			IF _is_field_name_unique_to_table = 'Y' THEN ; // if its unique, then use fast code
//		
//				$(param_destination_table_name):
//				NoConcatenate
//				Load 
//					FieldValue('$(param_source_field_name)',IterNo() ) as $(param_source_field_name)//$(param_destination_field_name)
//				AutoGenerate 
//					(1)
//				While not Isnull( FieldValue( '$(param_source_field_name)',IterNo() ) )
//				;
//			ELSE
//				call generate_error ('Procedure [get_fast_distinct_list_of_field_values] was passed a field name [$(param_source_field_name)] which is not unique to table [$param_source_table_name)]. This version of the procedure cannot return a distinct list of values using the fast method of detection.') ;
//				LET get_fast_distinct_list_of_field_values.response = 'ERROR' ;
//			END IF ;
//		
//		END IF ;
//
//	ELSE // if destination table exists then we cant use it and over-write it
//	
//		call generate_error ('Procedure [get_fast_distinct_list_of_field_values] was asked to create a table [$(param_destination_table_name)] that already exists.') ;
//		LET get_fast_distinct_list_of_field_values.response = 'ERROR' ;
//		
//	END IF ;
//	
//	
//END SUB // get_fast_distinct_list_of_field_values
//



/*
1st parameter: name of QVD that new empty QVD will be based on
2nd parameter : new QVD path\filename (can be same as 1st parameter
3rd parameter : if 'Y' then QVD will be generated, else wont STORE QVD file but will prepare it in memory. latter used during development and debugging
*/
SUB  store_an_empty_version_of_qvd (source_qvd_file, destination_qvd_file, param_store_qvd_files /* local vars */ , local_field_names ) ;

	// todo - error check destination file/folder?

	if $(f_does_file_exist(source_qvd_file)) = 'Y' THEN  ;

		call describe_qvd_file (source_qvd_file) ;
		call get_qvd_field_names (source_qvd_file) 

		let local_field_names 	= left (get_qvd_field_names.field_names, len (get_qvd_field_names.field_names)-1) ; // remove trailing semi-colon
		let local_field_names 	= replace(local_field_names,';',','); // need commas for field lists
	
		$(describe_qvd_file.table_name):
		NOCONCATENATE LOAD * INLINE [
		$(local_field_names)
		] ;
		
		if UPPER(param_store_qvd_files) = 'Y' THEN ; 
		
			call store_table_in_qvd (describe_qvd_file.table_name, destination_qvd_file ) ;
			CALL describe_qvd_file (destination_qvd_file );
			
			call drop_table (describe_qvd_file.table_name) ;
			
		else
		
			call generate_warning ('QVDs are not being stored by procedure [store_an_empty_version_of_qvd] since parameter [param_store_qvd_files] is set to [$(param_store_qvd_files)]') ; 
		
		end if;
	
	ELSE
	
		CALL common.generate_fatal_error ('Procedure [store_an_empty_version_of_qvd] has been passed an invalid file in parameter [source_qvd_file]. It has a value of: $(source_qvd_file)') ;
	
	end if ;
	
END SUB ;





// This procedure should be called when any file needs to have its metadata output in the QVW LOG file e.g. TXT files that you want to INCLUDE, XLS files for data, etc
// use SUB describe_qvd_file instead when wanting metadata for a QVD file since more information is available for a QVD file
//
SUB common_functions.describe_file (param_file ) ;

	if $(f_does_file_exist('$(param_file)')) = 'Y' THEN ;
	
		
		call sub_trace_event ('') ;
		call sub_trace_event ('SUB [common_functions.describe_any_file] showing details of file below:') ;
		let describe_file.filename 	= $(f_get_just_the_filename('$(param_file)')) ;
		
		let describe_file.folder 	= $(f_get_just_the_folder('$(param_file)')) ;
		
		let describe_file.modified = FileTime ( param_file) ;

		LET describe_file.size =	 FileSize ( param_file ) & 'bytes' &  ' '  & FLOOR (FileSize ( param_file )/1024) & 'K ' & FLOOR (FileSize ( param_file )/1024/1024) & 'M ' & FLOOR (FileSize ( param_file )/1024/1024/1024) & 'G';
		
		call output_variable_values ('describe_file.filename,describe_file.folder,describe_file.modified,describe_file.size') ; 
		
	ELSE
		call generate_error ('SUB [common_functions.describe_file] was passed an invalid file or path : $(param_file)') ;
		// do not end the script since its likely this SUB is only for self documentation purposes
			
	END IF ;
	

END SUB ;

// AN ALIAS FOR [common_functions.describe_file]
SUB common.describe_file (param_file ) ;
	CALL common_functions.describe_file (param_file ) ;
END SUB ;



// =======================================================================================================================================
// =======================================================================================================================================
// =======================================================================================================================================

// comma delimited list of variables named to output to LOG file


LET common.output_variable_values.running_variable_list = '' ;  //added sp10.6 will keep running tally of variables that have been output
sub output_variable_values (param_variable_list, /* LOCAL VARS */ v_local_CR, local_output_complete_text, local_output_text, local_variable_list, local_variable_index, local_list_delimiter, local_number_of_variables, local_variable_name, local_variable_value, local_max_length, local_formatting_spaces)


	let local_max_length=0;
	let local_output_complete_text= ''; // emppty to start with
	
	//call sub_trace_event ('Procedure [output_variable_values] outputs the value of variables shown below. Semi-colons will be replaced with commas to avoid formatting issues in the QVW TRACE command') ;
	let local_list_delimiter=',' ;
				
	let local_variable_list = TRIM (param_variable_list) ;
	IF RIGHT (local_variable_list, 1) <> local_list_delimiter THEN ; LET local_variable_list = local_variable_list & local_list_delimiter; END IF;
	
	let local_number_of_variables = substringcount ( local_variable_list, local_list_delimiter) ;

	//call sort_delimited_list (local_variable_list, ',') ; // todo-remove this and check still works
	//LET local_variable_list = sort_delimited_list.sorted_list ;
			
	// analyze variable name lengths first
	FOR local_variable_index = 1 to local_number_of_variables step 1 
	
		//TRACE local_variable_index=$(local_variable_index) ;
		let local_variable_name = TRIM (SubField (local_variable_list, local_list_delimiter, local_variable_index)) ; //ADDED TRIM 12/27 since spaces were killing me
		IF LEN (local_variable_name) > local_max_length THEN ;
			LET local_max_length  = LEN (local_variable_name) ;
		END IF ;
	NEXT local_variable_index ;
	
	FOR local_variable_index = 1 to local_number_of_variables step 1 
	
		//TRACE local_variable_index=$(local_variable_index) ;
		let local_variable_name = TRIM (SubField (local_variable_list, local_list_delimiter, local_variable_index)) ;
		let local_variable_value = '$' & '(' & local_variable_name & ')' ;
		let local_variable_value = local_variable_value ;
		
		//let local_variable_value = $(local_variable_value) ;
		
		LET local_formatting_spaces = repeat( ' ',  local_max_length - LEN (local_variable_name) ) ;
		LET local_output_text = '    Variable [' & local_variable_name & local_formatting_spaces & '] has value [$(local_variable_value)' & ']' ;
		call sub_trace_event (local_output_text) ;
		
		LET local_output_complete_text = local_output_complete_text & local_output_text ;
		
	
	NEXT local_variable_index ;


	call sub_trace_event ('') ;    

	LET common.output_variable_values.running_variable_list = common.output_variable_values.running_variable_list & local_variable_list ; //added sp10.6 will keep running tally of variables that have been output

LET QVW_ECS_COMMON_FUNCTIONS.output_variable_values.complete_output_text = local_output_complete_text; // supply the complete text output in case calling routine needs it

end sub ;


SUB common.output_single_horizontal_line ;

	CALL SUB_TRACE_EVENT (REPEAT ('-', 120)) ;
	

END SUB ;

SUB common.output_double_horizontal_line ;

	CALL SUB_TRACE_EVENT (REPEAT ('=', 120)) ;

END SUB ;


SUB commmon.output_all_variables ;

	CALL sort_delimited_list (common.output_variable_values.running_variable_list, ',', 'Y') ;

	call SUB_TRACE_EVENT ('') ;
	call common.output_double_horizontal_line ;
	call SUB_TRACE_EVENT ('The following variables were of interest in the script so far (as per CALL to SUB OUTPUT_VARIABLE_VALUES code)') ;
	call SUB_TRACE_EVENT ('') ;
	
	
	
	CALL OUTPUT_VARIABLE_VALUES (sort_delimited_list.sorted_list) ;

	CALL common.output_single_horizontal_line ;
	call SUB_TRACE_EVENT ('') ;
	
	
END SUB ;


// SUB create_empty_table_in_memory_from_qvd (param_qvd_file, param_table_name /* local vars */ ,local_v_field_names ) ;
//
//
//
//

SUB common.create_empty_table_in_memory_from_qvd (param_qvd_file, param_table_name /* local vars */ ,local_v_field_names ) ;


	// TODO-CHECK IF QVD FILE EXISTS OR NOT
	// todo -handle field names which have spaces
	
	
	call get_qvd_field_names (param_qvd_file)  ;
	
	let local_v_field_names = left (get_qvd_field_names.field_names, len (get_qvd_field_names.field_names)-1) ; // remove trailing semi-colon
	let local_v_field_names = replace(local_v_field_names,';',','); // need commas for field lists
					
		
	$(param_table_name):
	NOCONCATENATE LOAD * INLINE [
	$(local_v_field_names)
	] 
	;
				

END SUB ;


// SUB common.generate_fatal_error (param_error_text) ;
//
//

SUB common.generate_fatal_error (param_error_text) ;

	call generate_error (param_error_text) ;
	
	common.generate_fatal_error:
	NOCONCATENATE
	LOAD * 
	FROM
	[.\FATAL_ERROR_THIS_FILE_WILL_NOT_EXIST_AND_QVW_WILL_ERROR_OUT_PLEASE_SEE_QVW_LOG_FOR_MORE_INFORMATION.TXT]
	(txt)
	;
	
	EXIT SCRIPT;
	

END SUB ;



sub GET_INCLUDES_PATH_FROM_vDataDir ;


END SUB ;
// GET_INCLUDES_PATH_FROM_vDataDir ;

/*
Variable "vDataDir" is assumed to be global to all our apps and code should exist and indicate where the "\QVD" folder is located

If 
	supplied with a parameter denoting the path to the INCLUDES folder it will use that 
ELSE
	It will grab the value of global variable named "vDataDir" which is assumed to point to the "QVD" folder 
	This can be used to determine the "level" that the INCLUDES folder is at by substituting the first occurence of "\QVD\" in the string with "\INCLUDES\' and truncating off the remaing text

Examples
	"..\QVD\" becomes "..\INCLUDES\"
	"..\..\QVD\" becomes "..\..\INCLUDES\"
	"..\QVD\SUPPORT" becomes "..\INCLUDES"
	"QLIKDEV\CLAIMS\CSI\QVD\" becomes "QLIKDEV\CLAIMS\CSI\INCLUDES\"

	// example call
	call ENVIRONMENT_INDICATOR.GET_VALUE ('..\INCLUDES\') ; // VARIABLE [ENVIRONMENT_INDICATOR.RETURN_VALUE] WILL HAVE VALUE IN IT

	// returns variable "ENVIRONMENT_INDICATOR.RETURN_VALUE" with "DEV", "PROD" or whatever other value represents some unknown new env

	//LET vDataDir = '..\QVD\SUPPORT' ;
	
	call ENVIRONMENT_INDICATOR.GET_VALUE ('.\') ;


*/

// ADDED 02 14 2015 SOIO

SUB GET_INCLUDES_PATH_FROM_vDataDir ;

	IF ISNULL (vDataDir) THEN ;	
			LET GET_INCLUDES_PATH_FROM_vDataDir.RETURN_VALUE = '' ;
			call generate_error ('Procedure [GET_INCLUDES_PATH_FROM_vDataDir] attempted to use standard variable [vDataDir] in order to determine the path to the "INCLUDES" folder but the variable has a value of NULL') ;
			EXIT SUB ; // 
		else
			LET GET_INCLUDES_PATH_FROM_vDataDir.RETURN_VALUE = LEFT (UPPER(vDataDir), INDEX (UPPER(vDataDir), '\QVD', 1) -1) & '\INCLUDES\' ;
			IF RIGHT (GET_INCLUDES_PATH_FROM_vDataDir.RETURN_VALUE ,1) <> '\' THEN ; LET GET_INCLUDES_PATH_FROM_vDataDir.RETURN_VALUE = GET_INCLUDES_PATH_FROM_vDataDir.RETURN_VALUE   & '\' ; END IF ;
			call generate_warning ('Procedure [GET_INCLUDES_PATH_FROM_vDataDir] used standard variable [vDataDir] which has a value of [$(vDataDir)] and has determined the INCLUDES folder is at : $(GET_INCLUDES_PATH_FROM_vDataDir.RETURN_VALUE)') ;
		END IF ;
		
END SUB ;


SUB ENVIRONMENT_INDICATOR.GET_VALUE (optional_param_relative_path_to_includes /* local vars */ , ENVIRONMENT_INDICATOR.local_full_path_and_filename); // e.g. '..\INCLUDES\' or '..\..\INCLUDES\'
	
	LET ENVIRONMENT_INDICATOR.RETURN_VALUE =; // set to NULL just in case this procedure fails and the calling script continues. We dont want the calling script to be able to continue

	IF ISNULL (optional_param_relative_path_to_includes) THEN ; // if the parameter is NULL, it is assumed to not being supplied by the CALL statement 
	
		IF ISNULL (vDataDir) THEN ;	
			LET ENVIRONMENT_INDICATOR.local_full_path_and_filename= '' ;
			call generate_error ('Procedure [ENVIRONMENT_INDICATOR.GET_VALUE] has *not* been passed a value into parameter [optional_param_relative_path_to_includes] and an attempt to use standard variable [vDataDir] which has a value of [$(vDataDir)] to indirectly provide a path to the correct folder has failed') ;
			EXIT SUB ; // 
		else
			LET ENVIRONMENT_INDICATOR.local_full_path_and_filename = LEFT (UPPER(vDataDir), INDEX (UPPER(vDataDir), '\QVD', 1) -1) & '\INCLUDES\' ;
			
			// soio sp12 removed
			//call generate_warning ('Procedure [ENVIRONMENT_INDICATOR.GET_VALUE] has *not* been passed a value into parameter [optional_param_relative_path_to_includes] but standard variable [vDataDir] which has a value of [$(vDataDir)] has indirectly provided a path to the correct folder of : $(ENVIRONMENT_INDICATOR.local_full_path_and_filename)') ;

			// soio sp12 added (to make warning not be reported as a true warning)
			call sub_trace_event ('Procedure [ENVIRONMENT_INDICATOR.GET_VALUE] has *not* been passed a value into parameter [optional_param_relative_path_to_includes] but standard variable [vDataDir] which has a value of [$(vDataDir)] has indirectly provided a path to the correct folder of : $(ENVIRONMENT_INDICATOR.local_full_path_and_filename)') ;

		END IF ;
	ELSE
		LET ENVIRONMENT_INDICATOR.local_full_path_and_filename = optional_param_relative_path_to_includes ;
		IF RIGHT (ENVIRONMENT_INDICATOR.local_full_path_and_filename ,1) <> '\' THEN ; LET ENVIRONMENT_INDICATOR.local_full_path_and_filename = ENVIRONMENT_INDICATOR.local_full_path_and_filename   & '\' ; END IF ;
	END IF ;
	
	LET ENVIRONMENT_INDICATOR.local_full_path_and_filename = ENVIRONMENT_INDICATOR.local_full_path_and_filename & 'QVW_CSI_ENVIRONMENT_INDICATOR.txt' ;

	ENVIRONMENT_INDICATOR.TABLE:
	FIRST 1 // <<<<<<< ONLY LOAD FIRST ROW
	NOCONCATENATE
	LOAD 
		@1 as ENVIRONMENT_INDICATOR.FIELD_VALUE
	FROM
		[$(ENVIRONMENT_INDICATOR.local_full_path_and_filename)]
		(txt, no labels, delimiter is '\t', msq)
	;
	
	LET ENVIRONMENT_INDICATOR.RETURN_VALUE = UPPER (TRIM (PEEK ('ENVIRONMENT_INDICATOR.FIELD_VALUE', 0, 'ENVIRONMENT_INDICATOR.TABLE') )) ;
	
	//call DROP_TABLE ('ENVIRONMENT_INDICATOR.TABLE') ;
	DROP TABLE 'ENVIRONMENT_INDICATOR.TABLE';
	
	call sub_trace_event ('Variable [ENVIRONMENT_INDICATOR.RETURN_VALUE] now has value of [$(ENVIRONMENT_INDICATOR.RETURN_VALUE)] taken from file : $(ENVIRONMENT_INDICATOR.local_full_path_and_filename)') ;

END SUB ;

// aliases that can be used to point to [output_variable_values]
SUB common.output_variables (param_variable_list) ;
	call output_variable_values (param_variable_list);
end sub ;
SUB common.output_variable (param_variable_list) ;
	call output_variable_values (param_variable_list);
end sub ;
SUB common.output_variable_value (param_variable_list) ;
	call output_variable_values (param_variable_list);
end sub ;
// ========================================================================================================================

// example : call common.fatal_error_if_field_doesnt_exist ('fieldname2') ;
// example : where exists ( $(global.field_name_exists) )
//CALL common.fatal_error_if_field_doesnt_exist ('a b c') ;
//
//// global.field_name_exists
//
////LOAD * RESIDENT 'z12' WHERE EXISTS ( $(global.field_name_exists) );
//
//LOAD 
//	* 
//FROM [.\xyz.qvd] (qvd) 
//WHERE 
//	EXISTS ( [$(global.field_name_exists)] ) ; // [square brackets in this example] are not part of the workaround. but its always safer to surround field names in square brackets in case space infix'd field names come along later
//	
SUB common.fatal_error_if_field_doesnt_exist (param_field_name) ;
	
	call SUB_TRACE_EVENT ('A call to [SUB common.fatal_error_if_field_doesnt_exist] has field name [$(param_field_name)]. This procedure is usually called before a [LOAD FROM QVD/XLS/CSV WHERE EXISTS ($(param_field_name))] statement to detect bad a field name') ;
	IF $(f_does_field_exist_in_data_model('$(param_field_name)')) <> 'Y' THEN
	
		LET global.field_name_exists =; 
		CALL common.generate_fatal_error ('Field [$(param_field_name)] is expected to exist in the data model at this stage of the script execution but doesnt. The script cannot continue.') ;
		EXIT SCRIPT; // this code line should never be reached
		
	ELSE 
		CALL sub_trace_event ('Field [$(param_field_name)] confirmed exists') ;	
		LET global.field_name_exists = param_field_name ;
		
	END IF ;
	
	
END SUB ;

// ========================================================================================================================

sub describe_all_tables ;

	call sub_trace_event ('');
	CALL common.output_double_horizontal_line ;
	
	call sub_trace_event ('Procedure [describe_all_tables] lists all in-memory tables, counts, and field names') ;
	
	CALL common.output_single_horizontal_line ;
	
	LET common.max_length_numeric_output = 11 ;
	
	let common.number_of_tables = Nooftables() ;
	
	if common.number_of_tables  >= 1 then ;
		
		LET common.max_length_table_name =9 ;
		let common.table_names_delimited_list='' ;
		
		for common.table_index = 1 to common.number_of_tables
			
			LET common.table_name 						= TableName(common.table_index -1) ;
			LET common.table_names_delimited_list 		= common.table_name & ';' & common.table_names_delimited_list ;
			let common.length_table_name 				= len (common.table_name );
			
			if common.length_table_name > common.max_length_table_name THEN
				LET common.max_length_table_name = common.length_table_name ;
			END IF ;
			
			call if_tablename_has_potential_duplicate_in_model(common.table_name) ; // check for bad ones
			
		next common.table_index ;
	
		//call output_variable_values ('common.max_length_table_name,common.max_length_numeric_output');
		
		//CALL common.output_single_horizontal_line ;
		//LET common.table_names_delimited_list_UPPER = common.table_names_delimited_list ;
		call sort_delimited_list (common.table_names_delimited_list, ';') ;
		
		
		// TODO - SORT THE LIST OF TABLE NAMES IN A CASE IN-SENSITIVE MANNER
		
		
		//call sort_delimited_list (common.table_names_delimited_list_UPPER, ';') ;
		//CALL common.output_single_horizontal_line ;
		//call sub_trace_event ('') ;call sub_trace_event ('') ;call sub_trace_event ('') ;
		
		LET common.table_names_delimited_list = sort_delimited_list.sorted_list ;
		
		//call output_variable_values ('common.table_names_delimited_list,common.number_of_tables') ;
		
		LET common.count_tables_with_zero_rows = 0 ;
		
		let common.formatted_table_name_header		= $(f_return_fixed_length_text('Tablename',common.max_length_table_name)) ;
		let common.formatted_number_of_rows_header 	= $(f_return_fixed_length_text_justified('Rows',common.max_length_numeric_output)) ;
		let common.formatted_number_of_fields_header= $(f_return_fixed_length_text_justified('Fields',common.max_length_numeric_output)) ;							
		let common.formatted_output_header			= common.formatted_table_name_header & '  ' & common.formatted_number_of_rows_header & '  ' & common.formatted_number_of_fields_header & '        ' & 'Fieldnames';
	
		//call output_variable_values ('common.formatted_table_name_header,common.formatted_number_of_rows_header,common.formatted_number_of_fields_header,common.formatted_output_header') ;
		
		
		call sub_trace_event ('');
		call sub_trace_event (common.formatted_output_header) ;
		CALL common.output_single_horizontal_line ;
		
		
				
		for common.table_index = 1 to common.number_of_tables
			
			LET common.table_name	= SUBFIELD (common.table_names_delimited_list, ';', common.table_index);
			//LET common.table_name 	= TableName(common.table_index -1) ;
			
			let common.number_of_rows 		= NoOfRows('$(common.table_name)') ; if common.number_of_rows = 0 then ;LET common.count_tables_with_zero_rows = common.count_tables_with_zero_rows +1; end if ;
			let common.number_of_fields 	= NoOfFields('$(common.table_name)') ;
			//let common.table_number 		= 1+TableNumber('$(common.table_name)') ;
			
			call get_table_field_names(common.table_name, 'N') ;
	
			let common.formatted_table_name 			= $(f_return_fixed_length_text('$(common.table_name)',common.max_length_table_name)) ;
			// ;
			//let common.formatted_number_of_rows 		= $(f_return_fixed_length_number($(common.number_of_rows),common.max_length_numeric_output)) ;
			LET common.formatted_number_of_rows 		= num(common.number_of_rows,'###,###,###') ; //call output_variable_values ('common.formatted_number_of_rows');
			let common.formatted_number_of_rows 		= $(f_return_fixed_length_text_justified(common.formatted_number_of_rows,common.max_length_numeric_output)) ; //call output_variable_values ('common.formatted_number_of_rows');
			
			
			let common.formatted_number_of_fields 		= $(f_return_fixed_length_number($(common.number_of_fields),common.max_length_numeric_output)) ;
			let common.formatted_table_field_names		= REPLACE (get_table_field_names.field_names, ';', ', ') ;
			let common.formatted_output_detail			= common.formatted_table_name & '  ' & common.formatted_number_of_rows  & '  ' & common.formatted_number_of_fields & '       ' & common.formatted_table_field_names ;
	
	
	
			//		
			//CALL OUTPUT_VARIABLE_VALUES ('common.table_index,common.table_name,common.number_of_rows,common.number_of_fields,common.table_number,get_table_field_names.field_names,common.formatted_table_name,common.count_tables_with_zero_rows,common.formatted_number_of_rows') ;	
			
			call sub_trace_event (common.formatted_output_detail) ;
			
			
			
			
			
		
		next common.table_index ;
	
		CALL common.output_single_horizontal_line ;
		
		//  common.count_tables_with_zero_rows
		if  common.count_tables_with_zero_rows > 0 then ;
			call generate_warning ('There are [$(common.count_tables_with_zero_rows)] tables with zero rows in them. This may be as expected or may be a sympton of a problem in the code or the data') ;
			call sub_trace_event ('');
		end if ;
	
	
		let common.distinct_field_list	= '';


		// FIND FIELDS THAT HAVE ZERO VALUES IN THEM
		for common.table_index = 1 to NoOfTables() ;
		
			let common.table_name = TableName (common.table_index-1);
			
			for common.field_index = 1 to NoOfFields (common.table_name);
			
				let common.field_name = FieldName (common.field_index ,common.table_name );
				
				//let common.found_duplicate = INDEX ( common.distinct_field_list, common.field_delimiter & common.field_name & common.field_delimiter)  ;
				
				
				LET common_distinct_fieldvalue_count = FIELDVALUECOUNT ( common.field_name) ;
				
				//call output_variable_values ('common.table_index,common.table_name,common.field_index,common.field_name,common.distinct_field_list,common_distinct_fieldvalue_count') ;
				
				IF common_distinct_fieldvalue_count = 0 THEN ;
					LET common.distinct_field_list = common.distinct_field_list & common.field_name & '; ' ;
				ELSE
					// do nothing
					
				END IF ;
				
			NEXT common.field_index ;
		
		NEXT common.table_index;
		
		IF common.distinct_field_list <> '' THEN ;
		
			call generate_warning ('The following fields have either no values in them or contain only NULLs. This may be as expected or may be a sympton of a problem in the code or the data') ;
			call sub_trace_event ( REPLACE ('>>>>>>>> Fields : $(common.distinct_field_list)', ';' ,',') ) ;
		
		END IF ;

	end if ; // no tables so dont do anything	
	
end sub ;
// alias to above
sub common.describe_all_tables ;
	call describe_all_tables ;
END SUB ;

/*
SUB drop_all_tables_except  ('list of table names comma delimited')

Typically used dring development and debugging to leave one or a few tables in memory and drop all the others to avoid synthetic keys etc and concentraet one thse tables

*/
sub drop_all_tables_except (param_table_name_list /* local vars */ , _number_of_tables, _SINGLE_QUOTE,_table_name_list, _table_index)

	call sub_trace_event ('');
	CALL common.output_double_horizontal_line ;
	call sub_trace_event('Procedure [drop_all_tables_except] will drop all tables except [$(param_table_name_list)]') ;
	
//	let _number_of_tables 	= Nooftables() ;
	//let _SINGLE_QUOTE		= chr(39);
	//let _table_name_list 	= '';
	
	let common.param_table_name_list = param_table_name_list;
	LET common.param_table_name_list = TRIM (common.param_table_name_list);
	
	if RIGHT (common.param_table_name_list, 1) <> ',' THEN ; LET common.param_table_name_list = common.param_table_name_list & ',' ; END IF
	if LEFT (common.param_table_name_list, 1) <> ',' THEN ; LET common.param_table_name_list = ',' & common.param_table_name_list ; END IF
	LET common.table_list_count = SUBSTRINGCOUNT (common.param_table_name_list, ',') -1;
	
	if common.table_list_count = 0 then ;
		call generate_error ('There are no tables in the parameter') ;
		EXIT SUB ;
	END IF ;
	
	
	
	let common.number_of_tables 		= NoOfTables () ;
	
	IF common.number_of_tables = 0 then ;
		call generate_error ('There are no tables in the data model at this stage of the script') ;
		EXIT SUB ;
	ELSE
		CALL SUB_TRACE_EVENT ('The data model contains [$(common.number_of_tables)] tables in memory before any are dropped') ;
		
	end if ;
	
	let common.invalid_table_names = '';
	FOR common.table_index = 1 to common.table_list_count ;
		
		let common.table_name = SUBFIELD(common.param_table_name_list,',',common.table_index+1) ;	
		if $(f_does_table_exist(common.table_name)) = 'N' THEN ;
			let common.invalid_table_names  = common.table_name & ', ' & common.invalid_table_names  ;
		END IF ;
	next common.table_index  ;
	
	if common.invalid_table_names <> '' THEN ;
		call generate_error ('Parameter contains invalid table name(s) [$(common.invalid_table_names)]. NO tables will be dropped') ;
		exit sub ;
	END IF ;	
	
	let common.list_of_tables_to_drop 	= '' ; 
	let common.list_of_tables_to_drop_count = 0 ;
	
	FOR common.table_index = 1 to common.number_of_tables ;
			
		let common.table_name = Tablename (common.table_index-1) ; // todo - check 0 or 1 for first table
				
		//call output_variable_values ('common.table_index,common.table_name') ;
				
		IF INDEX (common.param_table_name_list, ',' & common.table_name  & ',') = 0 THEN ; 
			LET common.list_of_tables_to_drop 		= common.table_name & ',' & common.list_of_tables_to_drop ;
			let common.list_of_tables_to_drop_count = common.list_of_tables_to_drop_count + 1 ;
		END IF ;
				
	NEXT common.table_index ;
	
	if common.list_of_tables_to_drop_count = 0 then ;
		call generate_warning ('After excluding tables [$(param_table_name_list)] there are no tables remaining to be dropped') ;
		EXIT SUB ;
	END IF ;
	
	//call output_variable_values ('common.list_of_tables_to_drop,common.list_of_tables_to_drop_count') ;
	
	//call sub_trace_event ('drop these') ;
	
	for common.table_index =1  to common.list_of_tables_to_drop_count ; 
			
		let common.table_name = SUBFIELD (common.list_of_tables_to_drop, ',', common.table_index ) ;
			
		CALL DROP_TABLE (common.table_name); 

	NEXT common.table_index ;
	
	let common.number_of_tables 		= NoOfTables () ;
	CALL SUB_TRACE_EVENT ('The data model now contains [$(common.number_of_tables)] tables in memory') ;
		
end sub ;



/*

A function and a procedure which reads any registry entry given the path and key

Example:
path 	= 'HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\Session Manager\SubSystems'
key 	= 'Windows'

CALL GetRegistryString(path, key, return_variable) 
returns the value of a named registry key with a given registry path and will return its value in the variable passed via 'return_variable' and also via global variable 'LET common.f_get_registry_string.return_value' 

The function 'f_get_registry_string' can also be used but it has the disadvantage that its code will show up in any LOG file even if SET is defined in a hidden script

Example usage:
let x= $(f_get_registry_string('HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\Session Manager\SubSystems','Windows')) ;

call common.f_get_registry_string ('HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\Session Manager\SubSystems', 'Windows',v_set_via_sub ) ;

*/

SET f_get_registry_string=GETREGISTRYSTRING($1, $2) ; // PATH AND 

SUB common.f_get_registry_string (param_path, param_key, common.f_get_registry_string.byval_return_value, local_registry_text) ;

	//call output_variable_values ('param_path,param_key') ;
	//call sub_trace_event ('') ;
	
	LET local_registry_text = $(f_get_registry_string(param_path,param_key)) ;
	//GETREGISTRYSTRING (param_path, param_key) ;
	
	LET common.f_get_registry_string.byval_return_value 	= local_registry_text;
	LET common.f_get_registry_string.return_value 			= local_registry_text;
	
	//call output_variable_values ('local_registry_text') ;
	
END SUB ;

// =======================================================================================================================================
/*
	The following procedures, variables and files are all related
	SUB 	DEBUG.DEBUG_MODE_INDICATOR_YN.GET_VALUE 
	SUB 	DEBUG.LET_VARIABLE_EQUAL_VALUE
	VAR 	GLOBAL.DEBUG_MODE_INDICATOR_YN
	FILE 	INCLUDES\QVW_DEBUG_MODE_INDICATOR.txt
	
	// call this to check for existence and correct structure of INCLUDES\QVW_DEBUG_MODE_INDICATOR.txt file
	call DEBUG.DEBUG_MODE_INDICATOR_YN.GET_VALUE  ;
	
	// use this 
	LET publisher.csi_generate_metric_partitions='value before the call'; 
	call DEBUG.LET_VARIABLE_EQUAL_VALUE ('publisher.csi_generate_metric_partitions', 'batch1,CSI_DATA_MODEL_METRIC_AGGREGATION,001,001,IGNORED,18,10') ;
	
	// example usage
	if GLOBAL.DEBUG_MODE_INDICATOR_YN ='Y' THEN
		call drop_all_tables_except ('CSI_Facts') ;
	ELSE
		call drop_all_tables ;
	END IF ;

*/
// ---------------------------------------------------------------------------------------------------------------------------------------
SUB DEBUG.DEBUG_MODE_INDICATOR_YN.GET_VALUE ;
	
	LET GLOBAL.DEBUG_MODE_INDICATOR_YN = 'N' ; // BY DEFAULT DEBUG MODE IS NOT ACTIVE AND IT WILL TAKE A FULLY FORMED FILE IN THE RIGHT PLACE TO ENABLE IT
	
	IF ISNULL (vDataDir) OR TRIM (vDataDir) = '' THEN ;	

		call generate_warning('Procedure [DEBUG.DEBUG_MODE_INDICATOR_YN.SET_VALUE] requires a value in the standard variable [vDataDir] to provide a path. The variable either didnt exist or has (now) got a value of NULL or empty. Debug mode cannot be enabled until this is corrected') ;
		EXIT SUB ;
		
	else

		LET common.debug_indicator_full_path_and_filename = LEFT (UPPER(vDataDir), INDEX (UPPER(vDataDir), '\QVD', 1) -1) & '\INCLUDES\' ;
			
		//call sub_trace_event ('Procedure [DEBUG.DEBUG_MODE_INDICATOR_YN.GET_VALUE] will use standard variable [vDataDir] which has a value of [$(vDataDir)] has indirectly provided a path to the correct folder of : $(common.debug_indicator_full_path_and_filename)') ;

	END IF ;
	
	LET common.debug_indicator_full_path_and_filename = common.debug_indicator_full_path_and_filename & 'QVW_DEBUG_MODE_INDICATOR.txt' ;

	IF $(f_does_file_exist(common.debug_indicator_full_path_and_filename)) = 'Y' THEN ;
	
		DEBUG_MODE_INDICATOR.TABLE:
		FIRST 1 // <<<<<<< ONLY LOAD FIRST non-empty ROW
		NOCONCATENATE
		LOAD
			 
			UPPER (@1) 			as GLOBAL.DEBUG_MODE_INDICATOR_PARAMETER
			,
			TRIM(UPPER (@2)) 	as GLOBAL.DEBUG_MODE_INDICATOR_YN
		FROM
			[$(common.debug_indicator_full_path_and_filename)]
			(txt, no labels)
		;

		IF $(f_NoOfRows('DEBUG_MODE_INDICATOR.TABLE')) <= 0 THEN ;
			
			//call generate_warning ('Procedure [DEBUG.DEBUG_MODE_INDICATOR_YN.GET_VALUE] cannot locate a single row in file therefor debug mode cannot be enabled : $(common.debug_indicator_full_path_and_filename)') ;
			
		ELSE
		
			LET GLOBAL.DEBUG_MODE_INDICATOR_YN  = UPPER (TRIM (PEEK ('GLOBAL.DEBUG_MODE_INDICATOR_YN', 0, 'DEBUG_MODE_INDICATOR.TABLE') )) ;
		
			if not (GLOBAL.DEBUG_MODE_INDICATOR_YN = 'Y' or GLOBAL.DEBUG_MODE_INDICATOR_YN = 'N') THEN 
				LET GLOBAL.DEBUG_MODE_INDICATOR_YN = 'N' ; // always assume 'N' (no) to debug mode
			ELSE 
				CALL SUB_TRACE_EVENT ('Procedure [DEBUG.DEBUG_MODE_INDICATOR_YN.SET_VALUE] has set variable [GLOBAL.DEBUG_MODE_INDICATOR_YN] to the value of [$(GLOBAL.DEBUG_MODE_INDICATOR_YN)]') ;
				
			END IF ;
		
		END IF ;
		
		//CALL DROP_TABLE ('DEBUG_MODE_INDICATOR.TABLE') ;
		//drop table 'DEBUG_MODE_INDICATOR.TABLE' ;
	
	ELSE
	
		//call sub_trace_event ('DEBUG indicator file does not exist so variable [GLOBAL.DEBUG_MODE_INDICATOR_YN] is set to [$(GLOBAL.DEBUG_MODE_INDICATOR_YN)] File : $(common.debug_indicator_full_path_and_filename)') ;
		
	END IF ;
	
	//call sub_trace_event ('Variable [ENVIRONMENT_INDICATOR.RETURN_VALUE] now has value of [$(ENVIRONMENT_INDICATOR.RETURN_VALUE)] taken from file : $(ENVIRONMENT_INDICATOR.local_full_path_and_filename)') ;

END SUB ;


//global.debug_mode_indicator_YN 
// use this procedure to set variables which you would normally supply via Publisher or the command line and want to avoid hard coding in the QVW LOAD script
// e.g. CALL 
SUB DEBUG.LET_VARIABLE_EQUAL_VALUE (param_variable_name, param_variable_value) ;
	
	call sub_trace_event ('') ;
	//call debug_code_warning ('CALL to [SUB DEBUG.LET_VARIABLE_EQUAL_VALUE] with variable name [$(param_variable_name)] and value of : $(param_variable_value)') ;
	//call output_variable_values ('param_variable_name,GLOBAL.DEBUG_MODE_INDICATOR_YN') ;
	
	IF GLOBAL.DEBUG_MODE_INDICATOR_YN = 'Y' THEN ;
		LET common.before_change_var_value = $(param_variable_name) ;
		call sub_trace_event ('SUB DEBUG.LET_VARIABLE_EQUAL_VALUE variable [$(param_variable_name)] has the following value before any change : $(common.before_change_var_value)');
		LET $(param_variable_name) ='$(param_variable_value)' ;
		call debug_code_warning ('CALL TO [SUB DEBUG.LET_VARIABLE_EQUAL_VALUE] HAS *CHANGED* THE VALUE OF A VARIABLE [$(param_variable_name)] TO : $(param_variable_value) ');
		//call output_variable_values ('$(param_variable_name)') ;
		
	ELSE 
		call sub_trace_event ('Call to [SUB DEBUG.SET_VARIABLE_TO_VALUE] has *NOT* changed the value of any variable') ; // WILL COMMENT OUT EVENTUALLY
	END IF ;

END SUB ;

//=======================================================================================================================================
// example: if text is ",this,andthis," then outout will be "this,andthis"
// used by common functions itself but can also be called by use rscript
// result is returned in the variable that was used to call procedure AND also in variable 'common.remove_leading_and_trailing_chars.return_value '
SUB common.remove_leading_and_trailing_char (param_text, param_char, local_length, local_param_text ) ;
	
	// TODO : CHECK IF param_char IS ONE CHAR LONG. IF NOT THEN FATAL ERROR
	
	LET local_param_text = param_text ;

	LET local_length = LEN (local_param_text) ;
    IF LEFT (local_param_text, 1) =param_char THEN ;LET local_param_text = MID (local_param_text,2,local_length); END IF ;
    
    LET local_length = LEN (local_param_text) ;
    IF RIGHT (local_param_text, 1) =param_char THEN ;LET local_param_text = LEFT (local_param_text,local_length-1); END IF ;
	
	LET common.remove_leading_and_trailing_chars.return_value = local_param_text ;
	
END SUB ;
//=======================================================================================================================================

 // ========================================================================================================================
// LOGs the field names that are unique to either table and those that are common to both tables
// helpsto understand what will happen in a script when a JOIN or CONCATENATE is planned in a script
// 
// EXAMPLE USAGE : call compare_two_tables ('table_name_1', 'table_name_2') will log the fields that are common to both and distintive to each table
// 
// ========================================================================================================================

sub common.compare_two_tables     (param_table_one, param_table_two, /* expect this to be name of calling variable */ v_compare_two_tables,    /* local variables */ local_field_index, local_field_count, local_field_name, local_common_fields, local_table_one_specific, local_table_two_specific, local_CRLF, local_indent, local_table_1_list, local_table_2_list ) ;

	CALL SUB_TRACE_EVENT (''); CALL SUB_TRACE_EVENT ('') ;
    call sub_trace_event ('Procedure [COMMON.COMPARE_TWO_TABLES] will compare table1 [$(param_table_one)] to table2 [$(param_table_two)]') ;
    
    let v_compare_two_tables = 'ERROR in procedure [compare_two_tables]' ; // default
    //let local_CRLF = '' ;// /*CHR(10) & */CHR (13) ;
    //let local_indent = '    ' ;
    
    if $(f_does_table_exist(param_table_one)) <> 'Y' THEN 
        call generate_error ('Table one [$(param_table_one)] does not exist') ;
        EXIT SUB ;
    END IF

    if $(f_does_table_exist(param_table_two)) <> 'Y' THEN 
        call generate_error ('Table two [$(param_table_two)] does not exist') ;    
        EXIT SUB ;
    END IF
    
    call get_table_field_names(param_table_one, 'N') ; 
    let get_table_field_names.field_names = trim (get_table_field_names.field_names) ;

    call common.remove_leading_and_trailing_char (get_table_field_names.field_names, ';') ;
    LET get_table_field_names.field_names = common.remove_leading_and_trailing_chars.return_value ;


    LET local_table_1_list = REPLACE (get_table_field_names.field_names, ';', ','); ;
    
    call get_table_field_names(param_table_two, 'N') ; 
    let get_table_field_names.field_names = trim (get_table_field_names.field_names) ;

    call common.remove_leading_and_trailing_char (get_table_field_names.field_names, ';') ;
    LET get_table_field_names.field_names = common.remove_leading_and_trailing_chars.return_value ;
    
    LET local_table_2_list = REPLACE (get_table_field_names.field_names, ';', ',') ;


    LET local_table_one_row_count = NoOfRows(param_table_one);
    LET local_table_two_row_count = NoOfRows(param_table_two);

    LET local_table_one_field_count = NoOfFields(param_table_one);
    LET local_table_two_field_count = NoOfFields(param_table_two);
       
	call compare_two_delimited_lists (local_table_1_list, local_table_2_list, ',') ;
      
	call common.remove_leading_and_trailing_char (compare_two_delimited_lists.list_1_only, ',') ;
	LET compare_two_delimited_lists.list_1_only = common.remove_leading_and_trailing_chars.return_value ;

  	call common.remove_leading_and_trailing_char (compare_two_delimited_lists.list_2_only, ',') ;
	LET compare_two_delimited_lists.list_2_only = common.remove_leading_and_trailing_chars.return_value ;

  	call common.remove_leading_and_trailing_char (compare_two_delimited_lists.common_to_both_lists, ',') ;
	LET compare_two_delimited_lists.common_to_both_lists = common.remove_leading_and_trailing_chars.return_value ;

	LET local_table_one_field_count_formatted 	= $(f_return_fixed_length_number(local_table_one_field_count,8));
	LET local_table_two_field_count_formatted 	= $(f_return_fixed_length_number(local_table_two_field_count,8));
	LET local_table_one_row_count_formatted		= $(f_return_fixed_length_number(local_table_one_row_count,8));
	LET local_table_two_row_count_formatted 	= $(f_return_fixed_length_number(local_table_two_row_count,8));		
	
    CALL SUB_TRACE_EVENT ('>      Table1 has row count            : $(local_table_one_row_count_formatted)') ;
    CALL SUB_TRACE_EVENT ('>      Table2 has row count            : $(local_table_two_row_count_formatted)') ;
    CALL SUB_TRACE_EVENT ('>      ');
    CALL SUB_TRACE_EVENT ('>      Table1 has fields               : $(local_table_one_field_count_formatted) : $(local_table_1_list)') ;
    CALL SUB_TRACE_EVENT ('>      Table2 has fields               : $(local_table_two_field_count_formatted) : $(local_table_2_list)') ;
    CALL SUB_TRACE_EVENT ('>      ');    
    
    CALL SUB_TRACE_EVENT ('>      Fields in table1 but not table2 : $(compare_two_delimited_lists.list_1_only)' ); 
    CALL SUB_TRACE_EVENT ('>      Fields in table2 but not table1 : $(compare_two_delimited_lists.list_2_only)') ;
    CALL SUB_TRACE_EVENT ('>      Fields common to both tables    : $(compare_two_delimited_lists.common_to_both_lists)') ;
    
    CALL SUB_TRACE_EVENT ('>      '); 
	CALL SUB_TRACE_EVENT ('>      NOTE: The fields labelled "Fields in table but not" may exist in tables other than the 2 being compared. This is not a full analysis of the data model') ;
	CALL SUB_TRACE_EVENT ('>      NOTE: The fields labelled "Fields common to both tables" are candidates for any later joins (and synthetic keys)') ;
	    
CALL SUB_TRACE_EVENT ('');

//	common.compare_two_tables
end sub



sub QVW_Common_routines.logging_header ;

	call sub_trace_event ('') ;
	call sub_trace_event ('') ;
	call sub_trace_event ('') ;
	call sub_trace_event ('Common Routines code was last updated 08/03/2015 by Steven White (SOIO)');

	CALL SUB_TRACE_EVENT ('Improved [common.compare_two_tables] formatting. Procedure can be used to predict fields that a join or synthetic key will be based on');
	CALL SUB_TRACE_EVENT ('Added [common.remove_leading_and_trailing_chars] example: ",this,andthis," will return "this,andthis" (note the removal of leading and trailing chars)');

//	CALL SUB_TRACE_EVENT ('DEBUG MODE procedures, variables and files added : SUB DEBUG.DEBUG_MODE_INDICATOR_YN.GET_VALUE, DEBUG.LET_VARIABLE_EQUAL_VALUE , variable GLOBAL.DEBUG_MODE_INDICATOR_YN, file INCLUDES\QVW_DEBUG_MODE_INDICATOR.txt') ;
//	call sub_trace_event ('SUB ENVIRONMENT_INDICATOR.GET_VALUE updated to downgrade its warning to just a normal LOG entry') ;
//	CALL SUB_TRACE_EVENT ('Addition of [SUB common.fatal_error_if_field_doesnt_exist] which generates fatal error when field doesnt exist (needed to compensate for a quirk in QVW where it doesnt complain that a field doesnt exist in LOAD FROM QVD/CSV/XLS WHERE EXISTS (fieldname)') ;
//	CALL SUB_TRACE_EVENT ('Improved [SUB describe_all_tables] to show more information and sort table list by table name (case sensitive sort)');
//	CALL SUB_TRACE_EVENT ('Improved [SUB drop_all_tables_except] to allow a list of table names to be passed. Also improves error and warning checking');
	
//	call sub_trace_event ('Tidied up some formatting issues. No logic changed. Tested via Aggregation and Integration QVWs on 05/07/2015') ;
//	
//	call sub_trace_event ('Addition of global variable [common.output_variable_values.running_variable_list] to keep track of all variables output by [SUB OUTPUT_VARIABLE_VALUES]. A call to [SUB commmon.output_all_variables] will generate a sorted list of variables with current values ') ;
//	call sub_trace_event ('Added SUB [common.output_single_horizontal_line] and [common.output_double_horizontal_line]') ;
//	call sub_trace_event ('Added function [f_does_field_exist_in_data_model] and [SUB common.create_empty_table_in_memory_from_qvd] and [SUB common.generate_fatal_error ]') ;
//	
	call log_datetime ;
	
	LET QVW_Common_routines.v_DocumentName = DocumentName();
	LET QVW_Common_routines.v_DocumentPath = DocumentPath();
	call sub_trace_event ('') ;
	call sub_trace_event ('LOG for QVW file [$(QVW_Common_routines.v_DocumentName)] located in [$(QVW_Common_routines.v_DocumentPath)]');
	call sub_trace_event ('') ;
	
	
END sub ;


call QVW_Common_routines.logging_header ;
//call ENVIRONMENT_INDICATOR.GET_VALUE  ; // Assume running in Extract_Scripts and need to locate INCLUDES one level up. Later codebases can call the same procedure with a different path if necessary
//call DEBUG.DEBUG_MODE_INDICATOR_YN.GET_VALUE  ;

///$tab Outstanding Code Changes (created by SOIO)
/*

DONE
Tab "Loads" loading of table "Loads"
REPLACED:
	AND NOT EXISTS(ExcludeLogRecId, LogRecId)		// Exclude rows we assigned to Join operations
WITH:
	and NOT EXISTS (OperationId, LogRecId) // Exclude rows we assigned to Join operations




Bad or missing timestamps:
	Deal with CR (ascii 13) and LF (ascii 10) characters exisitng in the target QVW.LOG file and throwing off timestamp detection. 
	Sugestd workaroun is to have an option that over-rides a badly formed or missing leading timestamp with the value from the most recent valid line. 
	this will not throw off timings and durations

JOIN/KEEP causing duplication in output rows
	It seems JOIN/KEEP statements are duplicating rows in the LOG rows shown in this UI. Look into this.
	6/11/2015 DOESNT SEEM TO BE AN ISSUE ANY MORE

ANALYZE HISTORY
	Be able to be given a set of QVW.LOG files which are expected to be the same underlying QVW codebase just ran at different times (with invariably diff. data) and chart/highlight problem areas over time
	
		











*/
///$tab Main
SET ThousandSep=',';
SET DecimalSep='.';
SET MoneyThousandSep=',';
SET MoneyDecimalSep='.';
SET MoneyFormat='$#,##0.00;($#,##0.00)';
SET TimeFormat='h:mm:ss TT';
SET DateFormat='M/D/YYYY';
SET TimestampFormat='M/D/YYYY h:mm:ss[.fff] TT';
SET MonthNames='Jan;Feb;Mar;Apr;May;Jun;Jul;Aug;Sep;Oct;Nov;Dec';
SET DayNames='Mon;Tue;Wed;Thu;Fri;Sat;Sun';


///$tab qvc,qvs
REM ===== Begin of Qlikview Components included Qvc.qvs version 5.1 =====;
/*
Copyright (C) 2011  Rob Wunderlich

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with this program.  If not, see http://www.gnu.org/licenses/licenses.html
*/
// Qvc.Global.v.Version MUST be specified in the 3 line format to be picked up as an ANT property!
SET 
Qvc.Global.v.Version = 5.1
;
LET Qvc.Global.v.ScriptStart = now(1);

// Directory of Qvc script extension files.
// A null value means the extension mechanism is not used.
SET Qvc.Global.Extension.Directory=;

REM Configuration variables for Qvc.Calendar;
// Will we create Set Analysis Calendar variables?
SET Qvc.Calendar.v.CreateSetVariables = -1;

SET Qvc.Calendar.v.Field.Date=Date;
SET Qvc.Calendar.v.Field.Day=Day;
SET Qvc.Calendar.v.Field.Weekday=Weekday;
SET Qvc.Calendar.v.Field.Year=Year;
SET Qvc.Calendar.v.Field.Month=Month;
SET Qvc.Calendar.v.Field.YearMonth=Year-Month;
SET Qvc.Calendar.v.Field.Quarter=Quarter;

// Name of the optional script file that defines additonal Calendar fields.
SET Qvc.Calendar.v.ExtFields=CalendarExtFields.qvs;

SUB Qvc.Calendar(_startDate, _endDate, _tableName, _fieldPrefix, _firstMonth)
/**
@version $Id: Qvc_Calendar.qvs 201 2012-05-30 18:19:23Z rob@robwunderlich.com $
Create a Master Calendar Table.

By default, this routine creates "vSetxxx" variables containing time period set analysis expressions. Creation of the variables can be suppressed via a configuration variable. Note also that the variable names may be prefixed with the string given in parameter 4.

--Code Extension--
Default file: CalendarExtFields.qvs
Specified by variable: Qvc.Calendar.v.ExtFields 

The contents of the extension file are Included in the Calendar LOAD statement to create additional fields in the generated Calendar. 

The script may be any field definition allowable in a LOAD statement. The current date being processed must be referenced as field "Date". The AS clause naming the new field must be written  "as [$(_fieldPrefix)newfield]".

For example, to add two new fields for Week and Year-Week:

,week(Date) as [$(_fieldPrefix)Week]
,Year(Date) & '-' & week(Date) as [$(_fieldPrefix)Year-Week]


@syntax CALL Qvc.Calendar (vMindate, vMaxdate, ['CalendarTableName'], ['FieldPrefix'], [FirstMonth]);  

@param 1 Date string or number. The starting date.
@param 2 date string or number. The ending date.
@param 3 String. Optional - the name of the Calendar table. If not supplied the default is "MasterCalendar"
@param 4 String. Optional - A prefix that will be prepended to all field names and Set variables created for this calendar. For the set vars, blanks in this string will be replaced with underscores.
@param 5 Number. Optional - First month of the year. If you want to work with a fiscal year starting in April, specify 4. 

@var Qvc.Calendar.v.CreateSetVariables in -1/0 (true/false) Should Calendar Set Analysis variables be created? Default is true.
@var Qvc.Calendar.v.Field.Date in Field name for the calendar "Date" field.
@var Qvc.Calendar.v.Field.Day in Field name for the calendar "Day of Month" field.
@var Qvc.Calendar.v.Field.Weekday in Field name for the calendar "Weekday" field.
@var Qvc.Calendar.v.Field.Year in Field name for the calendar "Year" field.
@var Qvc.Calendar.v.Field.Month in Field name for the calendar "Month" field.
@var Qvc.Calendar.v.Field.YearMonth in Field name for the calendar "YearMonth" field.
@var Qvc.Calendar.v.Field.Quarter in Field name for the calendar "Quarter" field.

@var vSetYTD out Set Analysis expression for Year-To-Date.
@var vSetQTD out Set Analysis expression for Quarter-To-Date.
@var vSetMTD out Set Analysis expression for Month-To-Date.
@var vSetPreviousMonthMTD out Set Analysis expression for Previous-Month-To-Date.
@var vSetPreviousQuarter out Set Analysis expression for Previous-Quarter-To-Date.
@var vSetPreviousYearMTD out Set Analysis expression for Previous-Year-Month-To-Date.
@var vSetPreviousYearQTD out Set Analysis expression for Previous-Year-Quarter-To-Date.
@var vSetPreviousYearYTD out Set Analysis expression for Previous-Year-Year-To-Date.
@var vSetRolling12 out Set Analysis expression for Rolling-12-Months. 
*/



UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

// Set default _tablename if not supplied
LET _tableName = if(len('$(_tableName)')=0, 'MasterCalendar','$(_tableName)');
// Set Default first month if not specified
LET _firstMonth = if(len('$(_firstMonth)')=0, 1,'$(_firstMonth)');
LET _monthOffset = -($(_firstMonth)-1);  //Compute month offset for Addmonths function.

REM Make some shorter names for the field variables;
IF len('$(_Qvc.Calendar.v.Field.Date.Override)') > 0 THEN	// Use the fixed name (from CalendarFromField) if we have one.
	SET _fDate='[$(_Qvc.Calendar.v.Field.Date.Override)]';
ELSE 
	SET _fDate='[$(_fieldPrefix)$(Qvc.Calendar.v.Field.Date)]';
ENDIF
SET _fDay='[$(_fieldPrefix)$(Qvc.Calendar.v.Field.Day)]';
SET _fWeekday='[$(_fieldPrefix)$(Qvc.Calendar.v.Field.Weekday)]';
SET _fYear='[$(_fieldPrefix)$(Qvc.Calendar.v.Field.Year)]';
SET _fMonth='[$(_fieldPrefix)$(Qvc.Calendar.v.Field.Month)]';
SET _fYearMonth='[$(_fieldPrefix)$(Qvc.Calendar.v.Field.YearMonth)]';
SET _fQuarter='[$(_fieldPrefix)$(Qvc.Calendar.v.Field.Quarter)]';
SET _f_MonthSerial='[$(_fieldPrefix)_MonthSerial]';
SET _f_QuarterSerial='[$(_fieldPrefix)_QuarterSerial]';
SET _f_WeekSerial='[$(_fieldPrefix)_WeekSerial]';

LET _concatenate = if($(_Qvc.TableExists($(_tableName))), 'CONCATENATE ([$(_tableName)])', ''); 
   
[$(_tableName)]:
$(_concatenate) 
LOAD
	*,
	dual($(_fYear) & '-' & $(_fMonth),Date(MonthStart($(_fDate),$(_monthOffset))))  as $(_fYearMonth)
;

LOAD
    Date							as $(_fDate),
    Day(Date)						as $(_fDay),
    Weekday(Date)					as $(_fWeekday),
    Year(AddMonths(Date,$(_monthOffset))) 	as $(_fYear),
    Month(Date)						as $(_fMonth),
    'Q' & Ceil(Month(AddMonths(Date,$(_monthOffset))) / 3)		as $(_fQuarter),
    AutoNumber(MonthStart(Date),'$(_f_MonthSerial)') 	as $(_f_MonthSerial),
    AutoNumber(QuarterStart(Date),'$(_f_QuarterSerial)')	as $(_f_QuarterSerial),
    AutoNumber(weekyear(Date) &'|' & week(Date),'$(_f_WeekSerial)')	as $(_f_WeekSerial)
    $(Include=$(Qvc.Global.Extension.Directory)\$(Qvc.Calendar.v.ExtFields));

;    
LOAD date('$(_startDate)' + recno() - 1) as Date 
AUTOGENERATE date('$(_endDate)') - date('$(_startDate)') + 1
;

SET _concatenate=;
IF $(Qvc.Calendar.v.CreateSetVariables) THEN	// If SA variables requested,

// We don't want spaces in the SetAnalysis varable names. 
// Replace spaces with _.
LET _fieldPrefix = replace('$(_fieldPrefix)',' ','_');

//SET _vCalendarClear=concat({<$Table={'$1'}>}'[' & $Field & ']','=,') & '=';
SET _vClearFieldList=;
FOR i = 1 to NoOfFields('$(_tableName)')
	LET _vClearFieldList = '$(_vClearFieldList)' & '[' & FieldName($(i), '$(_tableName)') & ']=,';
NEXT i


REM Create the Set Analysis variables;
Let $(_fieldPrefix)vSetYTD = replace(
'{$<
$(_vClearFieldList)
$(_f_MonthSerial) = {"<=@(=Max($(_f_MonthSerial)))"},
$(_fDate) = {"<=@(=Max($(_fDate)))"},
$(_fYear) = {@(=Max($(_fYear)))}
>}'
,'@', '$');		
																		

Let $(_fieldPrefix)vSetQTD = replace(
'{$<
$(_vClearFieldList)
$(_f_QuarterSerial) =  {@(=Max($(_f_QuarterSerial)))}, 
$(_fDate) =  {"<=@(=Max($(_fDate)))"}
>}'
,'@', '$');	
				
Let $(_fieldPrefix)vSetMTD = replace(
'{$<
$(_vClearFieldList)
$(_f_MonthSerial) = {@(=Max($(_f_MonthSerial)))}, 
$(_fDate) =  {"<=@(=Max($(_fDate)))"}
>}'
,'@', '$');

Let $(_fieldPrefix)vSetPreviousMonthMTD = replace(
'{$<
$(_vClearFieldList)
$(_f_MonthSerial) = {@(=Max($(_f_MonthSerial)) - 1)}, 
$(_fDay) = {"<=@(=Max(@($(_fieldPrefix)vSetMTD) $(_fDay)))"}
>}'
,'@', '$');
				
Let $(_fieldPrefix)vSetPreviousQuarter =  replace(
'{$<
$(_vClearFieldList)
$(_f_QuarterSerial) =  {@(=Max($(_f_QuarterSerial)) - 1)}
>}'
,'@', '$');

Let $(_fieldPrefix)vSetPreviousYearMTD = replace(
'{$<
$(_vClearFieldList)
$(_f_MonthSerial) = {@(=Max($(_f_MonthSerial)) - 12)}, 
$(_fDay) = {"<=@(=Max(@($(_fieldPrefix)vSetMTD) $(_fDay)))"}, 
$(_fYear) =  {@(=Max($(_fYear))-1)}
>}'
,'@', '$');


Let $(_fieldPrefix)vSetPreviousYearQTD = replace(
'{$<
$(_vClearFieldList)
$(_f_QuarterSerial) =  {@(=Max($(_f_QuarterSerial)) - 4)}, 
$(_fDate) =  {"<=@(=AddMonths(Max($(_fDate)), -12))"}
>}'
,'@', '$');


Let $(_fieldPrefix)vSetPreviousYearYTD = replace(
'{$<
$(_vClearFieldList)
$(_f_MonthSerial) = {"<=@(=Max($(_f_MonthSerial)) - 12)"}, 
$(_fDate) =  {"<=@(=AddMonths(Max($(_fDate)), -12))"},
$(_fYear) =  {@(=Max($(_fYear))-1)}
>}'
,'@', '$');

Let $(_fieldPrefix)vSetRolling12 = replace(
'{$<
$(_vClearFieldList)
$(_f_MonthSerial) = {">=@(=Max($(_f_MonthSerial)) - 11)<=@(=Max($(_f_MonthSerial)))"}
>}'
,'@', '$');


SET _vClearFieldList=;

ENDIF


// Cleanup temp variables
SET _fDate=;
SET _fDay=;
SET _fWeekday=;
SET _fYear=;
SET _fMonth=;
SET _fYearMonth=;
SET _fQuarter=;
SET _f_MonthSerial=;
SET _f_QuarterSerial=;
SET _f_WeekSerial=;
SET _monthOffset =;
			
END SUB	
// End of Qvc.Calendar Sub

SUB Qvc.CalendarFromField(_fieldname, _tableName, _fieldPrefix, _firstMonth)
/**
@version $Id: Qvc_Calendar.qvs 201 2012-05-30 18:19:23Z rob@robwunderlich.com $
Create a Master Calendar based on the Min and Max values of an existing field. The fieldname is used as the "Date" field in the calendar, providinging automatic lkinkage.

This Sub calls Qvc.Calendar to generate the calendar. See the doc for Qvc.Calendar to understand the output and available configuration variables. 

@syntax CALL Qvc.CalendarFromField ('Fieldname', ['CalendarTableName'], ['FieldPrefix'], [FirstMonth]); 
 
@param 1 String. Fieldname that will be used to establish Min and Max values for the Calendar Date.
@param 2 String. Optional - the name of the Calendar table. If not supplied the default is "MasterCalendar"
@param 3 String. Optional - A prefix that will be prepended to all field names and Set variables created for this calendar. For the set vars, blanks in this string will be replaced with underscores.
@param 4 Number. Optional - First month of the year. If you want to work with a fiscal year starting in April, specify 4. 

*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

CALL Qvc.GetFieldValues('_vStats', '$(_fieldname)');

//SET _SaveCalendarDateField='$(Qvc.Calendar.v.Field.Date)';	// Save off the current Date fieldname.
//SET Qvc.Calendar.v.Field.Date='$(_fieldname)';		// Use the parameter fieldname for the Date field.
SET _Qvc.Calendar.v.Field.Date.Override='$(_fieldname)';		// Use the parameter fieldname for the Date field.
// Call Qvc.Calendar to do the work.
CALL Qvc.Calendar(_vStats.Min, _vStats.Max, '$(_tableName)', '$(_fieldPrefix)', '$(_firstMonth)');
//SET Qvc.Calendar.v.Field.Date='$(_SaveCalendarDateField)';		// Restore the saved value

SET _Qvc.Calendar.v.Field.Date.Override=;	// Reset to default behavior
//SET _SaveCalendarDateField=;
SET _vStats.Min=;
SET _vStats.Max=;
END SUB	
// End of Qvc.CalendarFromField Sub
SUB Qvc.Cleanup
/** 
@version $Id: Qvc_Cleanup.qvs 197 2012-05-29 22:54:49Z rob@robwunderlich.com $
Cleanup Qvc data such as global variables. Cleanup should always be called at the end of your script.
@syntax CALL Qvc.Cleanup
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

// Remove variables
// Global
SET Qvc.Global.Extension.Directory=;

// Calendar
SET Qvc.Calendar.v.CreateSetVariables=;
SET Qvc.Calendar.v.Field.Date=;
SET Qvc.Calendar.v.Field.Day=;
SET Qvc.Calendar.v.Field.Weekday=;
SET Qvc.Calendar.v.Field.Year=;
SET Qvc.Calendar.v.Field.Month=;
SET Qvc.Calendar.v.Field.YearMonth=;
SET Qvc.Calendar.v.Field.Quarter=;
SET Qvc.Calendar.v.ExtFields=;

// Log
SET Qvc.Log.v.LogTable=;
SET Qvc.Log.v.LogField=;
SET Qvc.Log.v.WriteLogFile=;
SET Qvc.Log.v.KeepDays=;
SET _Qvc.Log.v.LineCounter=;

// Incremental Load
SET Qvc.Loader.v.DatabaseDatetimeMask=;
SET Qvc.Loader.v.ModField.Type=;
SET Qvc.Loader.v.BaseValue=;
SET Qvc.Loader.v.QvdDirectory=;
SET Qvc.Loader.v.Tablename=;
SET Qvc.Loader.v.IncrementalExpression=;
SET Qvc.Loader.v.KeyFieldIsUnique=;
SET Qvc.Loader.v.Database=;
SET Qvc.Loader.v.IncrementalFloor=;

// Utility
SET _Qvc.DefaultIfEmpty=;
SET Qvc.FileExists=;
SET _Qvc.UniqueId.v.Counter=;
SET _Qvc.TableExists=;

// Calculate script elapsed duration
LET Qvc.Global.v.ScriptDuration = now(1) - Qvc.Global.v.ScriptStart;

END SUB


SUB Qvc.DataLineage (_qvwpath)
/**
@version $Id: Qvc_DataLineage.qvs 214 2012-07-30 18:45:36Z rob@robwunderlich.com $
Load a table describing the data sources for a qvw. 

The table will be named Qvc.LineageInfo and contains the following fields:
Qvc.LineageInfo.ConnString
Qvc.LineageInfo.Creator
Qvc.LineageInfo.LoadStatement
Qvc.LineageInfo.Source
Qvc.LineageInfo.Target

**Important Note: LineageInfo is extracted from the qvw file on disk, not the in-memory copy. This has two implications:
1. Script changes will not be reflected until the qvw is saved and the script reloaded again.
2. LineageInfo source file paths contain resolved absolute paths. If the script was last loaded by a desktop user, the path may have resolved to a different drive letter than your machine. This is corrected by reloading and saving the file.

@param 1 String. Optional. Path of QVW file to be processed. If omitted, the current QVW (Caller of this sub) is processed. 

@syntax CALL Qvc.DataLineage(['qvwpath.qvw']); 
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

IF len('$(_qvwpath)')=0 THEN			// If no param1
	LET _qvwpath = DocumentPath();		// Default qvw is this qvw.
	SET _qvctemp.ScanningThisQvw=1;		// Indicate we are scanning ourself by default
ELSE 
	SET _qvctemp.ScanningThisQvw=0;		// Indicate we are scanning QVW named in param1
ENDIF

LET _qvctemp.SaveErrorMode=$(ErrorMode);	// Save the current ErrorMode
SET ErrorMode=0;		// Set ErrorMode to 0 -- we may have some file paths we can't read

//==== Begin of nested SUB for scanning referenced QVDs. ===
// The parameter is a QVD path.
SUB _Qvc.LoadQvdInfo(_qvdpath)

// Get the Creator name (QVW name) for this QVD.
_qvctemp.TableHeader_temp:
LOAD
    CreatorDoc
    // CreatorDoc is in the XML Header of the QVD file
FROM $(_qvdpath) (XmlSimple, Table is [QvdTableHeader]);
LET _qvctemp.vCreatorDoc = peek('CreatorDoc',-1);
DROP TABLE _qvctemp.TableHeader_temp;


// Load the lineageInfo rows from the QVD.
_qvctemp.LineageInfo_qvd:
LOAD DISTINCT 
	'$(_qvctemp.vCreatorDoc)'			as Qvc.LineageInfo.Creator,  // Use Creator name we pulled earlier
	'$(_qvdpath)' 						as Qvc.LineageInfo.Target,	// The QVD file is the target (output)
	if(len(Statement)=0		// If no Statement,
		,Discriminator		// Then Discriminator holds a filename. Use it for Source
		// Otherwise, get what is after FROM (dbtablename) as the Source					  
		,ltrim(mid(Statement,index(UPPER(Statement),'FROM')+len('FROM')))) as Qvc.LineageInfo.Source,
	if( len(Statement)>0,Discriminator) as Qvc.LineageInfo.ConnString,		// If we have a Statement, then save Connection String
	if( Len(Statement)>0,Statement) 	as Qvc.LineageInfo.LoadStatement	// If we have a Statement, then save it
; 
LOAD 
	Discriminator,
	Statement
FROM [$(_qvdpath)] (XmlSimple, Table is [QvdTableHeader/Lineage/LineageInfo]);

//=== End of nested SUB for scanning referenced QVDs. ===
END SUB	//_Qvc.LoadQvdInfo


/****************************************************************************
* Load the source lineage rows from the QVW file 
*****************************************************************************/ 
Qvc.LineageInfo:
LOAD 
	*
WHERE NOT mixmatch(Qvc.LineageInfo.Source, DocumentPath())		// Ignore the Self-references
	AND NOT Qvc.LineageInfo.Source LIKE 'RESIDENT _qvctemp.*'
;	
LOAD 
	// If we are scanning ourself by default, use the special name ' This QVW' as Target.
	// Note the leading space makes it sort to top in charts.
	if($(_qvctemp.ScanningThisQvw),' This QVW', '$(_qvwpath)') as Qvc.LineageInfo.Target,
	if(len(Statement)=0,Discriminator,				  
		ltrim(mid(Statement,index(UPPER(Statement),'FROM')+len('FROM')))) as Qvc.LineageInfo.Source,
	if( len(Statement)>0,Discriminator) as Qvc.LineageInfo.ConnString,
	if( Len(Statement)>0,Statement) 	as Qvc.LineageInfo.LoadStatement	// If we have a Statement, then save Connection String
FROM [$(_qvwpath)] (XmlSimple, Table is [DocumentSummary/LineageInfo])		// If we have a Statement, then save it
;

/****************************************************************************
* Load source lineage rows for any QVDs use in thie QVW
*****************************************************************************/ 
FOR _qvctemp.lineageRow = 0 to NoOfRows('Qvc.LineageInfo')
	LET _qvctemp.qvdpath = peek('Qvc.LineageInfo.Source', $(_qvctemp.lineageRow), 'Qvc.LineageInfo');
	IF lower(SubField('$(_qvctemp.qvdpath)','.',-1)) = 'qvd' Then 
		CALL _Qvc.LoadQvdInfo('$(_qvctemp.qvdpath)');
	ENDIF
NEXT;

// Join the Creator (who created the QVD) QVW names with QVD Sources used in this QVW
IF NoOfRows('_qvctemp.LineageInfo_qvd')>0 THEN		// If any qvd sources,
	LEFT JOIN (Qvc.LineageInfo)
	LOAD
		Qvc.LineageInfo.Target as Qvc.LineageInfo.Source,
		Qvc.LineageInfo.Creator
	RESIDENT _qvctemp.LineageInfo_qvd
	;

	// Concatenate the QVD Lineage data to the final table
	Concatenate (Qvc.LineageInfo)
	LOAD * RESIDENT _qvctemp.LineageInfo_qvd
	;
	DROP TABLE _qvctemp.LineageInfo_qvd;		// Drop the temp QVD table
ENDIF

LET ErrorMode=$(_qvctemp.SaveErrorMode);	// Restore the ErrorMode


// Clean up temp variables
SET _qvwpath=;
SET _qvctemp.lineageRow=;
SET _qvctemp.vCreatorDoc=;
SET _qvctemp.ScanningThisQvw=;
SET _qvdpath=;
SET _qvctemp.SaveErrorMode=;


END SUB	// Qvc.DataLineage

// Variables - may be overidden by individual Loader qvw.

// Datetime literal format for DB (MS SQL Server)
SET Qvc.Loader.v.DatabaseDatetimeMask = 'MM-DD-YYYY hh:mm:ss';
// The directory for the QVD file
SET Qvc.Loader.v.QvdDirectory='QVD';
// How far back to load if First Load 
//LET Qvc.Loader.v.BaseDate = num(MakeDate(2000,01,01));
SET Qvc.Loader.v.BaseValue =;

// Specify the Database product name. Possible values are SQLSERVER | ORACLE | SFDC.
SET Qvc.Loader.v.Database=SQLSERVER;

// Specify the name that will be appended to Qvc.Loader.v.Predicate. to name the function used to create the predicate.
// Predicates are defined in the IncrementalSetup Sub. They must be defined there to get late binding of nested vars.
SET Qvc.Loader.v.ModField.Type=Datetime;

// Specify if the table uses unique (Primary) values for the Key Field. That is, every row contains a unique value (true). 
// If false, duplicate values are allowed between rows. All rows of a given key value will replace rows of the same value
// from the master QVD.
// ** Specify true if possible as this will result in better performance in the QVD update due to an optimized load. **
SET Qvc.Loader.v.KeyFieldIsUnique = -1;
SUB Qvc.IncrementalSetup (_vTablename, _vSqlModField, _vPk, _vForceFullReload)
/**
@version $Id: Qvc_Incremental_Reload.qvs 229 2012-07-30 21:50:53Z rob@robwunderlich.com $
Set up for incremental load. This is Step 1 of an incremental load process that supports insert, updates and optionally deletes.

Incremental load select rows from the database that have been updated after the last time ("delta time") that reload was run. 

The delta time is established as the max value of the modification field in the QVD. 

This routine builds the WHERE clause used by a subsequent SQL SELECT or LOAD to retrieve updated rows. After loading updated rows, call Qvc.IncrementalStore to update and save the QVD.

See the example qvw for complete instructions.

@syntax CALL Qvc.IncrementalSetup ('Orders', 'LastUpdate', 'OrderId', [ForceFullReload]);  

@param 1 String. The Qlikview tablename. This value will be assigned to the variable Qvc.Loader.v.Tablename.
@param 2 String. The name of the SQL column that indicates row modification. The Qlikview Fieldname is assumed to be the same.
@param 3 String. The Primary Key column of the Qlikview table.
@param 4 True/False (-1/0). If True, a full reload is forced, regardless of an existing QVD. Default is False.

@var Qvc.Loader.v.Database in Database product where tables will be loaded from. Possible values are SQLSERVER | ORACLE | SFDC. Default is SQLSERVER. For non-database files, use SQLSERVER.
@var Qvc.Loader.v.QvdDirectory in Directory for QVD files. Default is 'QVD'.
@var Qvc.Loader.v.BaseValue in How far back to load if first load. If the ModField is a datetime, this should be a QV date number. If revision, a number. If empty, the predicate "1=1" will be generated.
@var Qvc.Loader.v.ModField.Type in Type of the modification (param 2) column -- "Datetime" or "Revision".
@var Qvc.Loader.v.DatabaseDatetimeMask in datetime format used by database mod field. Default is 'MM-DD-YYYY hh:mm:ss'.

@var Qvc.Loader.v.Tablename out Name of Qlikview table.
@var Qvc.Loader.v.IncrementalExpression out The SQL Predicate (where) clause to be included in your SQL Select.

*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

// Set default for forceFullReload to False.
LET _vForceFullReload=$(_Qvc.DefaultIfEmpty($(_vForceFullReload), 0));

// vSqlModField must be present unless doing full reload
IF len('$(_vSqlModField)')=0 AND NOT $(_vForceFullReload) THEN
	CALL Qvc.LogError('ERROR: Parameter 2 (ModField) must be specified unless ForceFullReload is true');
	exit script;	REM Exit the script, this is an intolerable error;
ENDIF


SET _Qvc.Loader.v.ForceFullReload = '$(_vForceFullReload)';		// Make it a private global var for Qvc.IncrementalStore

SET Qvc.Loader.v.Tablename = '$(_vTablename)';		// Make it a global var
SET _Qvc.Loader.v.Tablename = '$(_vTablename)';		// Also a private copy for Qvc.IncrementalStore
SET _Qvc.Loader.v.QvdFile = '$(Qvc.Loader.v.QvdDirectory)\$(_Qvc.Loader.v.Tablename).qvd';
SET _Qvc.Loader.v.PrimaryKey = '$(_vPk)';		// Make it a global var				

/* Functions that create WHERE predicates. They are defined in the sub to allow for definition of vars referenced in the function. */
// Predicate for a datetime field (WHERE xx >= 'YYYY-MM-DD hh:mm:ss'). Also for Date field - just use different mask.
SET _Qvc.Loader.v.Predicate.SQLSERVER.Datetime = '>=' & chr(39) & timestamp($1, '$(Qvc.Loader.v.DatabaseDatetimeMask)') & chr(39);
SET _Qvc.Loader.v.Predicate.ORACLE.Datetime = '>= TIMESTAMP ' & chr(39) & timestamp($1, 'YYYY-MM-DD hh:mm:ss') & chr(39);
SET _Qvc.Loader.v.Predicate.SFDC.Datetime = '>= ' & timestamp($1, 'YYYY-MM-DD hh:mm:ss');


// Predicate for s revision field (WHERE xx >nnnn).
// The leading '' is a way to get the set to keep the quotes around the predicate.
SET _Qvc.Loader.v.Predicate.SQLSERVER.Revision = '' & '>$1';
SET _Qvc.Loader.v.Predicate.ORACLE.Revision = '' & '>$1';
SET _Qvc.Loader.v.Predicate.SFDC.Revision = '' & '>$1';


// The SQL modfield may be a qualified name like "T.LastUpdate". Remove the qualifier to get the QVD fieldname.
LET _vQvdModField = subfield('$(_vSqlModField)', '.', -1);	
SET _Qvc.Loader.v.TableModificationField = '$(_vQvdModField)';	// Save as private global var

// Set a variable indicating if the QVD exists or not
IF '$(_vForceFullReload)' THEN
	SET _vQvdExists = 0;	//ForceFullReload flag is on, treat as though QVD doesn't exist
ELSE  						// Test if qvd file exists
	LET _vQvdExists = $(Qvc.FileExists(_Qvc.Loader.v.QvdFile));
ENDIF

// Find the right function for predicate formatting
SET _tempLoaderPredicate = $(_Qvc.Loader.v.Predicate.$(Qvc.Loader.v.Database).$(Qvc.Loader.v.ModField.Type));

IF $(_vQvdExists) THEN		// QVD exists, we will do an incremental reload
	Call Qvc.Log('$(_Qvc.Loader.v.QvdFile) exists, rows=' & num(QvdNoOfRecords('$(_Qvc.Loader.v.QvdFile)'), '#$(ThousandSep)##0') );
	CALL Qvc.GetFieldValues ('_vDate', '$(_vQvdModField)',  '$(_Qvc.Loader.v.QvdFile)');
	SET Qvc.Loader.v.IncrementalFloor = $(_vDate.Max);	// Save copy for user defined custom where expression

	// Create a where predicate
	LET Qvc.Loader.v.IncrementalExpression = '$(_vSqlModField) ' & $(_tempLoaderPredicate($(_vDate.Max)));	
	Call Qvc.log ('Loading rows where $(Qvc.Loader.v.IncrementalExpression)') 
	
ELSE						// QVD does not exist
	IF len('$(Qvc.Loader.v.BaseValue)') > 0 THEN 
		LET Qvc.Loader.v.IncrementalExpression = '$(_vSqlModField) ' & $(_tempLoaderPredicate($(Qvc.Loader.v.BaseValue)));
		SET Qvc.Loader.v.IncrementalFloor = $(Qvc.Loader.v.BaseValue);	// Save copy for user defined custom where expression
	ELSE 
		SET Qvc.Loader.v.IncrementalExpression = '1=1';		// The always true predicate
		SET Qvc.Loader.v.IncrementalFloor =;
	ENDIF
	IF '$(_vForceFullReload)' THEN
		Call Qvc.log ('ForceFullReload requested. Doing full reload where $(Qvc.Loader.v.IncrementalExpression).');
	ELSE 
		Call Qvc.log ('QVD $(_Qvc.Loader.v.QvdFile) does not exist. Doing full reload where $(Qvc.Loader.v.IncrementalExpression).');
	ENDIF		
END IF

// Cleanup variables
SET _vQvdExists=;
SET _vBaseDate=; 
SET _vDate.Max=;
SET _vDate.Min=;
SET _tempLoaderPredicate =;
SET _Qvc.Loader.v.Predicate.SQLSERVER.Datetime=;
SET _Qvc.Loader.v.Predicate.SQLSERVER.Revision=;
SET _Qvc.Loader.v.Predicate.ORACLE.Datetime=;
SET _Qvc.Loader.v.Predicate.ORACLE.Revision=;
SET _Qvc.Loader.v.Predicate.SFDC.Datetime=;
SET _Qvc.Loader.v.Predicate.SFDC.Revision=;



END SUB;		// End of IncrementalSetup sub
SUB Qvc.IncrementalStore (_vDbKeyTable)
/**
@version $Id: Qvc_Incremental_Reload.qvs 229 2012-07-30 21:50:53Z rob@robwunderlich.com $
Update the QVD with changes from Incremental load. This is Step 2 of an incremental load process that supports insert, updates and optionally deletes.

If the optional parameter 1 is specified, delete processing will be done by inner joining the supplied key values with the QVD Primary Key. If parameter 1 is omitted, no delete processing will take place. 

This routine calls Qvc.UpdateQvd using the parameter values used in the last call to Qvc.IncrementalSetup.
@syntax CALL Qvc.IncrementalStore (['DbKeepKeys']);

@param 1 String, Optional. Name of table containing primary key values that should be kept in the QVD. The keys must be in the first field of the table. For performance reasons, the Fieldname should *not* be the same as the Primary Key Fieldname.

*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

// Copy Global Variables to local vars for the convienence of shorter names.
SET _vTablename = '$(_Qvc.Loader.v.Tablename)';
SET _vQvdFile = '$(_Qvc.Loader.v.QvdFile)';
SET _vQvdModField = '$(_Qvc.Loader.v.TableModificationField)';
SET _vTimestampMask = '$(Qvc.Loader.v.DatabaseDatetimeMask)';
SET _vPrimaryKey = '$(_Qvc.Loader.v.PrimaryKey)';

CALL Qvc.UpdateQvd ('$(_vTablename)', '$(_vQvdFile)', '$(_vPrimaryKey)', '$(_vDbKeyTable)', '$(_Qvc.Loader.v.ForceFullReload)'); 


// Update is done. Log some results */
CALL Qvc.log( '$(_vQvdFile) updated, rows=' & num(QvdNoOfRecords('$(_vQvdFile)'), '#$(ThousandSep)##0') )

//CALL Qvc.GetFieldValues ('_vDate', '$(_vQvdModField)', '$(_vTablename)');
//IF Qvc.Loader.v.ModField.Type = 'Datetime' THEN
//	LET _vDate.Min = timestamp($(_vDate.Min), '$(_vTimestampMask)');
//	LET _vDate.Max = timestamp($(_vDate.Max), '$(_vTimestampMask)');
//ENDIF
//CALL Qvc.log('$(_vQvdFile) min=$(_vDate.Min), max=$(_vDate.Max)')

DROP TABLE $(_vTablename);

// Cleanup variables

SET _Qvc.Loader.v.Tablename=;
SET _Qvc.Loader.v.QvdFile=;
SET _Qvc.Loader.v.PrimaryKey=;
SET _Qvc.Loader.v.TableModificationField=;
SET _Qvc.Loader.v.ForceFullReload=;

SET _vDate.Max=;
SET _vDate.Min=;
SET _vTablename=;
SET _vQvdFile=;
SET _vQvdModField=;
SET _vTimestampMask=;
SET _vPrimaryKey=;

END SUB		// End of IncrementalStore sub
SUB Qvc.UpdateQvd (_vTablename, _vQvdFile, _vPrimaryKey, _vDbKeyTable, _vReplaceQvd) 
/**
@version $Id: Qvc_Incremental_Reload.qvs 229 2012-07-30 21:50:53Z rob@robwunderlich.com $
Update a QVD with changed rows.

IF parameter ReplaceQvd is 0 or not specified, the QVD is CONCATENATE loaded to the Table using a WHERE NOT EXISTS(PrimaryKey) clause. If optional parameter 4 is specified, that table is INNER JOINed to remove rows that do not exist in the database. The QVD is then STOREd to the filesystem.

**NOTE** If you are using Qvc.IncrementalSetup(), use Qvc.IncrementalStore() to do the update instead of this routine.

@syntax CALL Qvc.UpdateQvd ('Table', 'QVDname', 'PrimaryKey', ['DbKeepKeys'], [ReplaceQvd]);

@param 1 String. Qlikview tablename. 
@param 2 String. QVD File Path. A relative name honors the current Directory setting.
@param 3 String. The Primary Key column of table.
@param 4 String, Optional. Name of table containing primary key values that should be kept in the QVD. The keys must be in the first field of the table. For performance reasons, the Fieldname should *not* be the same as the Primary Key Fieldname.
@param 4 True/False (-1/0). If True, existing QVD will be replaced without updates, as a full reload.

@var Qvc.Loader.v.KeyFieldIsUnique in True/False (-1/0). Default is true. Specify if the table uses unique (Primary) values for the Key Field. That is, every row contains a unique value (true). If false, duplicate values are allowed between rows and all rows of a given key value will replace rows of the same value from the master QVD.
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

// Set defaults
LET _vReplaceQvd=$(_Qvc.DefaultIfEmpty($(_vReplaceQvd), 0));

// Set a variable indicating if the QVD exists or not
IF '$(_vReplaceQvd)' THEN
	SET _vQvdExists = 0;	//vReplaceQvd flag is on, treat as though QVD doesn't exist
ELSE  						// Test if qvd file exists
	LET _vQvdExists = $(Qvc.FileExists(_vQvdFile));
ENDIF

REM If deletes requested;
IF len('$(_vDbKeyTable)') > 0 AND $(_vQvdExists) THEN
	LET _vDbKeyTable_Fieldname = FieldName(1,'$(_vDbKeyTable)');	// Get name of table field
	IF '$(_vDbKeyTable_Fieldname)' = '$(_vPrimaryKey)' THEN			// It can't be same as Primary Key or it will spoil the exists() test when we load QVD.
		CALL Qvc.LogWarning('DbKeyTable fieldname is same as PrimaryKey and will be renamed.');
		CALL _Qvc.UniqueId('_vDbKeyTable_Fieldname_Newname');		// Get a new fieldname
		// Copy the existing field to new name
		LEFT JOIN ([$(_vDbKeyTable)]) LOAD 
			DISTINCT [$(_vDbKeyTable_Fieldname)], 
			[$(_vDbKeyTable_Fieldname)] as [$(_vDbKeyTable_Fieldname_Newname)] 
			RESIDENT [$(_vDbKeyTable)];
		// Drop the original field from table.
		DROP FIELD [$(_vDbKeyTable_Fieldname)] FROM [$(_vDbKeyTable)];
	ENDIF
	
	SET _vDbKeyTable_Fieldname=;
	SET _vDbKeyTable_Fieldname_Newname=;
ENDIF

IF NOT '$(Qvc.Loader.v.KeyFieldIsUnique)' THEN
	// If not using unique keys, get all key values into a tem field.
	_qvctemp.PK_temp:
	LOAD FieldValue('$(_vPrimaryKey)', recno()) as [_qvctemp.PK_values] AUTOGENERATE FieldValueCount('$(_vPrimaryKey)');
	// Use the two parm exists test.
	SET _qvctemp.ExistsExpr = '[_qvctemp.PK_values],[$(_vPrimaryKey)]';
ELSE 
	// Use the single parm exists test.
	SET _qvctemp.ExistsExpr = '[$(_vPrimaryKey)]';
ENDIF

REM If incremental reload, load previous data and concatenate to data just read.;
IF $(_vQvdExists) THEN
// Concatenate is required if adding fields
	CONCATENATE ($(_vTablename))
	LOAD * FROM $(_vQvdFile) (qvd)
	WHERE NOT exists($(_qvctemp.ExistsExpr))
	;
END IF

// Clean up temp vars
SET _qvctemp.ExistsExpr=;
IF $(_Qvc.TableExists(_qvctemp.PK_temp)) THEN 
	DROP TABLE _qvctemp.PK_temp;
ENDIF

REM If deletes requested;
IF len('$(_vDbKeyTable)') > 0 AND $(_vQvdExists) THEN
	Call Qvc.Log ('Before deletes: $(_vTablename) rows=' & num(NoOfRows('$(_vTablename)'), '#$(ThousandSep)##0'));
	LET _vDbKeyTable_Fieldname = FieldName(1,'$(_vDbKeyTable)');
	INNER JOIN ([$(_vTablename)]) LOAD [$(_vDbKeyTable_Fieldname)]  AS [$(_vPrimaryKey)] RESIDENT [$(_vDbKeyTable)];
	Call Qvc.Log ('After deletes: $(_vTablename) rows=' & num(NoOfRows('$(_vTablename)'), '#$(ThousandSep)##0'));
	DROP TABLE [$(_vDbKeyTable)];		// Drop the Key Table
	
	SET _vDbKeyTable_Fieldname=;
ENDIF

STORE $(_vTablename) INTO $(_vQvdFile);

// Cleanup variables
SET _vQvdExists=;

END SUB		// End of Qvc.UpdateQvd Sub


SUB Qvc.JoinGenericTables (_targetTable, _genericTables)
/**
@version $Id: Qvc_JoinGenericTables.qvs 186 2012-04-07 23:36:07Z rob@robwunderlich.com $
Join Generic loaded output tables to a target table. 

@param 1 String. Table to be joined to. This is usually the table that was the source of the Generic load.
@param 2 String. The table name prefix for the generic output tables. This is the tablename label assigned in the Generic load.

@syntax CALL Qvc.JoinGeneric('TargetTable', 'GenericTablesPrefix'); 
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

//  Do a JOIN & DROP loop to consolidate generated generic tables
FOR _qvctemp.i = 0 to NoOfTables()
	_qvctemp.temptable:
	LOAD TableName($(_qvctemp.i)) as _qvctemp.Tablename AUTOGENERATE 1
	WHERE WildMatch(TableName($(_qvctemp.i)), '$(_genericTables).*');
NEXT _qvctemp.i

FOR _qvctemp.i = 1 to FieldValueCount('_qvctemp.Tablename')
	LET _qvctemp.vTable = FieldValue('_qvctemp.Tablename', $(_qvctemp.i));
	LEFT JOIN ([$(_targetTable)]) LOAD * RESIDENT [$(_qvctemp.vTable)];
	DROP TABLE [$(_qvctemp.vTable)];
NEXT _qvctemp.i

DROP TABLE _qvctemp.temptable;

SET _qvctemp.i=;
SET _qvctemp.vTable=;

END SUB


SUB Qvc.LinkTable (_linkTableName, _table, _fields)
/**
@version $Id: Qvc_LinkTable.qvs 186 2012-04-07 23:36:07Z rob@robwunderlich.com $
Create or update a LinkTable. 

The Fields specfied in parameter 3 will be moved from the source table specified in parameter 2, into the link table specified by parameter 1. 

If the link table does not exist, it will be created. If it does exist, it will be updated. 

@param 1 String. Name of new or existing Link Table.
@param 2 String. Table to load fields from.
@param 3 String. Comma seperated list of fields to move from source table to Link Table.

@syntax CALL Qvc.LinkTable('LinkTableName', 'SourceTableName', 'Field1, Field2, ...'); 
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

// Make a name for the temp link table
CALL _Qvc.UniqueId('_vId');
LET _LinkTableTemp = '$(_linkTableName)' & '_temp_' & '$(_vId)';
[$(_LinkTableTemp)]:
NOCONCATENATE LOAD DISTINCT 		// Load fields from source table to link table
	$(_fields),
	AutoNumberHash128($(_fields)) as %$(_linkTableName)_Key
RESIDENT $(_table);

LEFT JOIN ($(_table))	// Join key from link table to source table
LOAD DISTINCT %$(_linkTableName)_Key, $(_fields) RESIDENT $(_LinkTableTemp);

DROP FIELDS $(_fields) FROM $(_table);		// Drop fields from source table

IF $(_Qvc.TableExists($(_linkTableName))) THEN
	CONCATENATE ([$(_linkTableName)])
	LOAD *
	RESIDENT [$(_LinkTableTemp)];
	DROP TABLE [$(_LinkTableTemp)];

ELSE
	RENAME TABLE [$(_LinkTableTemp)] TO [$(_linkTableName)];
ENDIF

SET _LinkTableTemp=;
SET _vId=;

END SUB

SUB Qvc.ListDirectories (dir, mask, subdirectories, callback)
/**
@version $Id: Qvc_ListDirectories.qvs 191 2012-04-11 04:00:07Z rob@robwunderlich.com $
List filesystem directories. 

If the callback parameter is specified, the callback SUB is called for each directory with dirpath as a calling parameter.

If no callback parameter (4) is specified, a table named "Qvc.ListDirectoriesTable" will be created.

@param 1 String. Starting directory. May be relative or absolute.
@param 2 String, Optional. Mask pattern to limit scan. For example, '*-prj'. Default is '*'.
@param 3 True/False, Optional. If true (-1), process subdirectories. If false (0), don't process subdirectories. Default is True.
@param 4 String, Optional. Name of subroutine to call for each directory path. 

@syntax CALL Qvc.ListFiles('starting directory', ['mask'], ['subdirectories'], ['callbackSub']); 
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

// Add a trailing backslash to dir parm if not already provided.
IF len('$(dir)')>0 AND right('$(dir)',1) <> '\' THEN
	LET dir='$(dir)' & '\';
ENDIF

LET mask = $(_Qvc.DefaultIfEmpty($(mask), '*'));
LET subdirectories = $(_Qvc.DefaultIfEmpty($(subdirectories), -1));
LET _doCallback = if(len('$(callback)')>0,-1,0);	// Set flag if callback parm is present

CALL  _Qvc.ListDirectories._Listone ('$(dir)');		// call the directory lister for starting directory

	
SET _doCallback=;
SET _qvctemp.dir=;
	
END SUB

SUB _Qvc.ListDirectories._Listone (dir)
// Load info about each directory
FOR EACH _qvctemp.dir in DirList('$(dir)$(mask)');
	IF $(_doCallback) THEN
		CALL $(callback) ('$(_qvctemp.dir)');
	ELSE
		Qvc.ListDirectoriesTable:
		LOAD 
			'$(_qvctemp.dir)' as [Directory Path]
		AutoGenerate 1
		;
	ENDIF
	
	// Recursively process subdirectories
	IF '$(subdirectories)' THEN
		CALL  _Qvc.ListDirectories._Listone ('$(_qvctemp.dir)\');
	ENDIF
NEXT _qvctemp.dir;
END SUB


SUB Qvc.ListFiles (dir, mask, subdirectories, callback)
/**
@version $Id: Qvc_ListFiles.qvs 186 2012-04-07 23:36:07Z rob@robwunderlich.com $
List files from a directory and it's subdirectories.

If the callback parameter is specified, the callback SUB is called for each file with filepath as a calling parameter.

@param 1 String. Starting directory. May be relative or absolute.
@param 2 String, Optional. File mask pattern to limit scan. For example, '*.qvd'. Default is '*'.
@param 3 True/False, Optional. If true (-1), process subdirectories. If false (0), don't process subdirectories. Default is True.
@param 4 String, Optional. Name of subroutine to call with each filepath. 

@syntax CALL Qvc.ListFiles('starting directory', ['filemask'], ['subdirectories'], ['callbackSub']); 
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

LET mask = $(_Qvc.DefaultIfEmpty($(mask), '*'));
LET subdirectories = $(_Qvc.DefaultIfEmpty($(subdirectories), -1));
LET _doCallback = if(len('$(callback)')>0,-1,0);	// Set flag if callback parm is present

// Load info about each file in the directory
FOR EACH _file in filelist('$(dir)' &  '\' & '$(mask)');
	IF $(_doCallback) THEN
		CALL $(callback) ('$(_file)');
	ELSE
		Qvc.ListFilesTable:
		LOAD 
			'$(_file)' as [File Path]
		AutoGenerate 1
		;
	ENDIF
NEXT _file;
// We have processed all the files in the directory.
// Now recursively process subdirectories of $(dir)
IF '$(subdirectories)' THEN
	FOR EACH _subdir in dirlist( '$(dir)' & '\*' )
		CALL Qvc.ListFiles('$(_subdir)', '$(mask)', '$(subdirectories)', '$(callback)')
	NEXT _subdir;
ENDIF	
	
SET _doCallback=;
SET _file=;
SET _subdir=;
	
END SUB


/* Logging subroutine */
REM Default configuration for Qvc.Log;

SET Qvc.Log.v.LogTable = 'Qvc.LogTable';
SET Qvc.Log.v.LogField = 'Qvc.LogMessage';
SET Qvc.Log.v.LogLevelField=;
//SET Qvc.Log.v.LogDir='.';	// Directory to put logs. Default is current. 
LET Qvc.Log.v.LogFileName = left(DocumentPath(), index(DocumentPath(),'.',-1)-1) & '_log.txt';
SET Qvc.Log.v.WriteLogFile = 0;	// Write external log file, true/false
SET Qvc.Log.v.KeepDays=0;		// How many days of log to keep, 0 means overwrite every time


REM Constants for Qvc.Log;
SET Qvc.Log.v.Level.INFO=INFO;
SET Qvc.Log.v.Level.WARNING=WARNING;
SET Qvc.Log.v.Level.ERROR=ERROR;

// Code
SUB Qvc.Log (_msg, _level)
/**
@version $Id: Qvc_Log.qvs 206 2012-06-05 16:01:47Z rob@robwunderlich.com $
Write a message line to a log table and external file.

The default name for the external log file is documentName_log.txt and it is stored in the same directory as the qvw. Writing of the external file may be suppressed by setting config variable Qvc.Log.v.LogFile to empty.

@syntax CALL Qvc.Log ('Message to be logged', ['level']);
@param 1 Message string to be written to the log.
@param 2 Optional. The severity level to be assigned to this message. One of the Qvc.Log.v.Level.* constants, where * is INFO, WARNING or ERROR. If omitted, default is Qvc.Log.v.Level.INFO.

@var Qvc.Log.v.LogTable in String. Tablename for the log table. Default is 'Qvc.LogTable'.
@var Qvc.Log.v.LogField in String. Fieldname for the log message. Default is 'Qvc.LogMessage'.
@var Qvc.Log.v.LogLevelField in String. Fieldname for the log level. Default is '$(Qvc.Log.v.LogField)_Level'.
@var Qvc.Log.v.LogFileName in String. External filename where log messages will be written. Default is qvwname_log.txt.
@var Qvc.Log.v.WriteLogFile in -1/0 (true/false). If true, write log to external file. Default is false.
@var Qvc.Log.v.KeepDays in Number. Number of days of log to keep in logfile. Log records older than this will be rolled off. If 0 (default), log will be overwritten with every reload.
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

LET _level=$(_Qvc.DefaultIfEmpty($(_level), $(Qvc.Log.v.Level.INFO)));
SET _defaultLevelField='$(Qvc.Log.v.LogField)_Level';
LET _levelField=$(_Qvc.DefaultIfEmpty($(Qvc.Log.v.LogLevelField), $(_defaultLevelField)));
	
UNQUALIFY [$(Qvc.Log.v.LogField)], [$(_levelField)];	// Ensure unqualified

IF NOT $(_Qvc.TableExists($(Qvc.Log.v.LogTable))) THEN	// First call to Log
	SET _Qvc.Log.v.LineCounter=0;	// Default
ENDIF

IF $(Qvc.Log.v.KeepDays) > 0 THEN		// If requested to keep previous logs...
	IF NOT $(_Qvc.TableExists($(Qvc.Log.v.LogTable))) AND $(Qvc.FileExists('$(Qvc.Log.v.LogFile)')) THEN	// and we haven't loaded it
		[$(Qvc.Log.v.LogTable)]:
		LOAD 
			@1 as [$(_levelField)], 
    	 	@2 as [$(Qvc.Log.v.LogField)]
		FROM [$(Qvc.Log.v.LogFile)]
		(txt, no labels, delimiter is ',', msq, header is 1 lines)
		WHERE today(1) - Date#(subfield(@2,' ',2)) < $(Qvc.Log.v.KeepDays)
		; 
		// Get max value of current counter
		LET _Qvc.Log.v.LineCounter = subfield(peek('$(Qvc.Log.v.LogField)'),' ',1);
	ENDIF
ENDIF

LET _Qvc.Log.v.LineCounter = _Qvc.Log.v.LineCounter + 1;
[$(Qvc.Log.v.LogTable)]:
LOAD
	'$(_level)' as [$(_levelField)],
	num($(_Qvc.Log.v.LineCounter), '00000') & ' ' & now(1) & '; ' & '$(_msg)' as [$(Qvc.Log.v.LogField)]
AUTOGENERATE 1
;
IF '$(Qvc.Log.v.WriteLogFile)' THEN		// If writing to external logfile
	STORE [$(Qvc.Log.v.LogTable)] into [$(Qvc.Log.v.LogFileName)] (txt);
ENDIF

// Cleanup local variables
SET _level=;
SET _defaultLevelField=;
SET _levelField=;

END SUB
/* * End of Qvc.Log subroutine * */

SUB Qvc.LogError (_msg)
/**
@version $Id: Qvc_Log.qvs 206 2012-06-05 16:01:47Z rob@robwunderlich.com $
Writes an error level message to the Qvc.Log. Convienence sub that calls Qvc.Log('message',Qvc.Log.v.Level.ERROR). 
@syntax CALL Qvc.LogError ('Message to be logged');
@param 1 Message string to be written to the log.
*/
	CALL Qvc.Log(_msg, '$(Qvc.Log.v.Level.ERROR)');
END SUB

SUB Qvc.LogWarning (_msg)
/**
@version $Id: Qvc_Log.qvs 206 2012-06-05 16:01:47Z rob@robwunderlich.com $
Writes an warning level message to the Qvc.Log. Convienence sub that calls Qvc.Log('message',Qvc.Log.v.Level.WARNING). 
@syntax CALL Qvc.LogError ('Message to be logged');
@param 1 Message string to be written to the log.
*/
	CALL Qvc.Log(_msg, '$(Qvc.Log.v.Level.WARNING)');
END SUB
SUB Qvc.PopulateVariables (_vartable, _useLET)
/**
@version $Id: Qvc_PopulateVariables.qvs 186 2012-04-07 23:36:07Z rob@robwunderlich.com $
Populate variables from a two column table.

Column 1 of the table contains variable names. The variables will be SET to the contents of column 2 on the corressponding row. 

If optional parameter 2 is set to true (-1), then the variable assignment will be made using the LET statement instead of SET.

@param 1 String. Table of variable name/value pairs to populate from. Field 1 of the table contains variable names, field 2 variable values.
@param 2 True/False (-1/0). If true, use LET statement to assign variable values. Oterwise use SET.

@syntax CALL Qvc.PopulateVariables('vartable', [useLET]); 
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

LET _useLET = if(len('$(_useLET)')=0, 0, -1);	// Default for useLET is false

LET _varname_field = FieldName(1,'$(_vartable)');	// Get variable name
LET _varvalue_field = FieldName(2,'$(_vartable)');

FOR _i = 0 to NoOfRows('$(_vartable)')-1;
	// Get the varname for this row
	LET _varname = peek('$(_varname_field)',$(_i),'$(_vartable)');
	// Get the value for this row
	LET _varvalue = peek('$(_varvalue_field)',$(_i),'$(_vartable)');
	
	// Set the variable value
	IF $(_useLET) THEN		// If LET requested
		LET $(_varname)=$(_varvalue);	
	ELSE					// Else use SET
		SET $(_varname)=$(_varvalue);	
	ENDIF
NEXT _i;	

SET _i=;
SET _varname_field=;
SET _varvalue_field=;
SET _varname=;
SET _varvalue=;

END SUB


SUB Qvc.QvcAvailableUpdate (_retvar)
/**
@version $Id: Qvc_QvcAvailableUpdate.qvs 186 2012-04-07 23:36:07Z rob@robwunderlich.com $
Test if a newer version of Qvc is available for download. If a newer version is available, the new version number will be returned. If a newer version is not available, null will be returned.
    
@syntax CALL Qvc.QvcAvailableUpdate(vRetvar);

@param 1 Variable in which to return result.
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

_qvctemp.QvcAvailableUpdate:
NOCONCATENATE
LOAD 
	text(DownloadableQvcVersion) as _qvctemp.DownloadableQvcVersion
FROM
[http://qlikview-components.googlecode.com/svn/QVC_Source/LatestQvcDownloadVersion.txt]
(txt, codepage is 1252, embedded labels, delimiter is ',', msq)
;

LET _retvar = if(peek('_qvctemp.DownloadableQvcVersion') > '$(Qvc.Global.v.Version)', peek('_qvctemp.DownloadableQvcVersion'), null());

DROP TABLE _qvctemp.QvcAvailableUpdate;

END SUB
SUB Qvc.TableStats (_msg, _tableIncludeList)
/**
@version $Id: Qvc_TableStats.qvs 195 2012-05-29 22:34:59Z rob@robwunderlich.com $
Write statistics about current Qlikview tables to the Qvc.Log. 

One log line will be written for each table. Header and footer lines will be written at the begining and end of each set of lines. If Parameter 1 is specified, the parameter string will be included in the header and footer. 

@syntax CALL Qvc.TableStats (['Optional message'], ['includeTable1, includeTable2, ...'])
@param 1 String, Optional. Message that will be used at the begining and end of the log lines.
@param 2 String, Optional. Comma seperated list of tablenames to be reported on. The names may include wildcards. If omitted, default is '*'.
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

// Default tableIncludeList is '*'
LET _tableIncludeList = if(len('$(_tableIncludeList)')>0, '$(_tableIncludeList)', '*');
// Format input parm for use in WildMatch
// Parm input is like: 'table1, table2'.
// Wildmatch needs: 'table1','table1'.
_qvctemp.parmTable:
LOAD
// For each tablename, remove leading/trailing blanks and quote the name.
chr(39) & concat(trim(_qvctemp.tablename), chr(39) & ',' & chr(39)) & chr(39) as _qvctemp.StringList
;
// Break up at commas
LOAD subfield('$(_tableIncludeList)', ',') AS _qvctemp.tablename AutoGenerate 1
;
LET _tableIncludeList = peek('_qvctemp.StringList');	// Update the variable with formatted list
DROP TABLE _qvctemp.parmTable;


// Flag begin of Log block
CALL Qvc.Log('TableStats Begin: $(_msg)');

LET _qvctemp.counter = 0;
FOR _i = 0 to NoOfTables()-1
	LET _tablename = TableName($(_i));
	IF WildMatch('$(_tablename)', $(_tableIncludeList)) > 0 THEN
		LET _tableinfo = 'Table=$(_tablename)' 
			& ', Rows=' & num(NoOfRows('$(_tablename)'), '#$(ThousandSep)##0')
			& ', Fields=' & NoOfFields('$(_tablename)') 
			
			;
		CALL Qvc.Log('$(_tableinfo)');
		LET _qvctemp.counter = $(_qvctemp.counter)+1;
	ENDIF
NEXT _i

CALL Qvc.Log('$(_qvctemp.counter) tables listed.')
CALL Qvc.Log('TableStats End: $(_msg)');

// Cleanup variables
SET _i=;
SET _tablename=;
SET _tableinfo=;
SET _tableIncludeList=;
SET _msg=;
SET _qvctemp.counter=;

END SUB

SUB Qvc.GetFieldValues (_retvar, _field, _vTable)
/**
@version $Id: Qvc_Utility.qvs 207 2012-06-13 04:42:03Z rob@robwunderlich.com $
Get min & max values for a Field. The values are set in compound variables names using parameter 1 as the prefix. For example, if parameter 1 is 'vStat', the set variables will be:

	vStat.Min  =  the Min value of the field.
	vStat.Max  =  the Max value of the field.
    
@syntax CALL Qvc.GetFieldValues('vStats', 'LastUpdate', ['Transactions.qvd']);

@param 1 String. Variable stem name in which to return values. Variables created will stem.Max, stem.Min.
@param 2 String. The field name.
@param 3 String, Optional. Source that contains the field. If Source ends with '.qvd', source is assumed to be a QVD. If not, Source is a RESIDENT table. If omitted, all values of field are the source.
*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

IF len('$(_vTable)')=0 THEN
	SET _vSource = ";LOAD FieldValue('$(_field)', recno()) as [$(_field)] AUTOGENERATE FieldValueCount('$(_field)')";
ELSEIF index('$(_vTable)', '.') = 0 THEN
	SET _vSource = 'RESIDENT $(_vTable)';
ELSEIF '.qvd' = lower(right('$(_vTable)', 4)) THEN
	SET _vSource = 'FROM $(_vTable) (qvd)';
ELSE 
	SET _vSource = 'FROM $(_vTable)';	// Assume text file
ENDIF

_qvctemp.temptab:
LOAD 
	// +0 is to fix a bug in V10 where max is getting truncated to 9 digits precision.
	max([$(_field)])+0 as _qvctemp.maxval,
	min([$(_field)])+0 as _qvctemp.minval	
$(_vSource);
// Replace of European DecimalSep ',' is required to assure returned value is proper decimal number, not formatted string
LET $(_retvar).Max = replace(peek('_qvctemp.maxval'), ',', '.');
LET $(_retvar).Min = replace(peek('_qvctemp.minval'), ',', '.');
DROP table _qvctemp.temptab;

SET _vSource=;
END SUB
/** 
@Function Qvc.FileExists
@version $Id: Qvc_Utility.qvs 207 2012-06-13 04:42:03Z rob@robwunderlich.com $
Returns true if a file exists. This function may only be used in script.

@syntax LET vExists = $(Qvc.FileExists('dir\filename.ext'));

@param 1 The relative or absolute file path as string.
*/
SET Qvc.FileExists = if(len(FileSize($1)) > 0, -1, 0);
/*
@EndFunction
*/
/** 
@Function _Qvc.DefaultIfEmpty
@version $Id: Qvc_Utility.qvs 207 2012-06-13 04:42:03Z rob@robwunderlich.com $
Returns a default value if paramter not supplied

@syntax LET _param = $(_Qvc.DefaultIfEmpty('_param', 'String default'));

@param 1 The parameter.
@param 2 The value to be assigned if param 1 is empty.
*/
SET _Qvc.DefaultIfEmpty = if(len('$1')= 0,'$2', '$1');
/*
@EndFunction
*/
SET _Qvc.UniqueId.v.Counter=0;
SUB _Qvc.UniqueId (_retvar)
/**
@version $Id: Qvc_Utility.qvs 207 2012-06-13 04:42:03Z rob@robwunderlich.com $
Returns a unique identifier on each call.
@syntax CALL _Qvc.UniqueId ('returnVariable');
@param 1 Variable in which to return new unique identifier, quoted.
*/
	LET _Qvc.UniqueId.v.Counter = $(_Qvc.UniqueId.v.Counter) + 1;
	LET $(_retvar) = 'UID' & num($(_Qvc.UniqueId.v.Counter), '00000000');
END SUB

/** 
@Function Qvc.FieldContains
@version $Id: Qvc_Utility.qvs 207 2012-06-13 04:42:03Z rob@robwunderlich.com $
Search a field for the specified value. Returns true if a the value is found in the possible values.

@syntax LET vContains = $(Qvc.FieldContains(Field, searchValue));

@param 1 Field to be searched. No quotes.
@param 2 Value to be searched for. String values must be enclosed in single quotes. If no quotes, the searchValue will be evaluated. 1+1 is the same as searching for '2'.
*/
SET Qvc.FieldContains=sum(if($1=$2,1))>0;
/*
@EndFunction
*/

/** 
@Function _Qvc.TableExists
@version $Id: Qvc_Utility.qvs 207 2012-06-13 04:42:03Z rob@robwunderlich.com $
Returns true if a table exists in the current script.

@syntax LET vTableExists = $(_Qvc.TableExists(tablename));

@param 1 Tablename, no quotes.
*/
SET _Qvc.TableExists = len(NoOfRows('$1'))>0;
/*
@EndFunction
*/


SUB Qvc.CreateWildMapExpression (_expressionVar, _table)
/**
@version $Id: Qvc_WildMap.qvs 231 2012-08-16 16:16:42Z rob@robwunderlich.com $
Create an Expression for Wildcard mapping.

The generated expression is a pick(match()) expression that may be used to map values using wildcard characters in the "from" string.

@syntax CALL Qvc.CreateWildMapExpression (vMapExpr, WildMapTable);

@param 1 Variable to return the expression in. 
@param 2 Table that holds map values. The first column has "from" (key) values, the second column "to" values.

*/
UNQUALIFY "_qvctemp.*";	// UNQUALIFY all qvctemp fields

LET _MapKeyField = FieldName(1, '$(_table)');
LET _MapValueField = FieldName(2, '$(_table)');

_MapExprTable:
LOAD 
'pick(wildMatch($1,' & chr(39) 
& concat($(_MapKeyField), chr(39) & ',' & chr(39), RecNo()) 
& chr(39)
& '), ' & chr(39)
& concat($(_MapValueField), chr(39) & ',' & chr(39), RecNo())
& chr(39) & ')' as _qvctemp._MapExpr
RESIDENT $(_table)
;
LET _expressionVar = peek('_qvctemp._MapExpr', -1);
DROP TABLE _MapExprTable;
SET _MapKeyField=;
SET _MapValueField=;

END SUB
/* * End of Qvc.CreateWildMapExpression subroutine * */

REM ===== End of Qlikview Components included Qvc.qvs version 5.1 =====;
///$tab SOIO Variables
////
//LET v_search_folders='N' ;
//LET v_remove_invalid_timestamp_rows_YN = 'N';
////LET v_remove_leading_timestamp_and_text_from_backup_log_files = 'Y' ;
//LET vLogDir = '.\' ;
	
///$tab Variables
//=====================================================
// Determine the absolute path of the logfile dir
//=====================================================
FOR EACH vDir IN dirlist('$(vLogDir)')
	EXIT FOR WHEN 1;
NEXT 
SET vLoadedLogDir = $(vLogDir);
SET vDir=;


//=== Initial display limit ===
Set vDurationLimit=0;		// For limiting display by duration

//====================================================================================
// Variable expressions for OperationDuration background and (inverse) text color. 
// The @=$ replace() trick is necessary because LET tries to evalauate $ parms.
//====================================================================================
// Text color
LET vDurationTextColor = replace(
'if(OperationDuration >0
	,ColorMix1(OperationDuration / max({1<%LogFileKey = {@(=only(%LogFileKey))}>} TOTAL OperationDuration)
	,ARGB(255, 0, 0, 0), ARGB(255, 255, 255, 255)
	)
)'
,'@', '$'
)
;
// Background color
LET vDurationBackgroundColor = replace(
'if(OperationDuration >0 
	,ColorMix1(OperationDuration / max({1<%LogFileKey = {@(=only(%LogFileKey))}>} TOTAL OperationDuration)
	,ARGB(255, 255, 225, 225), ARGB(255, 128, 0, 0)
	)
)'
,'@', '$'
)
;

//==== Various Colors ====
LET vColorGreen=RGB(128,255,128);
LET vColorRed=ARGB(128,255,128,128);
LET vColorYellow=RGB(255,255,128);
LET vColorBlue=RGB(141,170,203);

///$tab Matches
//===================================================
// Create a table of logfile phrases we will search for,
// and map them to Operation buckets. 
//===================================================
WildMapTable:
LOAD * INLINE [
Mask, Type
NOCONCATENATE*LOAD*, Load
* NOCONCATENATE*LOAD*, Load
*NOCONCATENATE*, Load
* NOCONCATENATE*, Load
CONCATENATE*, Load
* CONCATENATE*, Load
CONCATENATE, Load
CONCATENATE*, Load
*CONCATENATE*, Load
CONCATENATE(*, Load
CONCATENATE*(*, Load
* fields found:*, LoadEnd
*fields found:*, LoadEnd
*Joining/Keeping*, JoinEnd
* FIELDS FOUND:*, LoadEnd
*FIELDS FOUND:*, LoadEnd
JOIN *, Join
JOIN(*, Join
LEFT*JOIN*, Join
LEFT*JOIN *, Join
*LEFT*JOIN*, Join
RIGHT*JOIN*, Join
INNER*JOIN*, Join
OUTER*JOIN*, Join
KEEP *, Join
KEEP(*, Join
LEFT*KEEP*, Join
RIGHT*KEEP*, Join
INNER*KEEP*, Join
OUTER*KEEP*, Join
* LOAD*, Load
LOAD*, Load
LOAD, Load
*SQL SELECT*, Load
*SQL*, Load
Execution Failed, ExecFailed
* MAPPING, Load
*MAPPING, Load
* MAPPING , Load
MAPPING*, Load
MAPPING *, Load
*DROP*TABLE*, Admin
*DROP*TABLES*, Admin
DROP*TABLE*, Admin
DROP*TABLES*, Admin
*DROP*TABLE, Admin
*DROP*TABLES, Admin
DROP*TABLE, Admin
DROP*TABLES, Admin
TABLE_NAMING ,Load
*TABLE_NAMING *,Load
TABLE_NAMING*,Load
*TABLE_NAMING,Load
*, Other
]
;

//*SELECT*, Load//
// TABLE_NAMING,Load added by SOIO


// Create the mapping expression in variable vMapExpr
CALL Qvc.CreateWildMapExpression (vMapExpr, 'WildMapTable');
DROP TABLE WildMapTable;	// No longer need table

trace vMapExpr =$(vMapExpr);
//EXIT SCRIPT ;
///$tab  
///$tab Start SUB LogData
//======================================================
REM Start of LoadLog SUB run for each logfile. ;
//======================================================
SUB LoadLog (_logpath)

//=== Valid Timestamp characters ===
SET vTimestampChars = '0123456789/.:ampmAMPM ';
///$tab LogSummary
//======================================================
// Load summary data about this log.
//======================================================
LogSummary:
LOAD 
    autonumber(FilePath(), 'LogFileKey') as %LogFileKey,
    FilePath() as LogFilePath,
    FileName() as LogFileName,
    FileTime() as LogFileTime
FROM [$(_logpath)]
(fix, codepage is 1252)
;

LET vLogFileKey = peek('%LogFileKey',-1, 'LogSummary');		// Needed later

TRACE vLogFileKey = [$(vLogFileKey)] ;

//exit script ;
///$tab Get vEncoding
/*
Each format specification item defines a certain property of the table file:
fspec-item ::= [ ansi | oem | mac | UTF-8 | Unicode | txt | fix | dif | biff | html | xml | qvd

Character Set
Available character sets are:
ansi
oem
mac
UTF-8
Unicode
The file can be written with the ansi character set (Windows), with the oem character set (DOS, OS/2 and others), Unicode, UTF-8 or with the mac. The conversion from the oem

todo
what does 'n' in the following expression represent [LOAD IsNum(left(@1:n,1)]??

*/

//TRACE n=$(n);

//======================================================
// Parse the log into functions and break out the Timestamps.
//======================================================
//
// Determine the character encoding of the logfile.
// QV11.2 is writing logs in unicode.
FOR EACH vEncoding IN 'utf8', 'unicode', 'codepage is 1252', 'ANSI', 'OEM', 'mac' ;
	TempCode:
	FIRST 1							// Log first row
	LOAD IsNum(left(@1:n,1)) as X		// Test first char. Set to true if it's a number.
	FROM
	[$(_logpath)]
	(fix, $(vEncoding))
	;
	 EXIT FOR WHEN IsNum (peek('X'));		// If a number, assume we have the right encoding.
NEXT vEncoding;


IF NOT peek('X') THEN		// If we didn't find an encoding, then write a log message

	//CALL Qvc.LogError('Unable to determine encoding for [$(_logpath)]');
	trace ERROR: Unable to determine encoding for [$(_logpath)] ;
	LET v_encoding_successful = 'N' ;

ELSE

	LET v_encoding_successful = 'Y' ;
	trace vEncoding=[$(vEncoding)];
	
	//exit script;
END IF ;

//TODO: Note that we continue even if we didn't find an encoding. We'll probably fail the timestamp test later. 
DROP TABLE TempCode;

TRACE v_encoding_successful = [$(v_encoding_successful)] ;

// We now have the logfile encoding in var vEncoding.

//exit script;
///$tab Main 31
SUB write_out_what_it_sees (param_table_name, param_description_prefix) ;


STORE '$(param_table_name)' INTO '.\$(param_description_prefix)_$(param_table_name).TXT' (TXT) ;




END SUB ; //write_out_what_it_sees
///$tab >>>>
///$tab Handle if encoding is known or not
// 6/6/2015 11:08:01 AM:               	9 fields found: %LogFileKey, LogText, temporary_log_table.ROW_NUMBER, contents_of_complete_line, command_text, first_whole_word, second_whole_word, text_after_first_whole_word, previous_first_whole_word, 13,457 lines fetched

/*

This is a quickfix that prevents TRACE command output confusing the script
e.g. A command line similar to [TRACE JOIN to table <xyx>] will generate LOG output [JOIN to table <xyx>] and the script will interpet this as a JOIN operator

The solution below will LOAD the whole script, detect which line represents a TRACE command and then alter the line followig the TRACE to be prefixed with [TRACE_OUTPUT]

example - original LOG output: 
5/12/2015 6:19:01 AM: 2911    CALL SUB_TRACE_EVENT ('Join Calendar') 
5/12/2015 6:19:01 AM: 0182      TRACE Join Calendar 
5/12/2015 6:19:01 AM: 0182      Join Calendar 

amended
5/12/2015 6:19:01 AM: 2911    CALL SUB_TRACE_EVENT ('Join Calendar') 
5/12/2015 6:19:01 AM: 0182      TRACE Join Calendar 
5/12/2015 6:19:01 AM: 0182      TRACE_OUTPUT Join Calendar 


*/
LET global.execution_started_text			= 'Execution started.'; 
let global.v_log_table_name					= 'temporary_log_table' ;
LET global.maximum_length_of_log_text_line	= 1024 ;

IF v_encoding_successful = 'Y' THEN ;
	
	$(global.v_log_table_name):
	NOCONCATENATE
	LOAD
		*
		,
		RowNo() 	as $(global.v_log_table_name).ROW_NUMBER,
		LogText 	as contents_of_complete_line
	;
	LOAD 
		autonumber(FilePath(), 'LogFileKey') as %LogFileKey,
		// the syntax underlining below does not indicate a genuine error. I dont know why its doing that
	    @1:n as LogText
	FROM [$(_logpath)]
	(fix, $(vEncoding) )
	WHERE len(trim(@1:n))>19	// Only records that have a timestamp
	;
ELSE
	TRACE v_encoding_successful <> 'Y' so adjusting text ;
	
	
	$(global.v_log_table_name):
	NOCONCATENATE
	LOAD
		*
		, LogText as contents_of_complete_line
	;
	LOAD
		%LogFileKey
		,
		RecNo () 	as $(global.v_log_table_name).ROW_NUMBER
		,
		IF (
			RecNo () = 1, 
			//'steven'
			MID (LogText, FINDONEOF (LogText, '0123456789'),1024) // assuming LOG line is not longer than 1024
			,
			LogText
			) as LogText
	;
	LOAD 
		autonumber(FilePath(), 'LogFileKey') as %LogFileKey,
		// the syntax underlining below does not indicate a genuine error. I dont know why its doing that
	    @1:n as LogText
	FROM [$(_logpath)]
	(fix)
	WHERE len(trim(@1:n))>19	// Only records that have a timestamp
	;
end if ;

//	// take contents of $(global.v_log_table_name) and grab first line
//	// use findoneof to remove encoding characters
//	// concatenate tidied first line back to all lines except line 1
//
//	LET v_first_line_with_encoding 				= PEEK ('contents_of_complete_line', 0, '$(global.v_log_table_name)') ;
//	LET v_first_line_with_encoding_removed 		= MID (v_first_line_with_encoding, FINDONEOF (v_first_line_with_encoding, '0123456789'),1024)  ; // Used 1024 characters coz i dont expect any LOG line to be longer than that
//	
//	TRACE v_first_line_with_encoding = [$(v_first_line_with_encoding); 	TRACE v_first_line_with_encoding_removed = [$(v_first_line_with_encoding_removed)];
//	
//	LOAD * INLINE [
//	$(global.v_log_table_name).ROW_NUMBER,contents_of_complete_line,%LogFileKey,LogText
//
//END IF ;
//

//exit script;




///$tab Handle extra leading timestamp and "Information" text
/*

A value of Y will remove leading timestamps generated by the automated backup process e.g. 6/10/2015<space>05:45:56.5254850<TAB>Information<space>"
A value of N will leave all rows unchanged

// Example of a LOG line from the automated backup process
// 6/10/2015 05:45:56.5254850	Information	6/10/2015  5:45:56 AM:      Execution started.    

// D=DELETE CHAR
// K=KEEP CHAR
// DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK
// 6/10/2015 05:45:56.5254850	Information	6/10/2015  5:45:56 AM:      Execution started.    



*/
// todo

// $(global.v_log_table_name)
//let v_leading_timestamp_and_text_infix = upper (chr (9) /* tab */ & 'Information' & chr(32)) ;
let v_leading_timestamp_and_text_infix	 		=  CHR(9) & 'Information'  ; TRAce v_leading_timestamp_and_text_infix = [$(v_leading_timestamp_and_text_infix)];
LET v_leading_timestamp_and_text_infix_length 	= 	LEN (v_leading_timestamp_and_text_infix) ;

LET v_log_first_line 							= PEEK ('contents_of_complete_line', 0, '$(global.v_log_table_name)' ) ; // row 0 is first line for PEEK function
LET v_column_position_of_command_text 			= INDEX (UPPER (v_log_first_line), UPPER (global.execution_started_text), 1) ;



TRACE v_column_position_of_command_text								= [$(v_column_position_of_command_text)] ;
TRACE v_log_first_line												= '$(v_log_first_line)' ;
TRACE vEncoding														= [$(vEncoding)] ;
TRACE v_remove_leading_timestamp_and_text_from_backup_log_files 	= [$(v_remove_leading_timestamp_and_text_from_backup_log_files)] ;



let v_is_file_from_backup_log_files_YN				= IF (INDEX (upper ( v_log_first_line ), upper ( '$(v_leading_timestamp_and_text_infix)' )) >0, 'Y', 'N') ;

TRACE v_is_file_from_backup_log_files_YN = [$(v_is_file_from_backup_log_files_YN)] ;







//exit script ;


IF upper (v_is_file_from_backup_log_files_YN) = 'Y' THEN ;
	// remove the leading timestamp text
	//LET x= MID ( v_log_first_line , INDEX (upper ( v_log_first_line ), upper (v_leading_timestamp_and_text_infix))+v_leading_timestamp_and_text_infix_length+1, 1024) ; trace x=[$(x)] ;
	//let y=left (v_log_first_line,4); TRACE y=[$(y)] ;

	trace Variable [v_remove_leading_timestamp_and_text_from_backup_log_files] has value [$(v_remove_leading_timestamp_and_text_from_backup_log_files)] which means that leading text added by Publisher backup process will be removed from each LOG line before continuing ;
	
	$(global.v_log_table_name)_remove_leading_timestamp_etc:
	NOCONCATENATE
	LOAD
		%LogFileKey
		,
		$(global.v_log_table_name).ROW_NUMBER
		,
		LogText
		,

		MID ( contents_of_complete_line , INDEX (upper ( contents_of_complete_line ), upper ( '$(v_leading_timestamp_and_text_infix)'        ))+ $(v_leading_timestamp_and_text_infix_length)+1, 1024) 
		
		AS contents_of_complete_line
	RESIDENT 
		'$(global.v_log_table_name)' 
	;

	DROP TABLE '$(global.v_log_table_name)' ;
	RENAME TABLE '$(global.v_log_table_name)_remove_leading_timestamp_etc' TO '$(global.v_log_table_name)' ;
	
	//exit script;

end if ;


// recapture these now that final tidying up has been done
LET v_log_first_line 							= PEEK ('contents_of_complete_line', 0, '$(global.v_log_table_name)' ) ; // row 0 is first line for PEEK function
LET v_column_position_of_command_text 			= INDEX (UPPER (v_log_first_line), UPPER (global.execution_started_text), 1) ;






//END IF ;


//call output_variable_values ('v_column_position_of_command_text,v_log_first_line') ;



//exit script;
///$tab Break out First and Second words in a line
/*


TAB, created by Steven White (SOIO), breaks out each LOG line to detect first and second words so that syntax detection is better
and less false positives with TRACE or LET/SET v = 'something inside quotes confusing things'

QVW LOG contents before:
6/10/2015  5:45:56 AM:      TRACE some text of another


1=first word
2=second word
QVW LOG contents after:
6/10/2015  5:45:56 AM:      TRACE some text of another
                            11111222222222222222222222
                            
                            
*/


$(global.v_log_table_name)_prepare:
LOAD
	*
;
LOAD 
	*,
	MID (command_text, INDEX (command_text, first_whole_word, 1) + LEN (first_whole_word), $(global.maximum_length_of_log_text_line) ) 	as text_after_first_whole_word // <<<<<<<<<<<<<<<<<<<<<<<<<< now later syntax analysis can be more aware of context
	,
	PREVIOUS (first_whole_word) 																										as previous_first_whole_word // <<<<<<<<<<<<<<<<<<<<<<<<<< now later syntax analysis can be more aware of context
;
LOAD 
	*
	,
	IF ( INDEX (first_whole_word_dirty, '(') > 0, LEFT (first_whole_word_dirty, INDEX (first_whole_word_dirty, '(')-1 ), first_whole_word_dirty) AS first_whole_word
	,
	IF ( INDEX (second_whole_word_dirty, '(') > 0, LEFT (second_whole_word_dirty, INDEX (second_whole_word_dirty, '(')-1 ), second_whole_word_dirty) AS second_whole_word
;
LOAD
	*
	,
	UPPER (SUBFIELD (LTRIM (command_text), ' ', 1) ) 				AS first_whole_word_dirty // <<<<<<<<<<<<<<<<<<<<<<<<<< now later syntax analysis can be more aware of context
	,
	RTRIM (UPPER (SUBFIELD (LTRIM (command_text), ' ', 2) ) ) 		AS second_whole_word_dirty // <<<<<<<<<<<<<<<<<<<<<<<<<< now later syntax analysis can be more aware of context
;
LOAD
	*
	,
	UPPER (MID (contents_of_complete_line, $(v_column_position_of_command_text), $(global.maximum_length_of_log_text_line) ) ) as command_text 
RESIDENT 
	'$(global.v_log_table_name)'		
ORDER BY
	$(global.v_log_table_name).ROW_NUMBER
;

DROP TABLE '$(global.v_log_table_name)' ;
RENAME TABLE '$(global.v_log_table_name)_prepare' TO '$(global.v_log_table_name)' ;

///$tab Clean up and prepare for Robs's code (created by SOIO)
SET v_single_quote_char 		= 'CHR (39)';
SET v_double_quote_char 		= 'CHR (34)';
SET v_left_square_bracket_char 	= 'CHR (91)';
LET v_TRACE_command_text 		= 'TRACE' ;
LET v_TRACE_OUTPUT_command_text	= 'TRACE_OUTPUT' ;

$(global.v_log_table_name)_amend_trace:
NOCONCATENATE
/* 	this final LOAD peels off the characters to the left of the first single quote, double quote or square bracket so that any text after that is not assessed for keywords
	it is assumed that QVW keywords will be before those delimiters for the purposes of this Script LOG Analyzer
	The one syntax that this code will prevent detection of is table names e.g. table_name: that themselves are enclosed in those characters e.g. [table_name]:
	See script tab [Detect table naming] for detecting of table naming
	
	
*/
load 
	*
	,
	IF 
		(
		INDEX ( LogText_not_TRACE, $(v_single_quote_char) )  <> 0 
		,
		// THEN 
		LEFT (LogText_not_TRACE, INDEX ( LogText_not_TRACE, $(v_single_quote_char) ) ) & $(v_single_quote_char)
		
		,
		// ELSE
		//LogText
			IF 
			(
			INDEX ( LogText_not_TRACE, $(v_double_quote_char) )  <> 0 
			,
			// THEN 
			LEFT (LogText_not_TRACE, INDEX ( LogText_not_TRACE, $(v_double_quote_char) ) ) & $(v_double_quote_char)
			
			,
			// ELSE
			//LogText_not_TRACE
				IF 
				(
				INDEX ( LogText_not_TRACE, $(v_left_square_bracket_char) )  <> 0 
				,
				// THEN 
				LEFT (LogText_not_TRACE, INDEX ( LogText_not_TRACE, $(v_left_square_bracket_char) ) ) & $(v_left_square_bracket_char)
				
				,
				// ELSE
				LogText_not_TRACE
				
				
				) 
				
						
			) 
		
		) 
		AS LogText_safe_to_asses_for_functions
;
LOAD // IF LINE IS TRACE OR TRACE_OUTPUT THEN no part of line is safe to assess for operations/functions
	*
	,
	IF (first_whole_word = '$(v_TRACE_command_text)' OR  first_whole_word = '$(v_TRACE_OUTPUT_command_text)' , 	'' , LogText) as LogText_not_TRACE
;
//LOAD
//	*
//WHERE
//	not (
//		first_whole_word = 'END'
//		AND
//		second_whole_word = 'SUB'
//		)
//;
//LOAD // RENAME THE WORD 'LOAD' ON LINES WHICH DO NOT START WITH THE WORD 'LOAD' E.G. TRACE commands which use the word 'LOAD' such as [TRACE Loading table XXX] to prevent Rob's code misdetecting them as the start of a LOAD statement
//	%LogFileKey
//	,
//	$(global.v_log_table_name).ROW_NUMBER
//	,
//	IF 	(
//		first_whole_word <> 'LOAD',
//		//IF 
//		IF (INDEX (UPPER (LogText), 'LOAD') > 0,
//			REPLACE (UPPER (LogText), 'LOAD', 'L*O*A*D')
//			,
//			LogText		
//			)
//		, LogText
//		)
//	 AS LogText
//	,
//	first_whole_word
//	,
//	second_whole_word
//	
//;	
LOAD // any lines immediately following a TRACE command will have a prefix added "TRACE_OUTPUT" to prevent Rob's code misdetectng LOAD statements
	
	IF (previous_first_whole_word = 'TRACE', 'TRACE_OUTPUT', first_whole_word ) as first_whole_word

	,

	second_whole_word

	,

	%LogFileKey

	,

	$(global.v_log_table_name).ROW_NUMBER

	,
	IF (previous_first_whole_word = 'TRACE',
	 	/* THEN */
		LEFT (contents_of_complete_line, $(v_column_position_of_command_text))
		&
		'TRACE_OUTPUT '
		&
		MID ( contents_of_complete_line, $(v_column_position_of_command_text), $(global.maximum_length_of_log_text_line) )
		,
		/* ELSE */
		contents_of_complete_line
		)				
		
		AS LogText 
RESIDENT 
	'$(global.v_log_table_name)' 
;

//EXIT SCRIPT;

DROP TABLE '$(global.v_log_table_name)' ;

RENAME TABLE '$(global.v_log_table_name)_amend_trace' TO 'RESIDENT_VERSION_OF_ORIGINAL_LOG_FILE' ;
DROP FIELDS '$(global.v_log_table_name).ROW_NUMBER';

//EXIT SCRIPT;
///$tab Detect table naming
/*

Rob's default code did not detect table naming e.g. this_is_a_table_name: so when you clicked on an operation in the UI (of this tool) it did not show the table name, only the LOAD syntax below it

Table names in QVW are optional and also can be quite complex. (Examples later)
But for this version we will assume the following syntax for detecting table names:
first non-blank characters on a line
those characters are followed by a full-colon
that full-colon can be followed by anything (we wont care)
This simplistic logic may misdetect some table names or detect non-table naming as table naming but the full syntax is very complicated

Examples of table naming in QVW (even if folks dont typically use these, they can be)
[table name]:
"[table name]":
['table name']:
table_name: LOAD * INLINE // yes table naming can be on the same line as something else


*/

LET v_full_colon_char = ':';

$(global.v_log_table_name)_detect_table_naming:
NOCONCATENATE
LOAD
	%LogFileKey
//	,LogText_safe_to_asses_for_functions
	,
	IF (
		RIGHT (first_whole_word,1) = '$(v_full_colon_char)' AND LEN(first_whole_word)>1 
	, 	/* THEN */ 
	
		LEFT (LogText_safe_to_asses_for_functions, $(v_column_position_of_command_text))
		&
		'TABLE_NAMING '
		&
		MID ( LogText_safe_to_asses_for_functions, $(v_column_position_of_command_text), $(global.maximum_length_of_log_text_line) )
	
		
	
	, /* ELSE */ LogText_safe_to_asses_for_functions
	
	
	
	) as LogText_safe_to_asses_for_functions
	,
	IF (
		RIGHT (first_whole_word,1) = '$(v_full_colon_char)' AND LEN(first_whole_word)>1 
		, 
		/* then */
		'TABLE_NAMING'
		,
		/* ELSE */
		'SOMETHING_ELSE'
		) AS LogText_syntax_type
	,
	LogText

,	first_whole_word
,	second_whole_word
RESIDENT 
	'RESIDENT_VERSION_OF_ORIGINAL_LOG_FILE' 
;

DROP TABLE 'RESIDENT_VERSION_OF_ORIGINAL_LOG_FILE'  ;

RENAME TABLE '$(global.v_log_table_name)_detect_table_naming' TO 'RESIDENT_VERSION_OF_ORIGINAL_LOG_FILE' ;
//DROP FIELDS '$(global.v_log_table_name).ROW_NUMBER';


//CALL DROP_ALL_TABLES_EXCEPT ('$(global.v_log_table_name)_detect_table_naming'); exit script;

/*
LogText
LogText_safe_to_asses_for_functions
%LogFileKey

*/
///$tab Detect FIELDS FOUND
/*
It seems the wildcard approach Rob uses is detecting incorrect LOAD statements 

So I will detect important markers separately starting with "FIELDS FOUND: .... LINES FETCHED"





*/
NOCONCATENATE
detect_fields_found_markers:
LOAD
	*
	,
	IF (FIELDS_FOUND_POS < LINES_FETCHED_POS, 'Y', 'N') AS FIELDS_FOUND_LINES_FETCHED_INDICATOR_YN
;
LOAD
	*,
	INDEX (UPPER (TRIM (LogText_safe_to_asses_for_functions)), 'FIELDS FOUND:') AS FIELDS_FOUND_POS
	,
	INDEX (UPPER (TRIM (LogText_safe_to_asses_for_functions)), 'LINES FETCHED') AS LINES_FETCHED_POS
RESIDENT
	'RESIDENT_VERSION_OF_ORIGINAL_LOG_FILE'
WHERE
	 1=1
;


DROP TABLE 'RESIDENT_VERSION_OF_ORIGINAL_LOG_FILE' ;
RENAME TABLE 'detect_fields_found_markers' TO 'RESIDENT_VERSION_OF_ORIGINAL_LOG_FILE' ;

//EXIT SCRIPT;
///$tab <<<<
///$tab first and second word variations
/*

'NOCONCATENATE','JOIN','LEFT','RIGHT','INNER','OUTER','KEEP','SQL','MAPPING',
'TABLE_NAMING'

*/
///$tab Initial Logdata Load
// The first line of a modern (QV8.5+) log looks like this:
// 03/21/2012 7:21:11 PM:      Execution started. 
// However, there is a lot variability in date and time formats. 
// We need to find the end of the formatted timestamp by counting colons (:).
//TimestampFormat_temp:
//// Find how many : are in the first line.
//FIRST 1
//LOAD 
//	SubStringCount(@1:n, ':') as ColonCount		// count :
//FROM [$(_logpath)]
//(fix, codepage is 1252)
//;
//LET vColonCount = peek('ColonCount');			// Get count in variable
//DROP TABLE TimestampFormat_temp;				

let vColonCount = PEEK ('LogText' ,0,'RESIDENT_VERSION_OF_ORIGINAL_LOG_FILE') ; TRACE vColonCount = [$(vColonCount)] ;
LET vColonCount = SubStringCount (vColonCount, ':') ; TRACE vColonCount = [$(vColonCount)] ;

//EXIT SCRIPT;

//======================================================
// A long preceding load, read from the bottom.
// A logfile line looks like:
// 03/21/2012 7:21:11 PM:      Execution started. 
// However, it may have slightly different formats for date
// and time. Common variations are no AM/PM, hh:mm, fractional
// seconds with or without a decimal point, two or more spaces
// between Date and Time. "." as date seperators.
//======================================================

//EXIT SCRIPT;

LogData:
// Assign a unique rowid to the logline. 
// Assign the script text to a function bucket.
// Test for an failed execution and set flag. 
LOAD 
	*,
	Rowno() as LogRecId,
//	if(InSQL, '', $(vMapExpr(ScriptText))) as LineFunction,

	if	(
		InSQL, 
		
		/* then */
		'', 
		
		/* else */
		if 	(
			FIELDS_FOUND_LINES_FETCHED_INDICATOR_YN = 'Y'
			/* then */
			, 
			'LoadEnd'
			/* else */
			,
			
			//$(vMapExpr(ScriptText))		
			IF (MATCH (first_whole_word, 'NOCONCATENATE','JOIN','LEFT','RIGHT','INNER','OUTER','KEEP','SQL','MAPPING') >0 , /* then */ 'Load', 'Other')
			
			
			)
		
	
		) as LineFunction,



//	if(InSQL, '', $(vMapExpr(LogText_safe_to_asses_for_functions))) as LineFunction,
//	if(InSQL, '', $(vMapExpr(ScriptText))   ) as LineFunction,
//	if(InSQL, '', $(vMapExpr(first_whole_word))   ) as LineFunction,
	// first_whole_word
	
	if(LogText_safe_to_asses_for_functions = 'Execution Failed', dual('Y',1), dual('N',0)) as [Script Failed]
	//if(ScriptText = 'Execution Failed', dual('Y',1), dual('N',0)) as [Script Failed]

// SOIO
// SHOULDNT THIS BE DETECTION OPERATIONS BASED ON FIRST WORD AND SECOND WORD?


;

LOAD 
	*
	,if(upper(left(ScriptText,4))='SQL ',1
	,if($(vMapExpr(ScriptText)) =  'LoadEnd' OR $(vMapExpr(ScriptText)) = 'JoinEnd', 0

	,peek('InSQL')
	)) as InSQL
;	

//	if(upper(left(LogText_safe_to_asses_for_functions,4))='SQL ',1
//	,if($(vMapExpr(LogText_safe_to_asses_for_functions)) =  'LoadEnd' OR $(vMapExpr(LogText_safe_to_asses_for_functions)) = 'JoinEnd', 0


// Flag if this was a valid timestamp or not.
// Get the script text portion from the line.
LOAD
	*
WHERE
	( [Valid Timestamp] = 'Y' AND upper ('$(v_remove_invalid_timestamp_rows_YN)') = 'Y')
	
	OR
	( upper ('$(v_remove_invalid_timestamp_rows_YN)') ='N')
	
;

LOAD
	*,
	if(LogTimestamp > 0			// If we have a value, 
		,dual('Y',1)			// Then flag it as a valid timestamp
		,dual('N',0) 			// else flag as invalid 
	) as [Valid Timestamp],
	
	if(LogTimestamp > 0			// If we have a timestamp value
//		,trim(mid(LogText, index(LogText,':',$(vColonCount))+6))	// Then extract the script text after the timestamp
//		,LogText													// no timestamp, use the whole record as the script text

		,trim(mid(LogText_safe_to_asses_for_functions, index(LogText_safe_to_asses_for_functions,':',$(vColonCount))+6))	// Then extract the script text after the timestamp
		,LogText_safe_to_asses_for_functions													// no timestamp, use the whole record as the script text


	) as ScriptText
;

// LogText_safe_to_asses_for_functions

// Finally! We get to interpret the timestamp text as a timestamp value.
// We will try multiple formats, and if none match, the alt() function will assign 0 
// to the LogTimestamp field.
LOAD 
	*,
	 timestamp(
		alt(
			// Use user specified format if present, otherwise try script default. 
			timestamp#(LogTimestamp_text,if(len(trim('$(vLogTimestampFormat)'))>0, trim('$(vLogTimestampFormat)'), '$(TimestampFormat)'))
			// Try US date format
			,timestamp#(LogTimestamp_text, 'MM/DD/YYYY hh:mm[:ss][.fff][ TT]')
			// Try Europe date format
			,timestamp#(LogTimestamp_text, 'DD/MM/YYYY hh:mm[:ss][.fff][ TT]')
			// Try this one
			,timestamp#(LogTimestamp_text, 'YYYY-MMM-DD hh:mm[:ss][.fff][ TT]')
			// And this one
			,timestamp#(LogTimestamp_text, 'YYYY-MM-DD hh:mm[:ss][.fff][ TT]')
			// And this one
			,timestamp#(LogTimestamp_text, 'YYYY-DD-MM hh:mm[:ss][.fff][ TT]')
			,0
		)
		
	) as LogTimestamp
;

// Some log lines do not have a timestamp. They are a continuation of a previous line. 
// In that case, use the timestamp from the previous line. 
// LogTimestamp_text will now contain:
// 3/22/2012 5:21:17 AM
LOAD
	*,
	if(len(trim(LogTimestamp_text_temp))=0		// If it looks like we don't have a timestamp to parse,
		,Previous(LogTimestamp_text_temp)		// then use timestamp from previous line. 
		,LogTimestamp_text_temp					// else use the presumed timestamp from this line.
	) as LogTimestamp_text
;

// I've seen timestamps that have extra fractional zeros but without the decimal point. 
// This is caused by the user leaving off the decimal in timestamp format like:
//   SET TimestampFormat='M/D/YYYY h:mm:ss[fff] TT';
// That causes QV to generate times like "5:21:1700", which will be interpreted as 
// "1700 seconds", resulting in incorrect duration times. 
// The following edit will remove the extra zeros by ensuring that hh mm ss are no more than 
// two digits each.
//
// LogTimestamp_text_temp will now contain:
// 3/22/2012 5:21:17 AM
LOAD 
	*,
	LogTimestamp_Date
	& ' '
	& replace(trim(
		left(SubField(LogTimestamp_Time_temp,':',1),2)	// hh
		& ' ' & left(SubField(LogTimestamp_Time_temp,':',2),2)	// mm
		& ' ' & left(SubField(LogTimestamp_Time_temp,':',3),2)	// ss
	),' ',':')
	& ' ' & SubField(LogTimestamp_Time_temp,' ',2) 			// TT
	as LogTimestamp_text_temp
;

// Get the Time portion. It's necessary to do it this way, rather than subfield(), 
// because there may be two or more spaces between Date and Time.
// Replace any "." seperator with ":".
// LogTimestamp_Time_temp will contain:
// 5:21:17 AM
LOAD
	*,
	Replace(													// Replace "." with ":".
		trim(mid(LogTimestamp_temp, len(LogTimestamp_Date)+1))	// Get string starting after the date portion
		,'.', ':'
	) as LogTimestamp_Time_temp
;

// Get just the Date portion.
// Replace any "." seperator with "/".
// LogTimestamp_Date will contain:
// 3/22/2012
LOAD
	*,
	Replace(
		SubField(LogTimestamp_temp,' ',1) 
		,'.', '/'
	) as LogTimestamp_Date		
;

// Extract the presumed Date Time words into LogTimestamp_temp.
// LogTimestamp_temp will now contain:
// 3/22/2012 5:21:17 AM
LOAD
	*,
	left(LogText,index(LogText,':',$(vColonCount))-1) as LogTimestamp_temp
;

// Pick up the Qlikview Version line if present. 
LOAD
	*,
	//TextBetween(LogText,'QlikView Version:', '') as [QlikView Version]	
	TextBetween(LogText,'QlikView Version:', '') as [QlikView Version]	
	
;	

//=== Beginning of LogData Load ===
// Assign a Key
// and put the line in a friendly field name.
LOAD 
	first_whole_word,
	second_whole_word,
	FIELDS_FOUND_LINES_FETCHED_INDICATOR_YN,
	//autonumber(FilePath(), 'LogFileKey') as 
	%LogFileKey
	,
    //@1:n as 
    LogText
    , LogText_safe_to_asses_for_functions
    , LogText_syntax_type
RESIDENT
	'RESIDENT_VERSION_OF_ORIGINAL_LOG_FILE'
//FROM [$(_logpath)]
//(fix, $(vEncoding))
WHERE 
	len(trim(LogText))>19	// Only records that have a timestamp
;

DROP TABLE 'RESIDENT_VERSION_OF_ORIGINAL_LOG_FILE';

//EXIT SCRIPT;

// Drop temp fields
DROP FIELDS
LogTimestamp_temp,
LogTimestamp_Time_temp,
LogTimestamp_text_temp
;

/*
LOAD 
	autonumber(FilePath(), 'LogFileKey') as %LogFileKey,
    @1:n as LogText
FROM [$(_logpath)]
(fix, $(vEncoding))
WHERE len(trim(@1:n))>19	// Only records that have a timestamp
;


*/


//EXIT SCRIPT;
///$tab TimestampMap
//======================================================
// Compute the duration between lines of the log.
//======================================================

LET vLogStartTime = num(peek('LogTimestamp',0));	// Get the start time of the log

// Add a field that represents the relative time of each logline.
// The first line is LogTimeStampRelative=0, a line that occurred 5 seconds 
// from the beginning is LogTimeStampRelative=5 and so on.
LEFT JOIN (LogData)
LOAD 
	LogRecId,
	interval(fabs(LogTimestamp - $(vLogStartTime)), 'hh:mm:ss') as LogTimeStampRelative
RESIDENT LogData
;


// Prepare a map of LogRecId to the LogTimestamp of the following row
TimestampMap_temp:
LOAD
	LogRecId, LogTimestamp
RESIDENT LogData
;
CONCATENATE LOAD
	peek('LogRecId',-1,)+1 as LogRecId,
	peek('LogTimestamp',-1) as LogTimestamp
AUTOGENERATE 1
;

// REPLACE does not seem to work with Maps. As a workaround,
// use the vLogFileKey to qualify the mapname and make a new map. 
TimestampMap_$(vLogFileKey):
MAPPING  LOAD
	LogRecId, LogTimestamp
RESIDENT TimestampMap_temp
;
DROP TABLE TimestampMap_temp;


// Create a LineDuration field, which is this line's timestamp
// minus the next line's timestamp.
LogData2:
NOCONCATENATE
LOAD
	*,
	interval(ApplyMap('TimestampMap_$(vLogFileKey)', LogRecId+1) - LogTimestamp, 'hh:mm:ss') as LineDuration
RESIDENT LogData
;

// Drop and rename tables
DROP TABLE LogData;
RENAME TABLE LogData2 TO LogData;

///$tab Joins
//======================================================
// Process the Join & Keep operations
//======================================================

// Load the Start and End operations into a new table.
Joins:
LOAD
	LogRecId,
	LineFunction,
	// If start, use the current LogRecId as the OperationId. Else use the previous (start) LogRecId.
	if(LineFunction = 'Join', LogRecId, peek('OperationId')) as OperationId	
RESIDENT LogData
WHERE Match(LineFunction, 'Join', 'JoinEnd')	// Only start/end for Join
;

// Assign the operation bucket,
// Set the LogRecId of the Operation start,
// Set the time of the Operation start.
Joins2:
LOAD 
	'Join/Keep' as Operation,
	OperationId,
	LogRecId as OperationStartLogRecId,
	ApplyMap('TimestampMap_$(vLogFileKey)', LogRecId) as OperationStart
RESIDENT Joins
WHERE LineFunction = 'Join'
;


// Set the LogRecId of the Operation end,
// Set the time of the Operation end.
LEFT JOIN(Joins2)
LOAD 
	OperationId,
	LogRecId as OperationEndLogRecId,
	ApplyMap('TimestampMap_$(vLogFileKey)', LogRecId+1) as OperationEnd
RESIDENT Joins
WHERE LineFunction = 'JoinEnd'
;

// Calculate the OperationDuration
LEFT JOIN(Joins2)
LOAD DISTINCT *,
	Interval(OperationEnd - OperationStart, 'hh:mm:ss') as OperationDuration
RESIDENT Joins2
;


DROP TABLE Joins;		// Drop the orginal table

// Do an interval match now to get all the LogRecId that are used in Join 
// so we can exclude them from Loads.
JoinLogRecIds:
IntervalMatch (LogRecId)
						  // For a failed script, we may not have an Operation end, so make OpEnd end of script.
LOAD OperationStartLogRecId, if(IsNull(OperationEndLogRecId), 999999, OperationEndLogRecId)
RESIDENT Joins2
;
// Create a ExcludeLogRecId field for future exists() testing
ExcludeIds:
LOAD LogRecId as ExcludeLogRecId
RESIDENT JoinLogRecIds
;

DROP TABLE JoinLogRecIds;	// Drop temp table

//exit script;




///$tab Loads
//======================================================
// Process the Load operations
//======================================================

// Load the Start and End operations into a new table,
// excluding the rows we already assigned to Join operation.
Loads:
LOAD
	LogRecId,
	LineFunction
RESIDENT LogData
WHERE 
	Match(LineFunction, 'Load', 'LoadEnd')

//and NOT EXISTS (OperationId, LogRecId) // Exclude rows we assigned to Join operations

// soio - when i disable this line much more operations are detected
AND NOT EXISTS(ExcludeLogRecId, LogRecId)		// Exclude rows we assigned to Join operations

;

call write_out_what_it_sees ('Loads', 'custom');


//Flag nested (preceding) loads. 
Loads2:
LOAD
	LogRecId,
	LineFunction,
	// A Load that was preceded by a Load is a nested (preceding) Load.
	if(LineFunction = 'Load' AND previous(LineFunction) = 'Load', 1) as IsNestedLoad
RESIDENT Loads
WHERE Match(LineFunction, 'Load', 'LoadEnd')
;
//EXIT SCRIPT;

DROP TABLE Loads;
RENAME TABLE Loads2 TO Loads;

// Load only not nested (preceding) loads.
Loads2:
NOCONCATENATE
LOAD * RESIDENT Loads
WHERE IsNestedLoad <> 1
;
DROP TABLE Loads;
RENAME TABLE Loads2 TO Loads;


// Load the Start and End operations into a new table.
Loads2:
LOAD
	*,
	// If start, use the current LogRecId as the OperationId. Else use the previous (start) LogRecId.
	if(LineFunction = 'Load', LogRecId, peek('OperationId')) as OperationId
RESIDENT Loads
;
DROP TABLE Loads;
RENAME TABLE Loads2 TO Loads;


// Assign the operation bucket,
// Set the LogRecId of the Operation start,
// Set the time of the Operation start.
Loads2:
LOAD 
	'Load' as Operation,
	OperationId,
	LogRecId as OperationStartLogRecId,
	ApplyMap('TimestampMap_$(vLogFileKey)', LogRecId) as OperationStart
RESIDENT Loads
WHERE LineFunction = 'Load'
;

// Set the LogRecId of the Operation end,
// Set the time of the Operation end.
LEFT JOIN(Loads2)
LOAD 
	OperationId,
	LogRecId as OperationEndLogRecId,
	ApplyMap('TimestampMap_$(vLogFileKey)', LogRecId+1) as OperationEnd
RESIDENT Loads
WHERE LineFunction = 'LoadEnd'
;

// Calculate the OperationDuration
LEFT JOIN(Loads2)
LOAD DISTINCT *,
	Interval(OperationEnd - OperationStart, 'hh:mm:ss') as OperationDuration
RESIDENT Loads2
;

DROP TABLE Loads; // Drop the orginal table


// Do an interval match now to get all the LogRecIds that are used in Load so we can exclude them from Others.
LoadLogRecIds:
IntervalMatch (LogRecId)
                          // For a failed script, we may not have an Operation end, so make OpEnd end of script.
LOAD OperationStartLogRecId, if(IsNull(OperationEndLogRecId), 999999, OperationEndLogRecId)
RESIDENT Loads2
;
// Create a ExcludeLogRecId field for future exists() testing
ExcludeIds:
LOAD LogRecId as ExcludeLogRecId
RESIDENT LoadLogRecIds
;

DROP TABLE LoadLogRecIds; // Drop temp table


///$tab Combine
//==============================================================
// Combine all operation types into a single Operations table.
//==============================================================
// Load operation=Join
Operations:
LOAD *,
	$(vLogFileKey) as %LogFileKey
RESIDENT Joins2
;
DROP TABLE Joins2;		

// Load operation=Load
CONCATENATE 
LOAD *,
	$(vLogFileKey) as %LogFileKey
RESIDENT Loads2
;
DROP TABLE Loads2;

//call drop_all_tables_except ('Operations'); ; exit script;

// Load operation=Other
// "Other" operations don't span lines, so we can use the 
// single line values for Operation start/stop.
CONCATENATE
LOAD 
	$(vLogFileKey) as %LogFileKey,
	LineFunction as Operation,
	LogRecId as OperationId,
	LogRecId as OperationStartLogRecId,
	LogRecId as OperationEndLogRecId,
	LogTimestamp as OperationStart,
	LogTimestamp as OperationEnd,
	LineDuration as OperationDuration
RESIDENT 
	LogData
WHERE 
	LineFunction = 'Other'
	
	//and NOT EXISTS (OperationId, LogRecId) // Exclude rows we assigned to Join operations

	AND NOT EXISTS(ExcludeLogRecId, LogRecId)		// Exclude lines already used in another bucket
;

DROP TABLE ExcludeIds;		// No longer needed

call write_out_what_it_sees ('LogData', 'before_IntervalMatch');

//==================================================
// Create a link between the Operations table and the LogData table.
//==================================================
LEFT JOIN
	(LogData)
IntervalMatch 
	(LogRecId, %LogFileKey)
LOAD 
	OperationStartLogRecId, 
	OperationEndLogRecId,
	%LogFileKey
RESIDENT 
	Operations
;

call write_out_what_it_sees ('LogData', 'after_combine_custom');

///$tab Final Tables
//==================================================
// Add this log's data to the accumlated (Final) tables.
//==================================================

// Add all LogData to table FinalLogData.
FinalLogData:
LOAD *,
	autonumber(%LogFileKey &'_'& OperationStartLogRecId &'_'& OperationEndLogRecId, 'OperationKey') as %OperationKey
RESIDENT LogData
;
DROP TABLE LogData;		// Drop single log table


// Add all Operations to table FinalOperations.
FinalOperations:
LOAD *,
	autonumber(%LogFileKey &'_'& OperationStartLogRecId &'_'& OperationEndLogRecId, 'OperationKey') as %OperationKey,
	interval(fabs(OperationStart - $(vLogStartTime)), 'hh:mm:ss') as OperationRelativeStart
RESIDENT Operations
;
DROP TABLE Operations;


	
///$tab END SUB LoadLog
// Clear variables
SET vLogFileKey=;		
SET vColonCount=;
SET vLogStartTime=;
SET vTimestampChars=;

END SUB ;
//======================================================
REM End of LoadLog SUB run for each logfile.;
//======================================================

///$tab Load Logs
// Process all log files found in specified directory

TRACE v_search_folders 	= [$(v_search_folders)] ;
//exit script;



IF UPPER (TRIM (v_search_folders)) = 'Y' THEN ;
	CALL Qvc.ListFiles('$(vLoadedLogDir)', '*.qvw.*log', '-1', 'LoadLog');
ELSE
	CALL Qvc.ListFiles('$(vLoadedLogDir)', '*.qvw.*log', '0', 'LoadLog');
END IF ;
///$tab Update LogSummary
IF NoOfRows('LogSummary') > 0 THEN 
//======================================================
// Calculate summary data and move fields to the LogSummary table.
//======================================================

LEFT JOIN (LogSummary)		// Add to LogSummary table
LOAD DISTINCT
	*,
	// Total runtime for this log
	interval(maxtime - mintime, 'hh:mm:ss') as TotalRuntime,
	
	// Identify the precision of timestamps in the Log.
	if([Valid Timestamp]
		,pick(
			SubStringCount(Max_LogTimestamp_text,':')
			,'minutes'
			,'seconds'
		)
		,''
	) as [LogTimestamp Precision]			
			

	
;

LOAD
	%LogFileKey,
	timestamp(min(LogTimestamp)) as mintime,		// Lowest timestamp	
	timestamp(max(LogTimestamp)) as maxtime,		// Highest timestamp
	max([Script Failed]) as [Script Failed],		// Will be true if any line has [Script Failed]
	min([Valid Timestamp]) as [Valid Timestamp],	// Will be false if any line has NOT [Valid Timetamp]
	MaxString([QlikView Version]) as [Qlikview Version],	// One line has the QV version #, get it.
	MaxString(LogTimestamp_text) as Max_LogTimestamp_text	// For precision test above
RESIDENT FinalLogData
GROUP BY %LogFileKey 				// Group values by Log
;
// Drop these fields from the detail table. They have been moved to the summary table.
DROP FIELD [Script Failed] FROM FinalLogData;
DROP FIELD [Valid Timestamp] FROM FinalLogData;
DROP FIELD [QlikView Version] FROM FinalLogData;

DROP FIELD Max_LogTimestamp_text;
ENDIF
///$tab Cleanup
//======================================================
// Cleanup
//======================================================
IF NoOfRows('LogSummary') > 0 THEN 
// If these fields were dropped in the SUB, it would break auto concatenation.
// Drop them here instead.
DROP FIELD OperationStartLogRecId, OperationEndLogRecId FROM FinalOperations;
DROP FIELD %LogFileKey FROM FinalLogData;
ENDIF

SET vMapExpr=;		// The Wildmap expression


// When using Qvc, always call Qvc.Cleanup
CALL Qvc.Cleanup;
///$tab EXIT SCRIPT;
EXIT SCRIPT;
///$tab exit script;
//call drop_table ('Joins2'); exit script;

//call drop_all_tables_except ('Loads2'); ; exit script;

